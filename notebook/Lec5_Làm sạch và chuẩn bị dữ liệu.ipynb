{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a35277-2812-41cc-a00e-c99ade49156f",
   "metadata": {},
   "source": [
    "# 📊 Làm sạch và chuẩn bị dữ liệu trong Khoa học Dữ liệu\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Mục tiêu học tập\n",
    "\n",
    "Sau khi hoàn thành bài học này, bạn sẽ có thể:\n",
    "\n",
    "✅ **Hiểu và xử lý dữ liệu thiếu** trong các bộ dữ liệu kinh tế  \n",
    "✅ **Phát hiện và loại bỏ dữ liệu trùng lặp** trong khảo sát khách hàng  \n",
    "✅ **Chuẩn hóa và biến đổi dữ liệu** để phù hợp với phân tích  \n",
    "✅ **Xử lý dữ liệu chuỗi ký tự** từ các nguồn khác nhau  \n",
    "✅ **Mã hóa dữ liệu phân loại** cho machine learning  \n",
    "\n",
    "---\n",
    "\n",
    "## 📍 Lộ trình bài giảng\n",
    "\n",
    "```\n",
    "Phần 1: Xử lý dữ liệu thiếu                    ⭐⭐ Trung bình\n",
    "    ├── Phát hiện dữ liệu thiếu\n",
    "    ├── Loại bỏ (dropna)\n",
    "    ├── Thay thế (fillna)\n",
    "    └── Dự đoán (ML methods)\n",
    "    \n",
    "Phần 2: Xử lý dữ liệu trùng lặp                ⭐ Dễ\n",
    "    ├── Phát hiện (duplicated)\n",
    "    └── Loại bỏ (drop_duplicates)\n",
    "    \n",
    "Phần 3: Chuẩn hóa dữ liệu                      ⭐⭐ Trung bình\n",
    "    ├── MinMaxScaler\n",
    "    ├── StandardScaler\n",
    "    └── RobustScaler\n",
    "    \n",
    "Phần 4: Xử lý chuỗi ký tự                       ⭐⭐⭐ Khó\n",
    "    ├── String methods cơ bản\n",
    "    └── Regular Expressions (Regex)\n",
    "    \n",
    "Phần 5: Dữ liệu phân loại                      ⭐⭐ Trung bình\n",
    "    ├── Label Encoding\n",
    "    └── One-Hot Encoding\n",
    "```\n",
    "\n",
    "> **💡 Khuyến nghị:** Học tuần tự từ Phần 1 → Phần 5. Mỗi phần xây dựng dựa trên kiến thức của phần trước.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Lưu ý quan trọng\n",
    "\n",
    "> **💡 Cho sinh viên Kinh tế:** Bài học này tập trung vào các kỹ thuật thực tế mà bạn sẽ sử dụng khi phân tích dữ liệu kinh tế, khảo sát khách hàng, và nghiên cứu thị trường.\n",
    "\n",
    "> **🔧 Tương thích:** Notebook này hoạt động tốt trên cả **Jupyter Notebook**, **JupyterLab**, và **Google Colab**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Bắt đầu học tập\n",
    "\n",
    "Hãy bắt đầu với **Phần 1: Xử lý dữ liệu thiếu** 👇\n",
    "\n",
    "> **💡 Cho sinh viên Kinh tế:** Bài học này tập trung vào các kỹ thuật thực tế mà bạn sẽ sử dụng khi phân tích dữ liệu kinh tế, khảo sát khách hàng, và nghiên cứu thị trường.\n",
    "\n",
    "> **🔧 Tương thích:** Notebook này hoạt động tốt trên cả **Jupyter Notebook**, **JupyterLab**, và **Google Colab**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b27ec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔧 Thiết lập môi trường\n",
    "\n",
    "> **💡 MỤC TIÊU:** Đảm bảo notebook hoạt động tốt trên cả môi trường local và Google Colab\n",
    "\n",
    "### **Cài đặt thư viện cần thiết:**\n",
    "\n",
    "```python\n",
    "# Chạy cell này nếu bạn đang sử dụng Google Colab\n",
    "# Hoặc nếu gặp lỗi ImportError khi chạy các cell khác\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Cài đặt package nếu chưa có\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✅ {package} đã được cài đặt\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Đang cài đặt {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ Đã cài đặt {package} thành công\")\n",
    "\n",
    "# Cài đặt các thư viện cần thiết\n",
    "packages = [\n",
    "    \"pandas\",\n",
    "    \"numpy\", \n",
    "    \"scikit-learn\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"🎉 Thiết lập hoàn tất! Bạn có thể tiếp tục với bài học.\")\n",
    "```\n",
    "\n",
    "### **Import thư viện:**\n",
    "\n",
    "```python\n",
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thiết lập hiển thị\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"✅ Đã import tất cả thư viện cần thiết!\")\n",
    "print(\"📊 Sẵn sàng bắt đầu bài học Data Cleaning!\")\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad714ca2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc92628e",
   "metadata": {},
   "source": [
    "## 🛠️ Thiết lập môi trường\n",
    "\n",
    "Trước khi bắt đầu, hãy đảm bảo bạn đã cài đặt các thư viện cần thiết:\n",
    "\n",
    "**📦 Cài đặt thư viện (chạy cell này nếu bạn đang sử dụng Google Colab):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6aa4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Thiếu thư viện: cannot import name 'KNNImputer' from 'sklearn.preprocessing' (/Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages/sklearn/preprocessing/__init__.py)\n",
      "🔧 Đang cài đặt...\n",
      "Requirement already satisfied: pandas in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "✅ Cài đặt hoàn tất! Vui lòng restart kernel và chạy lại cell này.\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện cho Google Colab (bỏ qua nếu đã cài đặt)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, KNNImputer\n",
    "    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "    print(\"✅ Tất cả thư viện đã sẵn sàng!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Thiếu thư viện: {e}\")\n",
    "    print(\"🔧 Đang cài đặt...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # Cài đặt các thư viện cần thiết\n",
    "    packages = ['pandas', 'numpy', 'scikit-learn']\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "    \n",
    "    print(\"✅ Cài đặt hoàn tất! Vui lòng restart kernel và chạy lại cell này.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d87558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8867191",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79fbd8d0",
   "metadata": {},
   "source": [
    "# 🔍 Phần 1: Xử lý dữ liệu thiếu (Missing Data)\n",
    "\n",
    "## 🎯 Mục tiêu phần này\n",
    "- Hiểu tại sao dữ liệu thiếu là vấn đề trong kinh tế\n",
    "- Phát hiện missing data trong dữ liệu\n",
    "- Áp dụng các phương pháp xử lý phù hợp\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Ví dụ thực tế: Tại sao dữ liệu thiếu quan trọng?\n",
    "\n",
    "Trong thực tế kinh doanh và nghiên cứu kinh tế, **dữ liệu thiếu** là vấn đề rất phổ biến:\n",
    "\n",
    "### 🏢 Ví dụ thực tế từ doanh nghiệp:\n",
    "- **Khảo sát khách hàng**: Một số khách hàng không trả lời câu hỏi về thu nhập\n",
    "- **Báo cáo tài chính**: Một số công ty không công bố đầy đủ thông tin\n",
    "- **Dữ liệu thị trường**: Giá cổ phiếu có thể bị thiếu trong ngày nghỉ lễ\n",
    "- **Nghiên cứu kinh tế**: Một số hộ gia đình từ chối cung cấp thông tin chi tiêu\n",
    "\n",
    "### ⚠️ Tác động của dữ liệu thiếu:\n",
    "- **Giảm độ tin cậy** của phân tích\n",
    "- **Thiên lệch kết quả** nghiên cứu\n",
    "- **Khó khăn trong dự báo** kinh tế\n",
    "- **Ảnh hưởng đến quyết định** đầu tư"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb9881",
   "metadata": {},
   "source": [
    "## 🎯 DEMO: Dữ liệu nhân viên có missing values\n",
    "\n",
    "Trước khi học lý thuyết, hãy xem một ví dụ thực tế về dữ liệu thiếu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 VÍ DỤ: Dữ liệu nhân viên công ty có missing values\n",
      "============================================================\n",
      "📋 DataFrame nhân viên với dữ liệu thiếu:\n",
      "          TenNV  Tuoi       Luong   PhongBan  KinhNghiem\n",
      "0  Nguyễn Văn A  25.0  15000000.0         IT         2.0\n",
      "1    Trần Thị B   NaN  18000000.0  Marketing         5.0\n",
      "2      Lê Văn C  30.0         NaN       None         NaN\n",
      "3    Phạm Thị D  28.0  22000000.0         IT         7.0\n",
      "4   Hoàng Văn E   NaN  16000000.0  Marketing         1.0\n",
      "\n",
      "📊 Thông tin tổng quan:\n",
      "   - Tổng số nhân viên: 5\n",
      "   - Số cột: 5\n",
      "   - Kiểu dữ liệu:\n",
      "TenNV          object\n",
      "Tuoi          float64\n",
      "Luong         float64\n",
      "PhongBan       object\n",
      "KinhNghiem    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 📊 Ví dụ thực tế: Dữ liệu nhân viên công ty có missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu về nhân viên công ty (tình huống thực tế)\n",
    "print(\"🏢 VÍ DỤ: Dữ liệu nhân viên công ty có missing values\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyễn Văn A', 'Trần Thị B', 'Lê Văn C', 'Phạm Thị D', 'Hoàng Văn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],  # Một số nhân viên không cung cấp tuổi\n",
    "    'Luong': [15000000, 18000000, None, 22000000, 16000000],  # Lương bị thiếu\n",
    "    'PhongBan': ['IT', 'Marketing', None, 'IT', 'Marketing'],  # Phòng ban không rõ\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]  # Kinh nghiệm chưa được cập nhật\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"📋 DataFrame nhân viên với dữ liệu thiếu:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\n📊 Thông tin tổng quan:\")\n",
    "print(f\"   - Tổng số nhân viên: {len(df_nhanvien)}\")\n",
    "print(f\"   - Số cột: {len(df_nhanvien.columns)}\")\n",
    "print(f\"   - Kiểu dữ liệu:\")\n",
    "print(df_nhanvien.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6d04b1",
   "metadata": {},
   "source": [
    "## 📚 Lý thuyết: Hiểu về dữ liệu thiếu\n",
    "\n",
    "Sau khi thấy ví dụ thực tế, hãy tìm hiểu lý thuyết về dữ liệu thiếu:\n",
    "\n",
    "* Trong thực tế, khi thu thập và lưu trữ dữ liệu, không phải lúc nào mọi giá trị cũng được ghi nhận đầy đủ.\n",
    "* Một số ô có thể bị trống hoặc mang các ký hiệu đặc biệt như NA, NaN, NULL, hoặc chuỗi rỗng \"\". Đây chính là dữ liệu thiếu (missing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a667638",
   "metadata": {},
   "source": [
    "### 🔍 Các dạng thiếu dữ liệu trong kinh tế\n",
    "\n",
    "Trong nghiên cứu kinh tế, chúng ta phân loại dữ liệu thiếu thành 3 loại chính:\n",
    "\n",
    "#### 1️⃣ **MCAR (Missing Completely At Random)** - Thiếu hoàn toàn ngẫu nhiên\n",
    "- **Ví dụ**: Máy tính bị lỗi khi thu thập dữ liệu giá cổ phiếu\n",
    "- **Đặc điểm**: Không liên quan đến bất kỳ yếu tố nào\n",
    "- **Xử lý**: Có thể loại bỏ an toàn\n",
    "\n",
    "#### 2️⃣ **MAR (Missing At Random)** - Thiếu có điều kiện\n",
    "- **Ví dụ**: Người có thu nhập cao thường không trả lời câu hỏi về thu nhập\n",
    "- **Đặc điểm**: Phụ thuộc vào các biến khác có thể quan sát được\n",
    "- **Xử lý**: Cần phân tích cẩn thận\n",
    "\n",
    "#### 3️⃣ **MNAR (Missing Not At Random)** - Thiếu có hệ thống\n",
    "- **Ví dụ**: Công ty có lợi nhuận thấp thường không công bố báo cáo tài chính\n",
    "- **Đặc điểm**: Liên quan trực tiếp đến giá trị bị thiếu\n",
    "- **Xử lý**: Cần kỹ thuật phức tạp để xử lý\n",
    "\n",
    "### 📋 Biểu diễn dữ liệu thiếu trong Python:\n",
    "- `NaN` (*Not a Number*) - cho dữ liệu số\n",
    "- `None` - cho dữ liệu đối tượng  \n",
    "- `NaT` (*Not a Time*) - cho dữ liệu thời gian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26c07b",
   "metadata": {},
   "source": [
    "### 🎯 Nguyên nhân gây ra dữ liệu thiếu trong kinh tế\n",
    "\n",
    "#### 📊 **Lỗi thu thập dữ liệu**\n",
    "- **Ví dụ**: Hệ thống giao dịch chứng khoán bị sập trong giờ cao điểm\n",
    "- **Tác động**: Mất dữ liệu giá cổ phiếu quan trọng\n",
    "\n",
    "#### 👥 **Người dùng không cung cấp**\n",
    "- **Ví dụ**: Khách hàng bỏ qua câu hỏi về thu nhập trong khảo sát\n",
    "- **Tác động**: Thiếu thông tin để phân tích hành vi tiêu dùng\n",
    "\n",
    "#### 📈 **Dữ liệu không tồn tại**\n",
    "- **Ví dụ**: Công ty mới thành lập chưa có báo cáo tài chính năm trước\n",
    "- **Tác động**: Khó so sánh hiệu suất với các công ty khác\n",
    "\n",
    "#### 🔄 **Lỗi xử lý dữ liệu**\n",
    "- **Ví dụ**: Lỗi khi chuyển đổi định dạng từ Excel sang CSV\n",
    "- **Tác động**: Mất thông tin quan trọng trong quá trình chuyển đổi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d455ee",
   "metadata": {},
   "source": [
    "### ⚠️ Tác động của dữ liệu thiếu đến phân tích kinh tế\n",
    "\n",
    "#### 📉 **Giảm kích thước mẫu**\n",
    "- **Ví dụ**: Khảo sát 1000 khách hàng, nhưng chỉ có 800 người trả lời đầy đủ\n",
    "- **Tác động**: Giảm độ tin cậy của kết quả nghiên cứu\n",
    "\n",
    "#### 🎯 **Thiên lệch kết quả**\n",
    "- **Ví dụ**: Chỉ những người có thu nhập cao mới trả lời câu hỏi về thu nhập\n",
    "- **Tác động**: Kết quả phân tích không đại diện cho toàn bộ dân số\n",
    "\n",
    "#### 🤖 **Giảm hiệu quả phân tích**\n",
    "- **Ví dụ**: Thuật toán machine learning không thể xử lý dữ liệu thiếu\n",
    "- **Tác động**: Không thể dự báo xu hướng thị trường chính xác\n",
    "\n",
    "#### 💼 **Ảnh hưởng quyết định kinh doanh**\n",
    "- **Ví dụ**: Thiếu dữ liệu về đối thủ cạnh tranh\n",
    "- **Tác động**: Ra quyết định đầu tư không chính xác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e720916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 VÍ DỤ: Dữ liệu nhân viên công ty có missing values\n",
      "============================================================\n",
      "📋 DataFrame nhân viên với dữ liệu thiếu:\n",
      "          TenNV  Tuoi       Luong   PhongBan  KinhNghiem\n",
      "0  Nguyễn Văn A  25.0  15000000.0         IT         2.0\n",
      "1    Trần Thị B   NaN  18000000.0  Marketing         5.0\n",
      "2      Lê Văn C  30.0         NaN       None         NaN\n",
      "3    Phạm Thị D  28.0  22000000.0         IT         7.0\n",
      "4   Hoàng Văn E   NaN  16000000.0  Marketing         1.0\n",
      "\n",
      "📊 Thông tin tổng quan:\n",
      "   - Tổng số nhân viên: 5\n",
      "   - Số cột: 5\n",
      "   - Kiểu dữ liệu:\n",
      "TenNV          object\n",
      "Tuoi          float64\n",
      "Luong         float64\n",
      "PhongBan       object\n",
      "KinhNghiem    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 📊 Ví dụ thực tế: Dữ liệu nhân viên công ty có missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu về nhân viên công ty (tình huống thực tế)\n",
    "print(\"🏢 VÍ DỤ: Dữ liệu nhân viên công ty có missing values\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyễn Văn A', 'Trần Thị B', 'Lê Văn C', 'Phạm Thị D', 'Hoàng Văn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],  # Một số nhân viên không cung cấp tuổi\n",
    "    'Luong': [15000000, 18000000, None, 22000000, 16000000],  # Lương bị thiếu\n",
    "    'PhongBan': ['IT', 'Marketing', None, 'IT', 'Marketing'],  # Phòng ban không rõ\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]  # Kinh nghiệm chưa được cập nhật\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"📋 DataFrame nhân viên với dữ liệu thiếu:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\n📊 Thông tin tổng quan:\")\n",
    "print(f\"   - Tổng số nhân viên: {len(df_nhanvien)}\")\n",
    "print(f\"   - Số cột: {len(df_nhanvien.columns)}\")\n",
    "print(f\"   - Kiểu dữ liệu:\")\n",
    "print(df_nhanvien.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c84ff4",
   "metadata": {},
   "source": [
    "### 🔍 Các phương thức phát hiện dữ liệu thiếu trong pandas\n",
    "\n",
    "Pandas cung cấp các phương thức chuyên dụng để **phát hiện và kiểm tra dữ liệu thiếu**:\n",
    "\n",
    "| Phương thức | Mô tả | Trả về | Ví dụ sử dụng |\n",
    "|-------------|-------|--------|---------------|\n",
    "| `isna()` / `isnull()` | Kiểm tra từng phần tử có thiếu không | Boolean DataFrame/Series | `df.isna()` |\n",
    "| `notna()` / `notnull()` | Kiểm tra từng phần tử có dữ liệu không | Boolean DataFrame/Series | `df.notna()` |\n",
    "| `isna().sum()` | Đếm số lượng dữ liệu thiếu theo cột | Series với số lượng | `df.isna().sum()` |\n",
    "| `isna().any()` | Kiểm tra có cột nào thiếu dữ liệu không | Boolean Series | `df.isna().any()` |\n",
    "\n",
    "**📊 Hãy xem cách sử dụng các phương thức này với dữ liệu nhân viên:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ba1fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bda1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DEMO: Các phương thức phát hiện dữ liệu thiếu\n",
      "============================================================\n",
      "📋 DataFrame gốc:\n",
      "          TenNV  Tuoi       Luong   PhongBan  KinhNghiem\n",
      "0  Nguyễn Văn A  25.0  15000000.0         IT         2.0\n",
      "1    Trần Thị B   NaN  18000000.0  Marketing         5.0\n",
      "2      Lê Văn C  30.0         NaN       None         NaN\n",
      "3    Phạm Thị D  28.0  22000000.0         IT         7.0\n",
      "4   Hoàng Văn E   NaN  16000000.0  Marketing         1.0\n",
      "\n",
      "============================================================\n",
      "1️⃣ KIỂM TRA TỪNG PHẦN TỬ CÓ THIẾU KHÔNG\n",
      "============================================================\n",
      "🔍 df_nhanvien.isna() - Kiểm tra từng ô có thiếu không:\n",
      "   TenNV   Tuoi  Luong  PhongBan  KinhNghiem\n",
      "0  False  False  False     False       False\n",
      "1  False   True  False     False       False\n",
      "2  False  False   True      True        True\n",
      "3  False  False  False     False       False\n",
      "4  False   True  False     False       False\n",
      "\n",
      "🔍 df_nhanvien.notna() - Kiểm tra từng ô có dữ liệu không:\n",
      "   TenNV   Tuoi  Luong  PhongBan  KinhNghiem\n",
      "0   True   True   True      True        True\n",
      "1   True  False   True      True        True\n",
      "2   True   True  False     False       False\n",
      "3   True   True   True      True        True\n",
      "4   True  False   True      True        True\n",
      "\n",
      "============================================================\n",
      "2️⃣ ĐẾM SỐ LƯỢNG DỮ LIỆU THIẾU THEO CỘT\n",
      "============================================================\n",
      "📊 df_nhanvien.isna().sum() - Số lượng missing values theo cột:\n",
      "TenNV         0\n",
      "Tuoi          2\n",
      "Luong         1\n",
      "PhongBan      1\n",
      "KinhNghiem    1\n",
      "dtype: int64\n",
      "\n",
      "📈 Tỷ lệ missing values (%):\n",
      "TenNV          0.0\n",
      "Tuoi          40.0\n",
      "Luong         20.0\n",
      "PhongBan      20.0\n",
      "KinhNghiem    20.0\n",
      "dtype: float64\n",
      "\n",
      "============================================================\n",
      "3️⃣ KIỂM TRA CỘT NÀO CÓ DỮ LIỆU THIẾU\n",
      "============================================================\n",
      "🔍 df_nhanvien.isna().any() - Cột nào có missing values:\n",
      "TenNV         False\n",
      "Tuoi           True\n",
      "Luong          True\n",
      "PhongBan       True\n",
      "KinhNghiem     True\n",
      "dtype: bool\n",
      "\n",
      "============================================================\n",
      "4️⃣ TỔNG SỐ DỮ LIỆU THIẾU\n",
      "============================================================\n",
      "📊 Tổng số missing values: 5\n",
      "📊 Tổng số ô dữ liệu: 25\n",
      "📊 Tỷ lệ missing: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# 🔍 DEMO: Phát hiện dữ liệu thiếu trong DataFrame nhân viên\n",
    "print(\"🔍 DEMO: Các phương thức phát hiện dữ liệu thiếu\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sử dụng DataFrame từ cell trước\n",
    "print(\"📋 DataFrame gốc:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1️⃣ KIỂM TRA TỪNG PHẦN TỬ CÓ THIẾU KHÔNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Kiểm tra dữ liệu thiếu - trả về Boolean DataFrame\n",
    "print(\"🔍 df_nhanvien.isna() - Kiểm tra từng ô có thiếu không:\")\n",
    "print(df_nhanvien.isna())\n",
    "\n",
    "print(\"\\n🔍 df_nhanvien.notna() - Kiểm tra từng ô có dữ liệu không:\")\n",
    "print(df_nhanvien.notna())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2️⃣ ĐẾM SỐ LƯỢNG DỮ LIỆU THIẾU THEO CỘT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 2. Đếm số lượng dữ liệu thiếu theo từng cột\n",
    "print(\"📊 df_nhanvien.isna().sum() - Số lượng missing values theo cột:\")\n",
    "missing_count = df_nhanvien.isna().sum()\n",
    "print(missing_count)\n",
    "\n",
    "# Tính phần trăm missing\n",
    "print(\"\\n📈 Tỷ lệ missing values (%):\")\n",
    "missing_percent = (missing_count / len(df_nhanvien)) * 100\n",
    "print(missing_percent.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3️⃣ KIỂM TRA CỘT NÀO CÓ DỮ LIỆU THIẾU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 3. Kiểm tra cột nào có dữ liệu thiếu\n",
    "print(\"🔍 df_nhanvien.isna().any() - Cột nào có missing values:\")\n",
    "print(df_nhanvien.isna().any())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4️⃣ TỔNG SỐ DỮ LIỆU THIẾU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 4. Tổng số dữ liệu thiếu trong toàn bộ DataFrame\n",
    "total_missing = df_nhanvien.isna().sum().sum()\n",
    "total_cells = df_nhanvien.shape[0] * df_nhanvien.shape[1]\n",
    "missing_percentage = (total_missing / total_cells) * 100\n",
    "\n",
    "print(f\"📊 Tổng số missing values: {total_missing}\")\n",
    "print(f\"📊 Tổng số ô dữ liệu: {total_cells}\")\n",
    "print(f\"📊 Tỷ lệ missing: {missing_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23b439",
   "metadata": {},
   "source": [
    "### 🛠️ Các phương pháp xử lý dữ liệu thiếu trong kinh tế\n",
    "\n",
    "**🎯 Có 3 cách chính để xử lý dữ liệu thiếu:**\n",
    "\n",
    "#### 1️⃣ **Loại bỏ** (*Deletion*) \n",
    "- **Khi nào dùng**: Dữ liệu thiếu < 5%, thiếu ngẫu nhiên\n",
    "- **Ví dụ**: Loại bỏ khách hàng không trả lời đầy đủ khảo sát\n",
    "- **Ưu điểm**: Đơn giản, không tạo bias\n",
    "- **Nhược điểm**: Giảm kích thước mẫu\n",
    "\n",
    "#### 2️⃣ **Thay thế** (*Imputation*)\n",
    "- **Khi nào dùng**: Dữ liệu thiếu 5-20%, có pattern\n",
    "- **Ví dụ**: Thay thế lương thiếu bằng lương trung bình của phòng ban\n",
    "- **Ưu điểm**: Giữ nguyên kích thước mẫu\n",
    "- **Nhược điểm**: Có thể tạo bias\n",
    "\n",
    "#### 3️⃣ **Dự đoán** (*Prediction*)\n",
    "- **Khi nào dùng**: Dữ liệu thiếu > 20%, có mối quan hệ phức tạp\n",
    "- **Ví dụ**: Dùng machine learning để dự đoán thu nhập dựa trên các yếu tố khác\n",
    "- **Ưu điểm**: Chính xác cao\n",
    "- **Nhược điểm**: Phức tạp, cần hiểu biết về ML\n",
    "\n",
    "**⚖️ Hướng dẫn lựa chọn phương pháp:**\n",
    "\n",
    "| Tỷ lệ thiếu | Loại dữ liệu | Phương pháp khuyến nghị |\n",
    "|-------------|--------------|------------------------|\n",
    "| < 5% | Bất kỳ | Loại bỏ |\n",
    "| 5-20% | Số | Mean/Median |\n",
    "| 5-20% | Phân loại | Mode |\n",
    "| > 20% | Có quan hệ | Machine Learning |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7cb6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 **So sánh các phương pháp xử lý Missing Values**\n",
    "\n",
    "Đã học xong các phương pháp xử lý missing values, hãy so sánh để hiểu rõ hơn:\n",
    "\n",
    "| Phương pháp | Khi nào dùng | Ưu điểm | Nhược điểm | Ví dụ |\n",
    "|-------------|--------------|---------|------------|-------|\n",
    "| **Drop (Loại bỏ)** | Missing < 5% tổng dữ liệu | Đơn giản, không làm méo dữ liệu | Mất thông tin, giảm kích thước dataset | Khảo sát có 2% không trả lời |\n",
    "| **Fill Mean/Median** | Dữ liệu số, phân phối chuẩn | Giữ nguyên kích thước dataset | Có thể tạo bias, không phù hợp với categorical | Thu nhập, tuổi tác |\n",
    "| **Fill Mode** | Dữ liệu phân loại | Phù hợp với categorical data | Có thể tạo bias | Giới tính, nghề nghiệp |\n",
    "| **Forward Fill** | Dữ liệu thời gian | Giữ nguyên xu hướng | Có thể tạo bias nếu missing nhiều | Giá cổ phiếu, doanh thu |\n",
    "| **ML Imputation** | Missing > 10%, có mối quan hệ giữa các cột | Chính xác, sử dụng thông tin từ các cột khác | Phức tạp, tốn thời gian | KNN, Random Forest |\n",
    "\n",
    "### **🤔 Khi nào dùng gì?**\n",
    "\n",
    "**Dùng Drop khi:**\n",
    "- ✅ Missing values < 5% tổng dữ liệu\n",
    "- ✅ Không có mối quan hệ giữa các cột\n",
    "- ✅ Cần dữ liệu hoàn toàn chính xác\n",
    "\n",
    "**Dùng Fill khi:**\n",
    "- ✅ Missing values 5-15%\n",
    "- ✅ Có thể ước lượng được giá trị thiếu\n",
    "- ✅ Cần giữ nguyên kích thước dataset\n",
    "\n",
    "**Dùng ML Imputation khi:**\n",
    "- ✅ Missing values > 10%\n",
    "- ✅ Có mối quan hệ mạnh giữa các cột\n",
    "- ✅ Cần độ chính xác cao\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **So sánh các Scaler**\n",
    "\n",
    "| Scaler | Khoảng giá trị | Khi nào dùng | Ưu điểm | Nhược điểm |\n",
    "|--------|----------------|--------------|---------|------------|\n",
    "| **MinMaxScaler** | [0, 1] | Dữ liệu không có outliers | Dễ hiểu, giữ nguyên phân phối | Nhạy cảm với outliers |\n",
    "| **StandardScaler** | Mean=0, Std=1 | Dữ liệu có phân phối chuẩn | Chuẩn hóa theo phân phối chuẩn | Nhạy cảm với outliers |\n",
    "| **RobustScaler** | Median=0, IQR=1 | Dữ liệu có outliers | Không bị ảnh hưởng bởi outliers | Khó hiểu hơn |\n",
    "\n",
    "### **🎯 Chọn Scaler phù hợp:**\n",
    "\n",
    "**MinMaxScaler:**\n",
    "- ✅ Dữ liệu không có outliers\n",
    "- ✅ Cần khoảng giá trị [0,1]\n",
    "- ✅ Neural networks\n",
    "\n",
    "**StandardScaler:**\n",
    "- ✅ Dữ liệu có phân phối chuẩn\n",
    "- ✅ Machine learning algorithms\n",
    "- ✅ Cần mean=0, std=1\n",
    "\n",
    "**RobustScaler:**\n",
    "- ✅ Dữ liệu có outliers\n",
    "- ✅ Cần tính robust\n",
    "- ✅ Dữ liệu không chuẩn\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27c281",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8cddba",
   "metadata": {},
   "source": [
    "#### **Phương pháp 1: Loại bỏ dữ liệu thiếu (`dropna`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b627f4",
   "metadata": {},
   "source": [
    "Phương thức `dropna()` cho phép loại bỏ các hàng hoặc cột có dữ liệu thiếu:\n",
    "\n",
    "**📋 Các tham số quan trọng của `dropna()`:**\n",
    "\n",
    "| Tham số | Giá trị | Mô tả |\n",
    "|---------|---------|-------|\n",
    "| `axis` | 0 (default) / 1 | 0: loại bỏ hàng, 1: loại bỏ cột |\n",
    "| `how` | 'any' (default) / 'all' | 'any': có ít nhất 1 NaN, 'all': toàn bộ là NaN |\n",
    "| `subset` | list | Chỉ xét dữ liệu thiếu trong các cột được chỉ định |\n",
    "| `thresh` | int | Số lượng giá trị không null tối thiểu cần có |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8d8b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame với dữ liệu thiếu:\n",
      "    Tên  Tuổi       Lương  Phòng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  Bình   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN       None\n",
      "3  Dũng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "1. Loại bỏ hàng có dữ liệu thiếu (how='any'):\n",
      "    Tên  Tuổi       Lương Phòng ban\n",
      "0    An  25.0  15000000.0        IT\n",
      "3  Dũng  28.0  22000000.0        IT\n",
      "Số hàng còn lại: 2\n",
      "2. Loại bỏ hàng khi tất cả giá trị đều thiếu (how='all'):\n",
      "    Tên  Tuổi       Lương  Phòng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  Bình   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN       None\n",
      "3  Dũng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "Số hàng còn lại: 5\n",
      "3. Loại bỏ cột có dữ liệu thiếu (axis=1):\n",
      "    Tên\n",
      "0    An\n",
      "1  Bình\n",
      "2   Chi\n",
      "3  Dũng\n",
      "4   Eva\n",
      "Số cột còn lại: 1\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu với dữ liệu thiếu\n",
    "data_missing = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Tuổi': [25, None, 30, 28, None],\n",
    "    'Lương': [15000000, 18000000, None, 22000000, 16000000],\n",
    "    'Phòng ban': ['IT', 'Marketing', None, 'IT', 'Marketing']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data_missing)\n",
    "print(\"DataFrame với dữ liệu thiếu:\")\n",
    "print(df_missing)\n",
    "\n",
    "# 1. Loại bỏ tất cả hàng có ít nhất 1 giá trị thiếu\n",
    "print(\"1. Loại bỏ hàng có dữ liệu thiếu (how='any'):\")\n",
    "df_drop_any = df_missing.dropna()\n",
    "print(df_drop_any)\n",
    "print(f\"Số hàng còn lại: {len(df_drop_any)}\")\n",
    "\n",
    "# 2. Loại bỏ hàng chỉ khi TẤT CẢ giá trị đều thiếu\n",
    "print(\"2. Loại bỏ hàng khi tất cả giá trị đều thiếu (how='all'):\")\n",
    "df_drop_all = df_missing.dropna(how='all')\n",
    "print(df_drop_all)\n",
    "print(f\"Số hàng còn lại: {len(df_drop_all)}\")\n",
    "\n",
    "# 3. Loại bỏ cột có dữ liệu thiếu\n",
    "print(\"3. Loại bỏ cột có dữ liệu thiếu (axis=1):\")\n",
    "df_drop_cols = df_missing.dropna(axis=1)\n",
    "print(df_drop_cols)\n",
    "print(f\"Số cột còn lại: {len(df_drop_cols.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee315f8",
   "metadata": {},
   "source": [
    "#### **Phương pháp 2: Thay thế dữ liệu thiếu (`fillna`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff3235",
   "metadata": {},
   "source": [
    "Phương thức `fillna()` cho phép **thay thế dữ liệu thiếu** bằng các giá trị cụ thể:\n",
    "\n",
    "**🔧 Các chiến lược thay thế phổ biến:**\n",
    "\n",
    "| Chiến lược | Ứng dụng | Ví dụ |\n",
    "|------------|----------|-------|\n",
    "| **Giá trị cố định** | Thay thế bằng một giá trị nhất định | `fillna(0)`, `fillna('Unknown')` |\n",
    "| **Giá trị trung bình** | Dữ liệu số, phân phối chuẩn | `fillna(df['col'].mean())` |\n",
    "| **Giá trị trung vị** | Dữ liệu số, có outliers | `fillna(df['col'].median())` |\n",
    "| **Giá trị phổ biến nhất** | Dữ liệu phân loại | `fillna(df['col'].mode()[0])` |\n",
    "| **Forward fill** | Dữ liệu chuỗi thời gian | `fillna(method='ffill')` |\n",
    "| **Backward fill** | Dữ liệu chuỗi thời gian | `fillna(method='bfill')` |\n",
    "\n",
    "**📊 Hãy xem các ví dụ cụ thể:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d63477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame với dữ liệu thiếu:\n",
      "    Tên  Tuổi       Lương  Phòng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  Bình   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN       None\n",
      "3  Dũng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "\n",
      "1. Thay thế bằng giá trị cố định:\n",
      "    Tên  Tuổi       Lương      Phòng ban\n",
      "0    An  25.0  15000000.0             IT\n",
      "1  Bình   0.0  18000000.0      Marketing\n",
      "2   Chi  30.0         0.0  Chưa xác định\n",
      "3  Dũng  28.0  22000000.0             IT\n",
      "4   Eva   0.0  16000000.0      Marketing\n",
      "\n",
      "2. Thay thế bằng giá trị trung bình:\n",
      "    Tên       Tuổi       Lương  Phòng ban\n",
      "0    An  25.000000  15000000.0         IT\n",
      "1  Bình  27.666667  18000000.0  Marketing\n",
      "2   Chi  30.000000  17750000.0       None\n",
      "3  Dũng  28.000000  22000000.0         IT\n",
      "4   Eva  27.666667  16000000.0  Marketing\n",
      "Tuổi trung bình: 27.7\n",
      "Lương trung bình: 17,750,000\n",
      "\n",
      "3. Thay thế bằng giá trị trung vị:\n",
      "    Tên  Tuổi       Lương  Phòng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  Bình  28.0  18000000.0  Marketing\n",
      "2   Chi  30.0  17000000.0       None\n",
      "3  Dũng  28.0  22000000.0         IT\n",
      "4   Eva  28.0  16000000.0  Marketing\n",
      "\n",
      "4. Thay thế bằng giá trị phổ biến nhất (mode):\n",
      "    Tên  Tuổi       Lương  Phòng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  Bình   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN         IT\n",
      "3  Dũng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "Phòng ban phổ biến nhất: IT\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu với dữ liệu thiếu\n",
    "data_missing = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Tuổi': [25, None, 30, 28, None],\n",
    "    'Lương': [15000000, 18000000, None, 22000000, 16000000],\n",
    "    'Phòng ban': ['IT', 'Marketing', None, 'IT', 'Marketing']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data_missing)\n",
    "print(\"DataFrame với dữ liệu thiếu:\")\n",
    "print(df_missing)\n",
    "\n",
    "# 1. Thay thế bằng giá trị cố định\n",
    "print(\"\\n1. Thay thế bằng giá trị cố định:\")\n",
    "df_fill_fixed = df_missing.fillna({'Tuổi': 0, 'Lương': 0, 'Phòng ban': 'Chưa xác định'})\n",
    "print(df_fill_fixed)\n",
    "\n",
    "# 2. Thay thế bằng giá trị trung bình (cho dữ liệu số)\n",
    "print(\"\\n2. Thay thế bằng giá trị trung bình:\")\n",
    "df_fill_mean = df_missing.copy()\n",
    "df_fill_mean['Tuổi'] = df_fill_mean['Tuổi'].fillna(df_fill_mean['Tuổi'].mean())\n",
    "df_fill_mean['Lương'] = df_fill_mean['Lương'].fillna(df_fill_mean['Lương'].mean())\n",
    "print(df_fill_mean)\n",
    "print(f\"Tuổi trung bình: {df_missing['Tuổi'].mean():.1f}\")\n",
    "print(f\"Lương trung bình: {df_missing['Lương'].mean():,.0f}\")\n",
    "\n",
    "# 3. Thay thế bằng giá trị trung vị (bền vững với outliers)\n",
    "print(\"\\n3. Thay thế bằng giá trị trung vị:\")\n",
    "df_fill_median = df_missing.copy()\n",
    "df_fill_median['Tuổi'] = df_fill_median['Tuổi'].fillna(df_fill_median['Tuổi'].median())\n",
    "df_fill_median['Lương'] = df_fill_median['Lương'].fillna(df_fill_median['Lương'].median())\n",
    "print(df_fill_median)\n",
    "\n",
    "# 4. Thay thế bằng giá trị phổ biến nhất (mode) - cho dữ liệu phân loại\n",
    "print(\"\\n4. Thay thế bằng giá trị phổ biến nhất (mode):\")\n",
    "df_fill_mode = df_missing.copy()\n",
    "df_fill_mode['Phòng ban'] = df_fill_mode['Phòng ban'].fillna(df_fill_mode['Phòng ban'].mode()[0])\n",
    "print(df_fill_mode)\n",
    "print(f\"Phòng ban phổ biến nhất: {df_missing['Phòng ban'].mode()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff8a4a",
   "metadata": {},
   "source": [
    "#### Phương pháp 3: Sử dụng mô hình dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68faa286",
   "metadata": {},
   "source": [
    "Sử dụng các mô hình **dự đoán** để ước lượng giá trị thiếu.\n",
    "\n",
    "**🔧 Các chiến lược thay thế phổ biến:**\n",
    "\n",
    "| Chiến lược | Ứng dụng | Ví dụ |\n",
    "|------------|----------|-------|\n",
    "| **Hồi quy** | Dữ liệu số | Sử dụng hồi quy tuyến tính để dự đoán giá trị |\n",
    "| **Phân loại** | Dữ liệu phân loại | Sử dụng cây quyết định để phân loại giá trị |\n",
    "| **Phân tích thống kê** | Dữ liệu số | Sử dụng thống kê để dự đoán giá trị |\n",
    "\n",
    "**📊 Hãy xem các ví dụ cụ thể:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b53ebe",
   "metadata": {},
   "source": [
    "**🤖 Khi nào sử dụng Machine Learning cho Missing Values:**\n",
    "\n",
    "- **Dữ liệu có mối quan hệ phức tạp**: Các biến có correlation cao với nhau\n",
    "- **Dữ liệu missing không ngẫu nhiên**: Missing data có pattern đặc biệt\n",
    "- **Dữ liệu quan trọng**: Không muốn mất thông tin bằng cách loại bỏ\n",
    "- **Yêu cầu độ chính xác cao**: Muốn dự đoán chính xác nhất có thể\n",
    "\n",
    "**⚡ Các kỹ thuật Machine Learning phổ biến:**\n",
    "\n",
    "- **Regression**: Dự đoán giá trị số (Linear, Random Forest, XGBoost)\n",
    "- **Classification**: Dự đoán giá trị phân loại (Decision Tree, SVM)\n",
    "- **Clustering**: Nhóm các quan sát tương tự (K-Means, DBSCAN)\n",
    "- **Deep Learning**: Neural Networks cho dữ liệu phức tạp\n",
    "\n",
    "**🎯 Ưu điểm và nhược điểm:**\n",
    "\n",
    "✅ **Ưu điểm:**\n",
    "- Độ chính xác cao hơn mean/median/mode\n",
    "- Tận dụng được mối quan hệ giữa các biến\n",
    "- Linh hoạt với nhiều loại dữ liệu\n",
    "\n",
    "❌ **Nhược điểm:**\n",
    "- Phức tạp, cần hiểu biết về ML\n",
    "- Tốn thời gian training\n",
    "- Có thể overfitting nếu không cẩn thận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf2cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Tạo dữ liệu mẫu cho các ví dụ Machine Learning:\n",
      "Dữ liệu gốc:\n",
      "     Tên  Tuổi       Lương  Phòng ban  Kinh nghiệm\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   Bình   NaN  18000000.0  Marketing            5\n",
      "2    Chi  30.0         NaN       None            7\n",
      "3   Dũng  28.0  22000000.0         IT            3\n",
      "4    Eva   NaN  16000000.0  Marketing            1\n",
      "5  Phong  35.0         NaN         IT           10\n",
      "6  Giang   NaN  25000000.0         HR            8\n",
      "7    Hoa  32.0         NaN         HR            6\n",
      "\n",
      "📈 Tỷ lệ missing data:\n",
      "Tuổi         37.5\n",
      "Lương        37.5\n",
      "Phòng ban    12.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết cho machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu với dữ liệu thiếu phức tạp hơn\n",
    "print(\"📊 Tạo dữ liệu mẫu cho các ví dụ Machine Learning:\")\n",
    "\n",
    "data_advanced = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva', 'Phong', 'Giang', 'Hoa'],\n",
    "    'Tuổi': [25, None, 30, 28, None, 35, None, 32],\n",
    "    'Lương': [15000000, 18000000, None, 22000000, 16000000, None, 25000000, None],\n",
    "    'Phòng ban': ['IT', 'Marketing', None, 'IT', 'Marketing', 'IT', 'HR', 'HR'],\n",
    "    'Kinh nghiệm': [2, 5, 7, 3, 1, 10, 8, 6]\n",
    "}\n",
    "\n",
    "df_advanced = pd.DataFrame(data_advanced)\n",
    "print(\"Dữ liệu gốc:\")\n",
    "print(df_advanced)\n",
    "print(f\"\\n📈 Tỷ lệ missing data:\")\n",
    "missing_percent = (df_advanced.isnull().sum() / len(df_advanced)) * 100\n",
    "print(missing_percent[missing_percent > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd93f66",
   "metadata": {},
   "source": [
    "#### **A. Random Forest Regression - Dự đoán giá trị số**\n",
    "\n",
    "**🌲 Random Forest là gì?**\n",
    "\n",
    "Random Forest là thuật toán **ensemble learning** kết hợp nhiều **Decision Trees**:\n",
    "\n",
    "- **Ensemble**: Kết hợp nhiều mô hình yếu thành một mô hình mạnh\n",
    "- **Bootstrap Aggregating**: Mỗi tree được train trên một subset ngẫu nhiên của dữ liệu\n",
    "- **Feature Randomness**: Mỗi split chỉ xét một subset ngẫu nhiên của features\n",
    "- **Voting**: Kết quả cuối cùng là trung bình của tất cả trees (regression) hoặc vote đa số (classification)\n",
    "\n",
    "**🎯 Ưu điểm của Random Forest:**\n",
    "- **Robust**: Ít bị overfitting nhờ averaging nhiều trees\n",
    "- **Handle Missing Values**: Có thể xử lý missing values trong quá trình training\n",
    "- **Feature Importance**: Cung cấp thông tin về tầm quan trọng của từng feature\n",
    "- **Non-linear**: Có thể học được các mối quan hệ phi tuyến phức tạp\n",
    "\n",
    "**⚙️ Các tham số quan trọng:**\n",
    "- `n_estimators`: Số lượng trees (default=100)\n",
    "- `max_depth`: Độ sâu tối đa của tree\n",
    "- `min_samples_split`: Số sample tối thiểu để split node\n",
    "- `random_state`: Seed cho reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf59cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 DEMO 1: Dự đoán Tuổi dựa trên Lương, Phòng ban và Kinh nghiệm\n",
      "======================================================================\n",
      "📋 Mapping Phòng ban:\n",
      "{'HR': 0, 'IT': 1, 'Marketing': 2, 'Unknown': 3}\n",
      "\n",
      "📊 Dữ liệu train: 5 samples\n",
      "📊 Dữ liệu cần dự đoán: 3 samples\n",
      "\n",
      "🔧 Features sử dụng: ['Lương', 'Phòng ban_encoded', 'Kinh nghiệm']\n",
      "📈 Training data:\n",
      "        Lương  Phòng ban_encoded  Kinh nghiệm\n",
      "0  15000000.0                  1            2\n",
      "2         0.0                  3            7\n",
      "3  22000000.0                  1            3\n",
      "5         0.0                  1           10\n",
      "7         0.0                  0            6\n",
      "\n",
      "🎯 Target (Tuổi):\n",
      "[25. 30. 28. 35. 32.]\n",
      "\n",
      "🔮 Dự đoán cho 3 samples:\n",
      "   Bình: 28.9 tuổi\n",
      "   Eva: 26.2 tuổi\n",
      "   Giang: 29.3 tuổi\n",
      "\n",
      "✅ Kết quả cuối cùng:\n",
      "     Tên  Tuổi       Lương  Phòng ban  Kinh nghiệm\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   Bình  28.9  18000000.0  Marketing            5\n",
      "2    Chi  30.0         NaN       None            7\n",
      "3   Dũng  28.0  22000000.0         IT            3\n",
      "4    Eva  26.2  16000000.0  Marketing            1\n",
      "5  Phong  35.0         NaN         IT           10\n",
      "6  Giang  29.3  25000000.0         HR            8\n",
      "7    Hoa  32.0         NaN         HR            6\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 DEMO 1: Dự đoán Tuổi dựa trên Lương, Phòng ban và Kinh nghiệm\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Bước 1: Chuẩn bị dữ liệu\n",
    "df_predict_age = df_advanced.copy()\n",
    "\n",
    "# Encode categorical data (Phòng ban)\n",
    "le_dept = LabelEncoder()\n",
    "df_predict_age['Phòng ban_encoded'] = le_dept.fit_transform(df_predict_age['Phòng ban'].fillna('Unknown'))\n",
    "\n",
    "print(\"📋 Mapping Phòng ban:\")\n",
    "dept_mapping = dict(zip(le_dept.classes_, le_dept.transform(le_dept.classes_)))\n",
    "print(dept_mapping)\n",
    "\n",
    "# Bước 2: Tách dữ liệu train và missing\n",
    "train_data = df_predict_age[df_predict_age['Tuổi'].notna()]\n",
    "missing_data = df_predict_age[df_predict_age['Tuổi'].isna()]\n",
    "\n",
    "print(f\"\\n📊 Dữ liệu train: {len(train_data)} samples\")\n",
    "print(f\"📊 Dữ liệu cần dự đoán: {len(missing_data)} samples\")\n",
    "\n",
    "if len(train_data) > 0 and len(missing_data) > 0:\n",
    "    # Bước 3: Chuẩn bị features và target\n",
    "    features = ['Lương', 'Phòng ban_encoded', 'Kinh nghiệm']\n",
    "    X_train = train_data[features].fillna(0)  # Fillna tạm thời cho missing features\n",
    "    y_train = train_data['Tuổi']\n",
    "    \n",
    "    print(f\"\\n🔧 Features sử dụng: {features}\")\n",
    "    print(\"📈 Training data:\")\n",
    "    print(X_train)\n",
    "    print(f\"\\n🎯 Target (Tuổi):\")\n",
    "    print(y_train.values)\n",
    "    \n",
    "    # Bước 4: Training model\n",
    "    model_age = RandomForestRegressor(n_estimators=10, random_state=42, max_depth=3)\n",
    "    model_age.fit(X_train, y_train)\n",
    "    \n",
    "    # Bước 5: Dự đoán\n",
    "    X_missing = missing_data[features].fillna(0)\n",
    "    predicted_ages = model_age.predict(X_missing)\n",
    "    \n",
    "    print(f\"\\n🔮 Dự đoán cho {len(missing_data)} samples:\")\n",
    "    for i, (idx, row) in enumerate(missing_data.iterrows()):\n",
    "        print(f\"   {row['Tên']}: {predicted_ages[i]:.1f} tuổi\")\n",
    "    \n",
    "    # Bước 6: Cập nhật dữ liệu\n",
    "    df_predict_age.loc[df_predict_age['Tuổi'].isna(), 'Tuổi'] = predicted_ages\n",
    "    \n",
    "    print(f\"\\n✅ Kết quả cuối cùng:\")\n",
    "    print(df_predict_age[['Tên', 'Tuổi', 'Lương', 'Phòng ban', 'Kinh nghiệm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abcf633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 DEMO 2: Dự đoán Lương dựa trên Tuổi, Phòng ban và Kinh nghiệm\n",
      "======================================================================\n",
      "📊 Dữ liệu train: 5 samples\n",
      "📊 Dữ liệu cần dự đoán: 3 samples\n",
      "\n",
      "🔧 Features sử dụng: ['Tuổi', 'Phòng ban_encoded', 'Kinh nghiệm']\n",
      "📈 Training data:\n",
      "   Tuổi  Phòng ban_encoded  Kinh nghiệm       Lương\n",
      "0  25.0                  1            2  15000000.0\n",
      "1   0.0                  2            5  18000000.0\n",
      "3  28.0                  1            3  22000000.0\n",
      "4   0.0                  2            1  16000000.0\n",
      "6   0.0                  0            8  25000000.0\n",
      "\n",
      "📊 Feature Importance:\n",
      "   Tuổi: 0.140\n",
      "   Phòng ban_encoded: 0.380\n",
      "   Kinh nghiệm: 0.480\n",
      "\n",
      "🔮 Dự đoán lương:\n",
      "   Chi: 20,300,000 VND\n",
      "   Phong: 23,100,000 VND\n",
      "   Hoa: 21,800,000 VND\n",
      "\n",
      "✅ Kết quả cuối cùng:\n",
      "     Tên  Tuổi       Lương  Phòng ban  Kinh nghiệm\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   Bình   NaN  18000000.0  Marketing            5\n",
      "2    Chi  30.0  20300000.0       None            7\n",
      "3   Dũng  28.0  22000000.0         IT            3\n",
      "4    Eva   NaN  16000000.0  Marketing            1\n",
      "5  Phong  35.0  23100000.0         IT           10\n",
      "6  Giang   NaN  25000000.0         HR            8\n",
      "7    Hoa  32.0  21800000.0         HR            6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🎯 DEMO 2: Dự đoán Lương dựa trên Tuổi, Phòng ban và Kinh nghiệm\") \n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sử dụng dữ liệu gốc (chưa có Tuổi được dự đoán)\n",
    "df_predict_salary = df_advanced.copy()\n",
    "df_predict_salary['Phòng ban_encoded'] = le_dept.fit_transform(df_predict_salary['Phòng ban'].fillna('Unknown'))\n",
    "\n",
    "# Tách dữ liệu train và missing cho Lương\n",
    "train_salary = df_predict_salary[df_predict_salary['Lương'].notna()]\n",
    "missing_salary = df_predict_salary[df_predict_salary['Lương'].isna()]\n",
    "\n",
    "print(f\"📊 Dữ liệu train: {len(train_salary)} samples\")\n",
    "print(f\"📊 Dữ liệu cần dự đoán: {len(missing_salary)} samples\")\n",
    "\n",
    "if len(train_salary) > 0 and len(missing_salary) > 0:\n",
    "    # Features cho dự đoán lương\n",
    "    salary_features = ['Tuổi', 'Phòng ban_encoded', 'Kinh nghiệm'] \n",
    "    X_train_salary = train_salary[salary_features].fillna(0)\n",
    "    y_train_salary = train_salary['Lương']\n",
    "    \n",
    "    print(f\"\\n🔧 Features sử dụng: {salary_features}\")\n",
    "    print(\"📈 Training data:\")\n",
    "    combined_train = pd.concat([X_train_salary, y_train_salary], axis=1)\n",
    "    print(combined_train)\n",
    "    \n",
    "    # Training model cho lương\n",
    "    model_salary = RandomForestRegressor(n_estimators=10, random_state=42, max_depth=3)\n",
    "    model_salary.fit(X_train_salary, y_train_salary)\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = model_salary.feature_importances_\n",
    "    print(f\"\\n📊 Feature Importance:\")\n",
    "    for feature, imp in zip(salary_features, importance):\n",
    "        print(f\"   {feature}: {imp:.3f}\")\n",
    "    \n",
    "    # Dự đoán lương\n",
    "    X_missing_salary = missing_salary[salary_features].fillna(0)\n",
    "    predicted_salaries = model_salary.predict(X_missing_salary)\n",
    "    \n",
    "    print(f\"\\n🔮 Dự đoán lương:\")\n",
    "    for i, (idx, row) in enumerate(missing_salary.iterrows()):\n",
    "        print(f\"   {row['Tên']}: {predicted_salaries[i]:,.0f} VND\")\n",
    "    \n",
    "    # Cập nhật dữ liệu\n",
    "    df_predict_salary.loc[df_predict_salary['Lương'].isna(), 'Lương'] = predicted_salaries\n",
    "    \n",
    "    print(f\"\\n✅ Kết quả cuối cùng:\")\n",
    "    print(df_predict_salary[['Tên', 'Tuổi', 'Lương', 'Phòng ban', 'Kinh nghiệm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487b44c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 TÓM TẮT PHẦN 1: XỬ LÝ DỮ LIỆU THIẾU\n",
    "\n",
    "### ✅ Kiến thức đã học:\n",
    "1. ✅ Phát hiện missing data với `.isna()` và `.isnull()`\n",
    "2. ✅ Loại bỏ với `.dropna(how='any'/'all', axis=0/1)`\n",
    "3. ✅ Thay thế với `.fillna(value/method/dict)`\n",
    "4. ✅ Dự đoán với Random Forest và KNN Imputer\n",
    "\n",
    "### 🔑 Hàm quan trọng:\n",
    "| Hàm | Mục đích | Ví dụ |\n",
    "|-----|----------|-------|\n",
    "| `.isna().sum()` | Đếm missing | `df.isna().sum()` |\n",
    "| `.dropna()` | Loại bỏ | `df.dropna(how='any')` |\n",
    "| `.fillna()` | Thay thế | `df.fillna(0)` |\n",
    "\n",
    "### ⚠️ Lỗi thường gặp:\n",
    "❌ Quên kiểm tra tỷ lệ missing trước khi dropna  \n",
    "❌ Dùng mean cho dữ liệu có outliers  \n",
    "❌ Fillna không specify `inplace=True`\n",
    "\n",
    "### 💡 Tips:\n",
    "- Luôn kiểm tra `df.isna().sum()` trước\n",
    "- Dùng median cho dữ liệu có outliers\n",
    "- Save a copy trước khi drop data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b745f",
   "metadata": {},
   "source": [
    "#### **B. KNN Imputation - K-Nearest Neighbors**\n",
    "\n",
    "**🔍 KNN Imputation là gì?**\n",
    "\n",
    "KNN Imputation sử dụng thuật toán **K-Nearest Neighbors** để điền missing values:\n",
    "\n",
    "1. **Tìm K neighbors gần nhất**: Dựa trên khoảng cách Euclidean trong không gian features\n",
    "2. **Tính giá trị trung bình**: Lấy trung bình của K neighbors (cho số) hoặc mode (cho categorical)\n",
    "3. **Điền vào missing values**: Thay thế missing value bằng giá trị được tính\n",
    "\n",
    "**📏 Công thức khoảng cách Euclidean:**\n",
    "\n",
    "$$d(x_i, x_j) = \\sqrt{\\sum_{k=1}^{n} (x_{ik} - x_{jk})^2}$$\n",
    "\n",
    "**🎯 Ưu điểm của KNN Imputation:**\n",
    "- **Preserve relationships**: Giữ nguyên mối quan hệ giữa các features\n",
    "- **Non-parametric**: Không giả định về phân phối dữ liệu\n",
    "- **Local patterns**: Tận dụng patterns cục bộ trong dữ liệu\n",
    "- **Multivariate**: Xem xét tất cả features cùng lúc\n",
    "\n",
    "**⚙️ Các tham số quan trọng:**\n",
    "- `n_neighbors`: Số lượng neighbors (default=5)\n",
    "- `weights`: 'uniform' hoặc 'distance' weighted\n",
    "- `metric`: Phương pháp tính distance ('nan_euclidean' cho missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0062f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 DEMO 3: KNN Imputation - Điền tất cả missing values cùng lúc\n",
      "======================================================================\n",
      "📊 Dữ liệu trước KNN Imputation:\n",
      "     Tên  Tuổi       Lương  Phòng ban  Kinh nghiệm\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   Bình   NaN  18000000.0  Marketing            5\n",
      "2    Chi  30.0         NaN       None            7\n",
      "3   Dũng  28.0  22000000.0         IT            3\n",
      "4    Eva   NaN  16000000.0  Marketing            1\n",
      "5  Phong  35.0         NaN         IT           10\n",
      "6  Giang   NaN  25000000.0         HR            8\n",
      "7    Hoa  32.0         NaN         HR            6\n",
      "\n",
      "🔧 Các cột số được sử dụng: ['Tuổi', 'Lương', 'Kinh nghiệm', 'Phòng ban_encoded']\n",
      "📈 Ma trận dữ liệu số (có missing values):\n",
      "   Tuổi       Lương  Kinh nghiệm  Phòng ban_encoded\n",
      "0  25.0  15000000.0            2                  1\n",
      "1   NaN  18000000.0            5                  2\n",
      "2  30.0         NaN            7                  3\n",
      "3  28.0  22000000.0            3                  1\n",
      "4   NaN  16000000.0            1                  2\n",
      "5  35.0         NaN           10                  1\n",
      "6   NaN  25000000.0            8                  0\n",
      "7  32.0         NaN            6                  0\n",
      "\n",
      "📊 Missing Data Pattern:\n",
      "    Tuổi  Lương  Kinh nghiệm  Phòng ban_encoded\n",
      "0  False  False        False              False\n",
      "1   True  False        False              False\n",
      "2  False   True        False              False\n",
      "3  False  False        False              False\n",
      "4   True  False        False              False\n",
      "5  False   True        False              False\n",
      "6   True  False        False              False\n",
      "7  False   True        False              False\n",
      "\n",
      "🤖 Áp dụng KNN Imputation với k=2 neighbors:\n",
      "\n",
      "✅ Kết quả sau KNN Imputation:\n",
      "     Tên  Tuổi       Lương  Phòng ban  Kinh nghiệm\n",
      "0     An  25.0  15000000.0         IT          2.0\n",
      "1   Bình  31.0  18000000.0  Marketing          5.0\n",
      "2    Chi  30.0  21500000.0       None          7.0\n",
      "3   Dũng  28.0  22000000.0         IT          3.0\n",
      "4    Eva  31.0  16000000.0  Marketing          1.0\n",
      "5  Phong  35.0  21500000.0         IT         10.0\n",
      "6  Giang  33.5  25000000.0         HR          8.0\n",
      "7    Hoa  32.0  21500000.0         HR          6.0\n",
      "\n",
      "📊 So sánh Missing Values:\n",
      "Trước: 6 missing values\n",
      "Sau: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 DEMO 3: KNN Imputation - Điền tất cả missing values cùng lúc\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Chuẩn bị dữ liệu cho KNN\n",
    "df_knn = df_advanced.copy()\n",
    "print(\"📊 Dữ liệu trước KNN Imputation:\")\n",
    "print(df_knn)\n",
    "\n",
    "# Encode categorical data\n",
    "df_knn['Phòng ban_encoded'] = le_dept.fit_transform(df_knn['Phòng ban'].fillna('Unknown'))\n",
    "\n",
    "# Chỉ lấy các cột số cho KNN Imputation\n",
    "numerical_cols = ['Tuổi', 'Lương', 'Kinh nghiệm', 'Phòng ban_encoded']\n",
    "df_numerical = df_knn[numerical_cols].copy()\n",
    "\n",
    "print(f\"\\n🔧 Các cột số được sử dụng: {numerical_cols}\")\n",
    "print(\"📈 Ma trận dữ liệu số (có missing values):\")\n",
    "print(df_numerical)\n",
    "\n",
    "# Hiển thị missing pattern\n",
    "print(f\"\\n📊 Missing Data Pattern:\")\n",
    "missing_pattern = df_numerical.isnull()\n",
    "print(missing_pattern)\n",
    "\n",
    "# Áp dụng KNN Imputation\n",
    "print(f\"\\n🤖 Áp dụng KNN Imputation với k=2 neighbors:\")\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "df_knn_filled = knn_imputer.fit_transform(df_numerical)\n",
    "\n",
    "# Chuyển đổi lại thành DataFrame  \n",
    "df_knn_result = df_knn.copy()\n",
    "df_knn_result['Tuổi'] = df_knn_filled[:, 0]\n",
    "df_knn_result['Lương'] = df_knn_filled[:, 1] \n",
    "df_knn_result['Kinh nghiệm'] = df_knn_filled[:, 2]\n",
    "\n",
    "print(f\"\\n✅ Kết quả sau KNN Imputation:\")\n",
    "result_display = df_knn_result[['Tên', 'Tuổi', 'Lương', 'Phòng ban', 'Kinh nghiệm']].copy()\n",
    "result_display['Tuổi'] = result_display['Tuổi'].round(1)\n",
    "result_display['Lương'] = result_display['Lương'].round(0)\n",
    "print(result_display)\n",
    "\n",
    "# So sánh missing values trước và sau\n",
    "print(f\"\\n📊 So sánh Missing Values:\")\n",
    "print(f\"Trước: {df_knn[numerical_cols[:-1]].isnull().sum().sum()} missing values\")\n",
    "print(f\"Sau: {pd.DataFrame(df_knn_filled[:, :-1]).isnull().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd82704",
   "metadata": {},
   "source": [
    "#### **C. So sánh các phương pháp xử lý Missing Values**\n",
    "\n",
    "**📊 Bảng tổng hợp so sánh:**\n",
    "\n",
    "| Phương pháp | Độ phức tạp | Thời gian | Độ chính xác | Phù hợp với |\n",
    "|-------------|-------------|-----------|--------------|-------------|\n",
    "| **Mean/Median** | Thấp ⭐ | Nhanh ⚡⚡⚡ | Thấp 📊 | Dữ liệu đơn giản, missing ngẫu nhiên |\n",
    "| **Mode** | Thấp ⭐ | Nhanh ⚡⚡⚡ | Thấp 📊 | Categorical data với ít categories |\n",
    "| **Forward/Backward Fill** | Thấp ⭐ | Nhanh ⚡⚡⚡ | Trung bình 📊📊 | Time series data |\n",
    "| **Random Forest** | Cao ⭐⭐⭐ | Chậm ⚡ | Cao 📊📊📊 | Dữ liệu có quan hệ phức tạp |\n",
    "| **KNN Imputation** | Trung bình ⭐⭐ | Trung bình ⚡⚡ | Cao 📊📊📊 | Dữ liệu có local patterns |\n",
    "\n",
    "**🎯 Hướng dẫn lựa chọn phương pháp:**\n",
    "\n",
    "**📈 Dữ liệu số (Numerical):**\n",
    "- **< 5% missing**: Mean/Median\n",
    "- **5-20% missing + có correlation**: KNN hoặc Random Forest  \n",
    "- **> 20% missing**: Cân nhắc loại bỏ cột hoặc thu thập thêm dữ liệu\n",
    "\n",
    "**🏷️ Dữ liệu phân loại (Categorical):**\n",
    "- **< 10% missing**: Mode\n",
    "- **> 10% missing + có relationship**: Random Forest Classification\n",
    "- **High cardinality**: Tạo category \"Unknown\"\n",
    "\n",
    "**⏰ Dữ liệu thời gian (Time Series):**\n",
    "- **Forward fill**: Cho dữ liệu stable (giá cổ phiếu)\n",
    "- **Backward fill**: Cho dữ liệu có trend  \n",
    "- **Interpolation**: Cho dữ liệu smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372d7dc",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu trùng lặp (Duplicate Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77a20c",
   "metadata": {},
   "source": [
    "### Hiểu về dữ liệu trùng lặp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf5e95",
   "metadata": {},
   "source": [
    "**🔄 Dữ liệu trùng lặp là gì?**\n",
    "\n",
    "Dữ liệu trùng lặp (*duplicate data*) là những **hàng có giá trị giống hệt nhau** trên tất cả hoặc một số cột nhất định. Dữ liệu trùng lặp có thể xuất hiện do:\n",
    "\n",
    "- **Lỗi nhập liệu**: Người dùng vô tình nhập cùng một thông tin nhiều lần\n",
    "- **Lỗi hệ thống**: Hệ thống ghi nhận cùng một sự kiện nhiều lần  \n",
    "- **Gộp dữ liệu**: Khi kết hợp nhiều nguồn dữ liệu có thông tin chồng chéo\n",
    "- **Lỗi thu thập**: Cảm biến hoặc thiết bị ghi nhận dữ liệu bị lặp\n",
    "\n",
    "**⚠️ Tác động của dữ liệu trùng lặp**\n",
    "\n",
    "- **Thiên lệch phân tích**: Một quan sát được tính nhiều lần, làm méo mó kết quả\n",
    "- **Giảm hiệu quả tính toán**: Xử lý dữ liệu thừa làm chậm thuật toán\n",
    "- **Tăng kích thước dữ liệu**: Lãng phí bộ nhớ và không gian lưu trữ\n",
    "- **Ảnh hưởng mô hình**: Machine learning có thể học sai từ dữ liệu lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a749036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "3    Alice   25     New York\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo dữ liệu mẫu\n",
    "duplicate_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "    'age': [25, 30, 35, 25],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "duplicate_data = pd.DataFrame(duplicate_data)\n",
    "\n",
    "# In dữ liệu mẫu\n",
    "print(duplicate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed9e8f",
   "metadata": {},
   "source": [
    "### Các phương pháp phát hiện và xử lý dữ liệu trùng lặp trong pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9479d87",
   "metadata": {},
   "source": [
    "Pandas cung cấp các phương thức để phát hiện và xử lý dữ liệu trùng lặp:\n",
    "\n",
    "| Phương thức | Mô tả | Trả về |\n",
    "|-------------|-------|--------|\n",
    "| `duplicated()` | Kiểm tra từng hàng có bị trùng lặp không | Boolean Series |\n",
    "| `drop_duplicates()` | Loại bỏ các hàng trùng lặp | DataFrame không trùng lặp |\n",
    "\n",
    "**📊 Hãy xem cách sử dụng các phương thức này:**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bdb44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "3    Alice   25     New York\n",
      "Phát hiện duplicate rows:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "Các hàng bị duplicate:\n",
      "    name  age      city\n",
      "3  Alice   25  New York\n",
      "\n",
      "Đếm số lượng duplicate:\n",
      "Tổng số duplicate: 1\n",
      "\n",
      " Xử lý duplicate bằng cách loại bỏ:\n",
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo dữ liệu mẫu\n",
    "duplicate_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "    'age': [25, 30, 35, 25],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "duplicate_data = pd.DataFrame(duplicate_data)\n",
    "\n",
    "# In dữ liệu mẫu\n",
    "print(duplicate_data)\n",
    "\n",
    "# Phát hiện duplicate rows\n",
    "print(\"Phát hiện duplicate rows:\")\n",
    "print(duplicate_data.duplicated())\n",
    "\n",
    "print(\"\\nCác hàng bị duplicate:\")\n",
    "print(duplicate_data[duplicate_data.duplicated()])\n",
    "\n",
    "print(\"\\nĐếm số lượng duplicate:\")\n",
    "print(f\"Tổng số duplicate: {duplicate_data.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n Xử lý duplicate bằng cách loại bỏ:\")\n",
    "print(duplicate_data.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e951b8d",
   "metadata": {},
   "source": [
    "## Biến đổi và chuẩn hóa dữ liệu (Data Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b07aa",
   "metadata": {},
   "source": [
    "### Tổng quan về biến đổi dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449fd38",
   "metadata": {},
   "source": [
    "**🔄 Biến đổi dữ liệu là gì?**\n",
    "\n",
    "Biến đổi dữ liệu (*data transformation*) là quá trình **chuyển đổi dữ liệu** từ định dạng này sang định dạng khác để:\n",
    "\n",
    "- **Cải thiện chất lượng dữ liệu**: Làm cho dữ liệu phù hợp hơn cho phân tích\n",
    "- **Chuẩn hóa thang đo**: Đưa các biến về cùng một thang đo\n",
    "- **Giảm nhiễu**: Loại bỏ các biến động không mong muốn\n",
    "- **Tạo biến mới**: Kết hợp hoặc biến đổi biến hiện có để tạo thông tin mới\n",
    "\n",
    "**🎯 Các mục tiêu chính:**\n",
    "\n",
    "1. **Normalization**: Đưa dữ liệu về khoảng [0,1]\n",
    "2. **Standardization**: Đưa dữ liệu về phân phối chuẩn (mean=0, std=1) \n",
    "3. **Scaling**: Điều chỉnh thang đo cho phù hợp\n",
    "4. **Encoding**: Chuyển đổi dữ liệu phân loại thành số\n",
    "\n",
    "**📋 Khi nào cần biến đổi dữ liệu:**\n",
    "\n",
    "- Các biến có **đơn vị đo khác nhau** (VND, USD, kg, cm)\n",
    "- Dữ liệu có **phạm vi giá trị chênh lệch lớn** (1-10 vs 1000-10000)\n",
    "- Sử dụng **thuật toán nhạy cảm với thang đo** (KNN, SVM, Neural Networks)\n",
    "- **Cải thiện hiệu suất** của mô hình machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529a255",
   "metadata": {},
   "source": [
    "## 📊 DEMO: Tại sao cần chuẩn hóa dữ liệu?\n",
    "\n",
    "Trước khi học các phương pháp, hãy xem ví dụ thực tế:\n",
    "\n",
    "### 🏢 Ví dụ: Dữ liệu nhân viên công ty\n",
    "```\n",
    "Nhân viên A: Lương 15,000,000 VND, Tuổi 25, Kinh nghiệm 2 năm\n",
    "Nhân viên B: Lương 25,000,000 VND, Tuổi 35, Kinh nghiệm 8 năm\n",
    "```\n",
    "\n",
    "**❌ Vấn đề:** Thuật toán sẽ coi Lương quan trọng hơn vì giá trị lớn!\n",
    "\n",
    "**✅ Giải pháp:** Chuẩn hóa để đưa về cùng thang đo [0,1]\n",
    "\n",
    "---\n",
    "\n",
    "### Min-Max Normalization (Chuẩn hóa Min-Max)\n",
    "\n",
    "**📐 Công thức đơn giản:**\n",
    "```\n",
    "Giá trị mới = (Giá trị cũ - Min) / (Max - Min)\n",
    "```\n",
    "\n",
    "**🎯 Kết quả:** Tất cả giá trị nằm trong khoảng [0, 1]\n",
    "\n",
    "**✅ Ưu điểm:**\n",
    "- Dễ hiểu và tính toán\n",
    "- Bảo toàn phân phối gốc\n",
    "- Phù hợp với dữ liệu không có outliers\n",
    "\n",
    "**❌ Nhược điểm:**\n",
    "- Nhạy cảm với outliers (giá trị ngoại lai)\n",
    "- Nếu có giá trị rất lớn, các giá trị khác sẽ bị \"nén\" về gần 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05eac5",
   "metadata": {},
   "source": [
    "**📐 Công thức chi tiết:**\n",
    "\n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "**🔍 Giải thích từng phần:**\n",
    "- $X$ = giá trị gốc\n",
    "- $X_{min}$ = giá trị nhỏ nhất trong cột\n",
    "- $X_{max}$ = giá trị lớn nhất trong cột\n",
    "- Kết quả luôn nằm trong khoảng [0, 1]\n",
    "\n",
    "**📊 Ví dụ minh họa:**\n",
    "```\n",
    "Dữ liệu gốc: [10, 20, 30, 40, 50]\n",
    "Min = 10, Max = 50\n",
    "\n",
    "Giá trị 20 → (20-10)/(50-10) = 10/40 = 0.25\n",
    "Giá trị 40 → (40-10)/(50-10) = 30/40 = 0.75\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a39c847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 VÍ DỤ: Dữ liệu nhân viên công ty\n",
      "==================================================\n",
      "📋 Dữ liệu gốc:\n",
      "    Ten     Luong  Tuoi  KinhNghiem\n",
      "0    An  15000000    25           2\n",
      "1  Bình  25000000    35           8\n",
      "2   Chi  30000000    40          12\n",
      "3  Dũng  18000000    28           3\n",
      "4   Eva  22000000    32           6\n",
      "\n",
      "📊 Thống kê mô tả:\n",
      "              Luong      Tuoi  KinhNghiem\n",
      "count  5.000000e+00   5.00000    5.000000\n",
      "mean   2.200000e+07  32.00000    6.200000\n",
      "std    5.873670e+06   5.87367    4.024922\n",
      "min    1.500000e+07  25.00000    2.000000\n",
      "25%    1.800000e+07  28.00000    3.000000\n",
      "50%    2.200000e+07  32.00000    6.000000\n",
      "75%    2.500000e+07  35.00000    8.000000\n",
      "max    3.000000e+07  40.00000   12.000000\n",
      "\n",
      "🔧 Áp dụng Min-Max Normalization:\n",
      "✅ Kết quả sau chuẩn hóa:\n",
      "    Ten     Luong      Tuoi  KinhNghiem\n",
      "0    An  0.000000  0.000000         0.0\n",
      "1  Bình  0.666667  0.666667         0.6\n",
      "2   Chi  1.000000  1.000000         1.0\n",
      "3  Dũng  0.200000  0.200000         0.1\n",
      "4   Eva  0.466667  0.466667         0.4\n",
      "\n",
      "📈 So sánh trước và sau:\n",
      "Trước: Lương có giá trị từ 15M-30M, Tuổi từ 25-40\n",
      "Sau: Tất cả giá trị từ 0.0-1.0\n"
     ]
    }
   ],
   "source": [
    "# 📊 DEMO: Min-Max Normalization với dữ liệu thực tế\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo dữ liệu nhân viên với các thang đo khác nhau\n",
    "print(\"🏢 VÍ DỤ: Dữ liệu nhân viên công ty\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'Ten': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Luong': [15000000, 25000000, 30000000, 18000000, 22000000],  # VND/tháng\n",
    "    'Tuoi': [25, 35, 40, 28, 32],  # năm\n",
    "    'KinhNghiem': [2, 8, 12, 3, 6]  # năm\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"📋 Dữ liệu gốc:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\n📊 Thống kê mô tả:\")\n",
    "print(df_nhanvien[['Luong', 'Tuoi', 'KinhNghiem']].describe())\n",
    "\n",
    "# Áp dụng Min-Max Normalization\n",
    "print(f\"\\n🔧 Áp dụng Min-Max Normalization:\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Chuẩn hóa các cột số\n",
    "df_normalized = df_nhanvien.copy()\n",
    "df_normalized[['Luong', 'Tuoi', 'KinhNghiem']] = scaler.fit_transform(\n",
    "    df_nhanvien[['Luong', 'Tuoi', 'KinhNghiem']]\n",
    ")\n",
    "\n",
    "print(\"✅ Kết quả sau chuẩn hóa:\")\n",
    "print(df_normalized)\n",
    "\n",
    "print(f\"\\n📈 So sánh trước và sau:\")\n",
    "print(\"Trước: Lương có giá trị từ 15M-30M, Tuổi từ 25-40\")\n",
    "print(\"Sau: Tất cả giá trị từ 0.0-1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068c457",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 TÓM TẮT PHẦN 3: CHUẨN HÓA DỮ LIỆU\n",
    "\n",
    "### ✅ Kiến thức đã học:\n",
    "1. ✅ MinMaxScaler: Đưa dữ liệu về [0,1]\n",
    "2. ✅ StandardScaler: Mean=0, Std=1\n",
    "3. ✅ RobustScaler: Sử dụng median và IQR\n",
    "\n",
    "### 📊 So sánh các phương pháp Scaling:\n",
    "\n",
    "| Phương pháp | Khoảng giá trị | Ưu điểm | Nhược điểm | Khi nào dùng |\n",
    "|-------------|----------------|---------|------------|--------------|\n",
    "| **MinMaxScaler** | [0, 1] | Đơn giản, bảo toàn phân phối | Nhạy cảm với outliers | Dữ liệu không có outliers |\n",
    "| **StandardScaler** | Mean=0, Std=1 | Phù hợp với thuật toán tuyến tính | Vẫn bị ảnh hưởng bởi outliers | Dữ liệu có phân phối chuẩn |\n",
    "| **RobustScaler** | Median=0, IQR=1 | Bền vững với outliers | Phức tạp hơn | Dữ liệu có nhiều outliers |\n",
    "\n",
    "### ⚠️ Lỗi thường gặp:\n",
    "❌ Quên fit scaler trên training data trước khi transform  \n",
    "❌ Dùng MinMaxScaler cho dữ liệu có outliers  \n",
    "❌ Transform cả training và test data cùng lúc\n",
    "\n",
    "### 💡 Tips:\n",
    "- Luôn fit scaler trên training data\n",
    "- Dùng RobustScaler khi có outliers\n",
    "- Save scaler để transform test data sau\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978ba47",
   "metadata": {},
   "source": [
    "### Standard Scaler (Z-score Standardization)\n",
    "\n",
    "**📐 Công thức đơn giản:**\n",
    "```\n",
    "Giá trị mới = (Giá trị cũ - Trung bình) / Độ lệch chuẩn\n",
    "```\n",
    "\n",
    "**🎯 Kết quả:** Mean = 0, Standard Deviation = 1\n",
    "\n",
    "**✅ Ưu điểm:**\n",
    "- Không bị ảnh hưởng nhiều bởi outliers\n",
    "- Phù hợp với thuật toán tuyến tính (Linear Regression, Logistic Regression)\n",
    "- Bảo toàn thông tin về phân phối gốc\n",
    "\n",
    "**❌ Nhược điểm:**\n",
    "- Vẫn bị ảnh hưởng một phần bởi outliers\n",
    "- Phức tạp hơn Min-Max\n",
    "\n",
    "**📊 Ví dụ minh họa:**\n",
    "```\n",
    "Dữ liệu gốc: [10, 20, 30, 40, 50]\n",
    "Mean = 30, Std = 15.81\n",
    "\n",
    "Giá trị 20 → (20-30)/15.81 = -0.63\n",
    "Giá trị 40 → (40-30)/15.81 = 0.63\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce3d87",
   "metadata": {},
   "source": [
    "**📊 Công thức Z-score Standardization:**\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Trong đó:\n",
    "- $X$ = giá trị gốc\n",
    "- $\\mu$ = giá trị trung bình (mean)\n",
    "- $\\sigma$ = độ lệch chuẩn (standard deviation)\n",
    "\n",
    "**🎯 Đặc điểm:**\n",
    "- Đưa dữ liệu về **phân phối chuẩn** với mean=0, std=1\n",
    "- **Không bị ảnh hưởng** bởi outliers nhiều như Min-Max\n",
    "- **Bảo toàn thông tin** về phân phối gốc\n",
    "- Phù hợp với **các thuật toán giả định phân phối chuẩn** (Linear Regression, Logistic Regression)\n",
    "\n",
    "**🔧 Sử dụng `StandardScaler` từ scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01fb4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 VÍ DỤ: Standard Scaler với dữ liệu nhân viên\n",
      "=======================================================\n",
      "📋 Dữ liệu gốc:\n",
      "    Ten     Luong  Tuoi  KinhNghiem\n",
      "0    An  15000000    25           2\n",
      "1  Bình  25000000    35           8\n",
      "2   Chi  30000000    40          12\n",
      "3  Dũng  18000000    28           3\n",
      "4   Eva  22000000    32           6\n",
      "\n",
      "🔧 Áp dụng Standard Scaler:\n",
      "✅ Kết quả sau standardization:\n",
      "    Ten     Luong      Tuoi  KinhNghiem\n",
      "0    An -1.332427 -1.332427   -1.166667\n",
      "1  Bình  0.571040  0.571040    0.500000\n",
      "2   Chi  1.522774  1.522774    1.611111\n",
      "3  Dũng -0.761387 -0.761387   -0.888889\n",
      "4   Eva  0.000000  0.000000   -0.055556\n",
      "\n",
      "📊 Kiểm tra Mean và Std:\n",
      "Mean của các cột: [ 0. -0. -0.]\n",
      "Std của các cột: [1.118 1.118 1.118]\n",
      "✅ Mean ≈ 0, Std ≈ 1 (như mong đợi!)\n"
     ]
    }
   ],
   "source": [
    "# 📊 DEMO: Standard Scaler với dữ liệu thực tế\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sử dụng dữ liệu nhân viên từ ví dụ trước\n",
    "print(\"🏢 VÍ DỤ: Standard Scaler với dữ liệu nhân viên\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'Ten': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Luong': [15000000, 25000000, 30000000, 18000000, 22000000],\n",
    "    'Tuoi': [25, 35, 40, 28, 32],\n",
    "    'KinhNghiem': [2, 8, 12, 3, 6]\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"📋 Dữ liệu gốc:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "# Áp dụng Standard Scaler\n",
    "print(f\"\\n🔧 Áp dụng Standard Scaler:\")\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "df_standardized = df_nhanvien.copy()\n",
    "df_standardized[['Luong', 'Tuoi', 'KinhNghiem']] = scaler_std.fit_transform(\n",
    "    df_nhanvien[['Luong', 'Tuoi', 'KinhNghiem']]\n",
    ")\n",
    "\n",
    "print(\"✅ Kết quả sau standardization:\")\n",
    "print(df_standardized)\n",
    "\n",
    "# Kiểm tra mean ≈ 0 và std ≈ 1\n",
    "print(f\"\\n📊 Kiểm tra Mean và Std:\")\n",
    "print(\"Mean của các cột:\", df_standardized[['Luong', 'Tuoi', 'KinhNghiem']].mean().round(4).values)\n",
    "print(\"Std của các cột:\", df_standardized[['Luong', 'Tuoi', 'KinhNghiem']].std().round(4).values)\n",
    "print(\"✅ Mean ≈ 0, Std ≈ 1 (như mong đợi!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d372e",
   "metadata": {},
   "source": [
    "### Robust Scaler (Sử dụng Median và IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d20b9",
   "metadata": {},
   "source": [
    "**📈 Công thức Robust Scaling:**\n",
    "\n",
    "$$X_{robust} = \\frac{X - X_{median}}{IQR}$$\n",
    "\n",
    "Trong đó:\n",
    "- $X_{median}$ = giá trị trung vị (median)\n",
    "- $IQR$ = Interquartile Range = Q3 - Q1\n",
    "\n",
    "**🛡️ Đặc điểm:**\n",
    "- **Rất bền vững** (*robust*) trước outliers\n",
    "- Sử dụng **median thay vì mean**, **IQR thay vì std**\n",
    "- **Không bị méo** bởi các giá trị ngoại lai\n",
    "- Phù hợp khi dữ liệu có **nhiều outliers**\n",
    "\n",
    "**🎯 Khi nào sử dụng Robust Scaler:**\n",
    "- **Dữ liệu có nhiều outliers** \n",
    "- **Không muốn loại bỏ outliers** nhưng vẫn cần chuẩn hóa\n",
    "- **Dữ liệu không tuân theo phân phối chuẩn**\n",
    "\n",
    "**🔧 Sử dụng `RobustScaler` từ scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a796d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu có outliers:\n",
      "       Lương  Tuổi  Kinh nghiệm\n",
      "0   15000000    25            2\n",
      "1   25000000    35            8\n",
      "2   30000000    40           12\n",
      "3   18000000    28            3\n",
      "4   22000000    32            6\n",
      "5  200000000    22            1\n",
      "\n",
      "Mô tả thống kê:\n",
      "              Lương       Tuổi  Kinh nghiệm\n",
      "count  6.000000e+00   6.000000     6.000000\n",
      "mean   5.166667e+07  30.333333     5.333333\n",
      "std    7.285785e+07   6.653320     4.179314\n",
      "min    1.500000e+07  22.000000     1.000000\n",
      "25%    1.900000e+07  25.750000     2.250000\n",
      "50%    2.350000e+07  30.000000     4.500000\n",
      "75%    2.875000e+07  34.250000     7.500000\n",
      "max    2.000000e+08  40.000000    12.000000\n",
      "\n",
      "============================================================\n",
      "SO SÁNH CÁC PHƯƠNG PHÁP SCALING VỚI OUTLIERS\n",
      "============================================================\n",
      "\n",
      "1. MinMax Scaler (bị ảnh hưởng bởi outliers):\n",
      "      Lương      Tuổi  Kinh nghiệm\n",
      "0  0.000000  0.166667     0.090909\n",
      "1  0.054054  0.722222     0.636364\n",
      "2  0.081081  1.000000     1.000000\n",
      "3  0.016216  0.333333     0.181818\n",
      "4  0.037838  0.555556     0.454545\n",
      "5  1.000000  0.000000     0.000000\n",
      "\n",
      "2. Standard Scaler (bị ảnh hưởng một phần):\n",
      "      Lương      Tuổi  Kinh nghiệm\n",
      "0 -0.551297 -0.878114    -0.873704\n",
      "1 -0.400943  0.768350     0.698963\n",
      "2 -0.325766  1.591582     1.747408\n",
      "3 -0.506191 -0.384175    -0.611593\n",
      "4 -0.446049  0.274411     0.174741\n",
      "5  2.230247 -1.372053    -1.135815\n",
      "\n",
      "3. Robust Scaler (bền vững trước outliers):\n",
      "       Lương      Tuổi  Kinh nghiệm\n",
      "0  -0.871795 -0.588235    -0.476190\n",
      "1   0.153846  0.588235     0.666667\n",
      "2   0.666667  1.176471     1.428571\n",
      "3  -0.564103 -0.235294    -0.285714\n",
      "4  -0.153846  0.235294     0.285714\n",
      "5  18.102564 -0.941176    -0.666667\n"
     ]
    }
   ],
   "source": [
    "# Import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Tạo dữ liệu có outliers\n",
    "data_with_outliers = {\n",
    "    'Lương': [15000000, 25000000, 30000000, 18000000, 22000000, 200000000],  # outlier: 200M\n",
    "    'Tuổi': [25, 35, 40, 28, 32, 22],\n",
    "    'Kinh nghiệm': [2, 8, 12, 3, 6, 1]\n",
    "}\n",
    "\n",
    "df_outliers = pd.DataFrame(data_with_outliers)\n",
    "print(\"Dữ liệu có outliers:\")\n",
    "print(df_outliers)\n",
    "print(f\"\\nMô tả thống kê:\")\n",
    "print(df_outliers.describe())\n",
    "\n",
    "# So sánh 3 phương pháp scaling\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SO SÁNH CÁC PHƯƠNG PHÁP SCALING VỚI OUTLIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# MinMax Scaler (bị ảnh hưởng mạnh bởi outliers)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaled_minmax = scaler_minmax.fit_transform(df_outliers[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "print(\"\\n1. MinMax Scaler (bị ảnh hưởng bởi outliers):\")\n",
    "print(pd.DataFrame(scaled_minmax, columns=['Lương', 'Tuổi', 'Kinh nghiệm']))\n",
    "\n",
    "# Standard Scaler (bị ảnh hưởng một phần bởi outliers)\n",
    "scaler_std = StandardScaler()\n",
    "scaled_std = scaler_std.fit_transform(df_outliers[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "print(\"\\n2. Standard Scaler (bị ảnh hưởng một phần):\")\n",
    "print(pd.DataFrame(scaled_std, columns=['Lương', 'Tuổi', 'Kinh nghiệm']))\n",
    "\n",
    "# Robust Scaler (ít bị ảnh hưởng bởi outliers)\n",
    "scaler_robust = RobustScaler()\n",
    "scaled_robust = scaler_robust.fit_transform(df_outliers[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "print(\"\\n3. Robust Scaler (bền vững trước outliers):\")\n",
    "print(pd.DataFrame(scaled_robust, columns=['Lương', 'Tuổi', 'Kinh nghiệm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe95fbe",
   "metadata": {},
   "source": [
    "## Xử lý chuỗi ký tự (String Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544b9d0",
   "metadata": {},
   "source": [
    "### Tầm quan trọng của việc xử lý chuỗi ký tự"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4834c8a",
   "metadata": {},
   "source": [
    "**📝 Dữ liệu chuỗi ký tự trong thực tế**\n",
    "\n",
    "Dữ liệu chuỗi ký tự (*string data*) chiếm một phần lớn trong các bộ dữ liệu thực tế:\n",
    "\n",
    "- **Tên người, địa chỉ**: Thông tin cá nhân\n",
    "- **Mô tả sản phẩm**: Trong thương mại điện tử\n",
    "- **Bình luận, đánh giá**: Trong phân tích sentiment\n",
    "- **Danh mục, nhãn**: Dữ liệu phân loại\n",
    "\n",
    "**🧹 Các vấn đề thường gặp với dữ liệu chuỗi:**\n",
    "\n",
    "1. **Không nhất quán về định dạng**: \"iPhone\", \"iphone\", \"IPHONE\"\n",
    "2. **Khoảng trắng thừa**: \"  Apple  \", \"Apple \"\n",
    "3. **Ký tự đặc biệt**: \"email@domain.com\", \"phone: +84-123-456-789\"\n",
    "4. **Viết tắt khác nhau**: \"Dr.\", \"Doctor\", \"BS\"\n",
    "5. **Lỗi chính tả**: \"Compnay\" thay vì \"Company\"\n",
    "\n",
    "**🔧 Pandas String Accessor (`.str`)**\n",
    "\n",
    "Pandas cung cấp **accessor `.str`** cho phép áp dụng các phương thức xử lý chuỗi lên toàn bộ Series:\n",
    "\n",
    "```python\n",
    "# Thay vì làm thủ công từng phần tử\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'column'] = df.loc[i, 'column'].upper()\n",
    "\n",
    "# Sử dụng .str accessor\n",
    "df['column'] = df['column'].str.upper()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bfbce",
   "metadata": {},
   "source": [
    "### Các phương thức cơ bản xử lý chuỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337bbe7",
   "metadata": {},
   "source": [
    "**📋 Bảng tổng hợp các phương thức quan trọng:**\n",
    "\n",
    "| Phương thức | Mô tả | Ví dụ |\n",
    "|-------------|-------|-------|\n",
    "| `.str.lower()` | Chuyển về chữ thường | `\"HELLO\"` → `\"hello\"` |\n",
    "| `.str.upper()` | Chuyển về chữ hoa | `\"hello\"` → `\"HELLO\"` |\n",
    "| `.str.title()` | Viết hoa chữ cái đầu | `\"hello world\"` → `\"Hello World\"` |\n",
    "| `.str.strip()` | Loại bỏ khoảng trắng đầu/cuối | `\"  hello  \"` → `\"hello\"` |\n",
    "| `.str.replace()` | Thay thế chuỗi con | `\"hello\"` → `\"hi\"` |\n",
    "| `.str.contains()` | Kiểm tra chứa chuỗi con | `\"hello world\"` contains `\"world\"` → `True` |\n",
    "| `.str.startswith()` | Kiểm tra bắt đầu bằng | `\"hello\"` startswith `\"he\"` → `True` |\n",
    "| `.str.endswith()` | Kiểm tra kết thúc bằng | `\"hello\"` endswith `\"lo\"` → `True` |\n",
    "| `.str.len()` | Độ dài chuỗi | `\"hello\"` → `5` |\n",
    "| `.str.split()` | Tách chuỗi | `\"a,b,c\"` → `[\"a\", \"b\", \"c\"]` |\n",
    "\n",
    "**🔥 Hãy xem các ví dụ thực tế:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c701e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu gốc và kiểu dữ liệu:\n",
      "id          object\n",
      "score       object\n",
      "date        object\n",
      "category    object\n",
      "dtype: object\n",
      "\n",
      "  id score        date category\n",
      "0  1  85.5  2023-01-01        A\n",
      "1  2  90.0  2023-01-02        B\n",
      "2  3  78.5  2023-01-03        A\n",
      "3  4  92.0  2023-01-04        C\n",
      "4  5  88.5  2023-01-05        B\n",
      "\n",
      "Sau khi chuyển đổi kiểu dữ liệu:\n",
      "id                   int64\n",
      "score              float64\n",
      "date        datetime64[ns]\n",
      "category          category\n",
      "dtype: object\n",
      "\n",
      "   id  score       date category\n",
      "0   1   85.5 2023-01-01        A\n",
      "1   2   90.0 2023-01-02        B\n",
      "2   3   78.5 2023-01-03        A\n",
      "3   4   92.0 2023-01-04        C\n",
      "4   5   88.5 2023-01-05        B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': ['1', '2', '3', '4', '5'],\n",
    "    'score': ['85.5', '90.0', '78.5', '92.0', '88.5'],\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'category': ['A', 'B', 'A', 'C', 'B']\n",
    "})\n",
    "\n",
    "print(\"Dữ liệu gốc và kiểu dữ liệu:\")\n",
    "print(sample_data.dtypes)\n",
    "print()\n",
    "print(sample_data)\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu\n",
    "sample_data['id'] = sample_data['id'].astype('int64')\n",
    "sample_data['score'] = sample_data['score'].astype('float64')\n",
    "sample_data['date'] = pd.to_datetime(sample_data['date'])\n",
    "sample_data['category'] = sample_data['category'].astype('category')\n",
    "\n",
    "print(\"\\nSau khi chuyển đổi kiểu dữ liệu:\")\n",
    "print(sample_data.dtypes)\n",
    "print()\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c64432",
   "metadata": {},
   "source": [
    "### Normalization và Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d22fbc",
   "metadata": {},
   "source": [
    "Normalization và standardization là các kỹ thuật quan trọng để đưa dữ liệu về cùng một thang đo, đặc biệt hữu ích cho machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cbffc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu gốc:\n",
      "   height  weight  income\n",
      "0     150      50   30000\n",
      "1     160      60   45000\n",
      "2     170      70   60000\n",
      "3     180      80   75000\n",
      "4     190      90   90000\n",
      "\n",
      "Mô tả thống kê:\n",
      "           height     weight        income\n",
      "count    5.000000   5.000000      5.000000\n",
      "mean   170.000000  70.000000  60000.000000\n",
      "std     15.811388  15.811388  23717.082451\n",
      "min    150.000000  50.000000  30000.000000\n",
      "25%    160.000000  60.000000  45000.000000\n",
      "50%    170.000000  70.000000  60000.000000\n",
      "75%    180.000000  80.000000  75000.000000\n",
      "max    190.000000  90.000000  90000.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Tạo dữ liệu mẫu cho normalization\n",
    "norm_data = pd.DataFrame({\n",
    "    'height': [150, 160, 170, 180, 190],  # cm\n",
    "    'weight': [50, 60, 70, 80, 90],       # kg  \n",
    "    'income': [30000, 45000, 60000, 75000, 90000]  # VND/month\n",
    "})\n",
    "\n",
    "print(\"Dữ liệu gốc:\")\n",
    "print(norm_data)\n",
    "print(\"\\nMô tả thống kê:\")\n",
    "print(norm_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2fc07",
   "metadata": {},
   "source": [
    "### 🔍 Regular Expressions (Regex) - Tìm kiếm thông minh trong văn bản\n",
    "\n",
    "## 📚 Regex là gì và tại sao cần thiết?\n",
    "\n",
    "**🔍 Regular Expressions (Regex)** là một **công cụ tìm kiếm thông minh** giúp bạn tìm và xử lý các mẫu văn bản một cách tự động.\n",
    "\n",
    "### 🏢 Ví dụ thực tế trong kinh doanh:\n",
    "\n",
    "**Tình huống:** Bạn có 1000 email khách hàng và cần:\n",
    "- ✅ Tìm tất cả số điện thoại trong email\n",
    "- ✅ Kiểm tra email có hợp lệ không  \n",
    "- ✅ Tách tên và địa chỉ từ chuỗi văn bản\n",
    "- ✅ Tìm các từ khóa quan trọng\n",
    "\n",
    "**❌ Làm thủ công:** Mất hàng giờ, dễ sai sót  \n",
    "**✅ Dùng Regex:** Chỉ vài dòng code, chính xác 100%\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Hiểu Regex qua ví dụ đơn giản\n",
    "\n",
    "### Ví dụ 1: Tìm số điện thoại\n",
    "```\n",
    "Văn bản: \"Liên hệ tôi qua 0123-456-789 hoặc 0987654321\"\n",
    "Regex: \\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}\n",
    "Kết quả: \"0123-456-789\", \"0987654321\"\n",
    "```\n",
    "\n",
    "### Ví dụ 2: Tìm email\n",
    "```\n",
    "Văn bản: \"Email: john@gmail.com hoặc contact@company.vn\"\n",
    "Regex: [a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\n",
    "Kết quả: \"john@gmail.com\", \"contact@company.vn\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Các ký hiệu Regex cơ bản (Dễ hiểu)\n",
    "\n",
    "| Ký hiệu | Ý nghĩa | Ví dụ thực tế |\n",
    "|---------|---------|---------------|\n",
    "| `\\d` | **Số** (0-9) | `\\d\\d\\d` → tìm \"123\", \"456\" |\n",
    "| `\\w` | **Chữ cái và số** | `\\w+` → tìm \"hello\", \"abc123\" |\n",
    "| `\\s` | **Khoảng trắng** | `\\s+` → tìm spaces, tabs |\n",
    "| `+` | **1 hoặc nhiều** | `\\d+` → \"1\", \"123\", \"12345\" |\n",
    "| `*` | **0 hoặc nhiều** | `\\d*` → \"\", \"1\", \"123\" |\n",
    "| `?` | **0 hoặc 1** | `\\d?` → \"\", \"1\" |\n",
    "| `[]` | **Chọn một trong** | `[0-9]` → số từ 0-9 |\n",
    "| `^` | **Bắt đầu** | `^Hello` → chuỗi bắt đầu \"Hello\" |\n",
    "| `$` | **Kết thúc** | `world$` → chuỗi kết thúc \"world\" |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Cách sử dụng Regex với Pandas\n",
    "\n",
    "Pandas có 4 phương thức chính để làm việc với Regex:\n",
    "\n",
    "| Phương thức | Mục đích | Ví dụ |\n",
    "|-------------|----------|-------|\n",
    "| `.str.contains()` | **Kiểm tra** có chứa pattern không | Có email hợp lệ không? |\n",
    "| `.str.extract()` | **Trích xuất** thông tin | Lấy số điện thoại ra |\n",
    "| `.str.replace()` | **Thay thế** text | Đổi format số điện thoại |\n",
    "| `.str.findall()` | **Tìm tất cả** matches | Tìm tất cả email |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Mẹo học Regex hiệu quả\n",
    "\n",
    "1. **Bắt đầu đơn giản**: Học từng ký hiệu một\n",
    "2. **Thực hành nhiều**: Dùng các ví dụ thực tế\n",
    "3. **Test online**: Dùng regex101.com để test\n",
    "4. **Copy-paste**: Sử dụng patterns có sẵn\n",
    "5. **Không cần nhớ hết**: Chỉ cần hiểu cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5f680",
   "metadata": {},
   "source": [
    "## 🎯 DEMO: Regex từ cơ bản đến nâng cao\n",
    "\n",
    "### 📱 Tình huống thực tế: Xử lý dữ liệu khách hàng\n",
    "\n",
    "Bạn là nhân viên marketing và nhận được danh sách liên hệ khách hàng từ nhiều nguồn khác nhau. Dữ liệu rất lộn xộn và cần được làm sạch.\n",
    "\n",
    "**🎯 Mục tiêu:**\n",
    "1. **Trích xuất số điện thoại** từ các định dạng khác nhau\n",
    "2. **Tìm email hợp lệ** \n",
    "3. **Kiểm tra website/URL**\n",
    "4. **Chuẩn hóa số điện thoại** về định dạng thống nhất\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Dữ liệu mẫu (Tình huống thực tế)\n",
    "\n",
    "Chúng ta có 5 dòng dữ liệu khách hàng với thông tin liên hệ lộn xộn:\n",
    "\n",
    "```\n",
    "1. \"Liên hệ: 0123-456-789 hoặc email: john@gmail.com\"\n",
    "2. \"SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1, TP.HCM\"  \n",
    "3. \"Phone: (024) 3825-7863, email: info@company.vn\"\n",
    "4. \"Mobile: 0987654321, website: https://example.com\"\n",
    "5. \"Hotline: 1900-1234, fax: (028) 3829-5678\"\n",
    "```\n",
    "\n",
    "**❓ Câu hỏi:** Làm sao để tự động trích xuất thông tin từ những chuỗi văn bản phức tạp này?\n",
    "\n",
    "**✅ Trả lời:** Sử dụng Regex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ce829d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 DEMO: Xử lý dữ liệu liên hệ khách hàng với Regex\n",
      "======================================================================\n",
      "📋 BƯỚC 1: Dữ liệu khách hàng gốc (lộn xộn)\n",
      "--------------------------------------------------\n",
      "📊 DataFrame khách hàng:\n",
      "        KhachHang                                           ThongTin\n",
      "0       Công ty A   Liên hệ: 0123-456-789 hoặc email: john@gmail.com\n",
      "1    Khách hàng B  SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1,...\n",
      "2  Doanh nghiệp C     Phone: (024) 3825-7863, email: info@company.vn\n",
      "3       Cá nhân D   Mobile: 0987654321, website: https://example.com\n",
      "4       Tổ chức E           Hotline: 1900-1234, fax: (028) 3829-5678\n",
      "\n",
      "======================================================================\n",
      "🔍 BƯỚC 2: HỌC REGEX QUA VÍ DỤ ĐƠN GIẢN\n",
      "======================================================================\n",
      "📚 HIỂU REGEX QUA VÍ DỤ:\n",
      "\n",
      "1️⃣ Tìm số điện thoại:\n",
      "   Văn bản: '0123-456-789'\n",
      "   Regex: r'\\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}'\n",
      "   Giải thích:\n",
      "   - \\d{3,4} = 3 hoặc 4 số\n",
      "   - [-.]? = có thể có dấu - hoặc . (hoặc không)\n",
      "   - Kết quả: '0123-456-789'\n",
      "\n",
      "2️⃣ Tìm email:\n",
      "   Văn bản: 'john@gmail.com'\n",
      "   Regex: r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
      "   Giải thích:\n",
      "   - [a-zA-Z0-9._%+-]+ = tên email (chữ, số, ký tự đặc biệt)\n",
      "   - @ = ký tự @\n",
      "   - [a-zA-Z0-9.-]+ = tên domain\n",
      "   - \\. = dấu chấm\n",
      "   - [a-zA-Z]{2,} = đuôi domain (ít nhất 2 chữ)\n",
      "   - Kết quả: 'john@gmail.com'\n",
      "\n",
      "\n",
      "======================================================================\n",
      "🛠️ BƯỚC 3: ÁP DỤNG REGEX VÀO DỮ LIỆU THỰC TẾ\n",
      "======================================================================\n",
      "🔍 3.1: Trích xuất số điện thoại\n",
      "----------------------------------------\n",
      "📱 Pattern: (\\+?84[\\s\\-]?)?\\(?0?\\d{2,3}\\)?[\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4}\n",
      "📝 Giải thích:\n",
      "   - (\\+?84[\\s\\-]?)? = mã quốc gia +84 (có thể có hoặc không)\n",
      "   - \\(?0?\\d{2,3}\\)? = mã vùng (có thể có dấu ngoặc)\n",
      "   - [\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4} = số điện thoại\n",
      "\n",
      "📊 Kết quả:\n",
      "        KhachHang                                           ThongTin  \\\n",
      "0       Công ty A   Liên hệ: 0123-456-789 hoặc email: john@gmail.com   \n",
      "1    Khách hàng B  SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1,...   \n",
      "2  Doanh nghiệp C     Phone: (024) 3825-7863, email: info@company.vn   \n",
      "3       Cá nhân D   Mobile: 0987654321, website: https://example.com   \n",
      "4       Tổ chức E           Hotline: 1900-1234, fax: (028) 3829-5678   \n",
      "\n",
      "  SoDienThoai  \n",
      "0        None  \n",
      "1        +84   \n",
      "2        None  \n",
      "3        None  \n",
      "4        None  \n",
      "\n",
      "🔍 3.2: Trích xuất email\n",
      "----------------------------------------\n",
      "📧 Pattern: ([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\n",
      "📝 Giải thích:\n",
      "   - [a-zA-Z0-9._%+-]+ = tên email\n",
      "   - @ = ký tự @\n",
      "   - [a-zA-Z0-9.-]+ = domain\n",
      "   - \\. = dấu chấm\n",
      "   - [a-zA-Z]{2,} = đuôi domain\n",
      "\n",
      "📊 Kết quả:\n",
      "        KhachHang                                           ThongTin  \\\n",
      "0       Công ty A   Liên hệ: 0123-456-789 hoặc email: john@gmail.com   \n",
      "1    Khách hàng B  SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1,...   \n",
      "2  Doanh nghiệp C     Phone: (024) 3825-7863, email: info@company.vn   \n",
      "3       Cá nhân D   Mobile: 0987654321, website: https://example.com   \n",
      "4       Tổ chức E           Hotline: 1900-1234, fax: (028) 3829-5678   \n",
      "\n",
      "             Email  \n",
      "0   john@gmail.com  \n",
      "1              NaN  \n",
      "2  info@company.vn  \n",
      "3              NaN  \n",
      "4              NaN  \n",
      "\n",
      "🔍 3.3: Kiểm tra có website/URL\n",
      "----------------------------------------\n",
      "🌐 Pattern: https?://[^\\s]+\n",
      "📝 Giải thích:\n",
      "   - https? = http hoặc https\n",
      "   - :// = ký tự ://\n",
      "   - [^\\s]+ = mọi ký tự không phải khoảng trắng\n",
      "\n",
      "📊 Kết quả:\n",
      "        KhachHang                                           ThongTin  \\\n",
      "0       Công ty A   Liên hệ: 0123-456-789 hoặc email: john@gmail.com   \n",
      "1    Khách hàng B  SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1,...   \n",
      "2  Doanh nghiệp C     Phone: (024) 3825-7863, email: info@company.vn   \n",
      "3       Cá nhân D   Mobile: 0987654321, website: https://example.com   \n",
      "4       Tổ chức E           Hotline: 1900-1234, fax: (028) 3829-5678   \n",
      "\n",
      "   CoWebsite  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3       True  \n",
      "4      False  \n",
      "\n",
      "======================================================================\n",
      "✨ BƯỚC 4: CHUẨN HÓA SỐ ĐIỆN THOẠI\n",
      "======================================================================\n",
      "🔧 Chuẩn hóa số điện thoại:\n",
      "\n",
      "📊 Kết quả cuối cùng:\n",
      "        KhachHang SoDienThoai SoDienThoaiChuan            Email  CoWebsite\n",
      "0       Công ty A        None             None   john@gmail.com      False\n",
      "1    Khách hàng B        +84                84              NaN      False\n",
      "2  Doanh nghiệp C        None             None  info@company.vn      False\n",
      "3       Cá nhân D        None             None              NaN       True\n",
      "4       Tổ chức E        None             None              NaN      False\n",
      "\n",
      "======================================================================\n",
      "🎉 TỔNG KẾT: REGEX ĐÃ GIÚP CHÚNG TA\n",
      "======================================================================\n",
      "✅ Trích xuất số điện thoại từ 5 định dạng khác nhau\n",
      "✅ Tìm email hợp lệ\n",
      "✅ Kiểm tra có website không\n",
      "✅ Chuẩn hóa số điện thoại về định dạng thống nhất\n",
      "✅ Tất cả chỉ trong vài dòng code!\n",
      "\n",
      "💡 Regex giúp xử lý dữ liệu văn bản phức tạp một cách tự động và chính xác!\n"
     ]
    }
   ],
   "source": [
    "# 🎯 DEMO: Regex từ cơ bản đến nâng cao\n",
    "# Tình huống: Xử lý dữ liệu liên hệ khách hàng\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "print(\"🏢 DEMO: Xử lý dữ liệu liên hệ khách hàng với Regex\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 📋 Bước 1: Tạo dữ liệu mẫu (thực tế từ nhiều nguồn khác nhau)\n",
    "print(\"📋 BƯỚC 1: Dữ liệu khách hàng gốc (lộn xộn)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "data_khachhang = {\n",
    "    'KhachHang': ['Công ty A', 'Khách hàng B', 'Doanh nghiệp C', 'Cá nhân D', 'Tổ chức E'],\n",
    "    'ThongTin': [\n",
    "        'Liên hệ: 0123-456-789 hoặc email: john@gmail.com',\n",
    "        'SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1, TP.HCM', \n",
    "        'Phone: (024) 3825-7863, email: info@company.vn',\n",
    "        'Mobile: 0987654321, website: https://example.com',\n",
    "        'Hotline: 1900-1234, fax: (028) 3829-5678'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_khachhang = pd.DataFrame(data_khachhang)\n",
    "print(\"📊 DataFrame khách hàng:\")\n",
    "print(df_khachhang)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🔍 BƯỚC 2: HỌC REGEX QUA VÍ DỤ ĐƠN GIẢN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 📚 Giải thích Regex cơ bản\n",
    "print(\"📚 HIỂU REGEX QUA VÍ DỤ:\")\n",
    "print()\n",
    "\n",
    "print(\"1️⃣ Tìm số điện thoại:\")\n",
    "print(\"   Văn bản: '0123-456-789'\")\n",
    "print(\"   Regex: r'\\\\d{3,4}[-.]?\\\\d{3,4}[-.]?\\\\d{3,4}'\")\n",
    "print(\"   Giải thích:\")\n",
    "print(\"   - \\\\d{3,4} = 3 hoặc 4 số\")\n",
    "print(\"   - [-.]? = có thể có dấu - hoặc . (hoặc không)\")\n",
    "print(\"   - Kết quả: '0123-456-789'\")\n",
    "print()\n",
    "\n",
    "print(\"2️⃣ Tìm email:\")\n",
    "print(\"   Văn bản: 'john@gmail.com'\")\n",
    "print(\"   Regex: r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}'\")\n",
    "print(\"   Giải thích:\")\n",
    "print(\"   - [a-zA-Z0-9._%+-]+ = tên email (chữ, số, ký tự đặc biệt)\")\n",
    "print(\"   - @ = ký tự @\")\n",
    "print(\"   - [a-zA-Z0-9.-]+ = tên domain\")\n",
    "print(\"   - \\\\. = dấu chấm\")\n",
    "print(\"   - [a-zA-Z]{2,} = đuôi domain (ít nhất 2 chữ)\")\n",
    "print(\"   - Kết quả: 'john@gmail.com'\")\n",
    "print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🛠️ BƯỚC 3: ÁP DỤNG REGEX VÀO DỮ LIỆU THỰC TẾ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 🔍 Bước 3.1: Trích xuất số điện thoại\n",
    "print(\"🔍 3.1: Trích xuất số điện thoại\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Regex đơn giản hơn để dễ hiểu\n",
    "phone_pattern = r'(\\+?84[\\s\\-]?)?\\(?0?\\d{2,3}\\)?[\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4}'\n",
    "\n",
    "print(f\"📱 Pattern: {phone_pattern}\")\n",
    "print(\"📝 Giải thích:\")\n",
    "print(\"   - (\\\\+?84[\\\\s\\\\-]?)? = mã quốc gia +84 (có thể có hoặc không)\")\n",
    "print(\"   - \\\\(?0?\\\\d{2,3}\\\\)? = mã vùng (có thể có dấu ngoặc)\")\n",
    "print(\"   - [\\\\s\\\\-]?\\\\d{3,4}[\\\\s\\\\-]?\\\\d{3,4} = số điện thoại\")\n",
    "\n",
    "df_khachhang['SoDienThoai'] = df_khachhang['ThongTin'].str.extract(phone_pattern, expand=False)\n",
    "print(\"\\n📊 Kết quả:\")\n",
    "print(df_khachhang[['KhachHang', 'ThongTin', 'SoDienThoai']])\n",
    "\n",
    "# 🔍 Bước 3.2: Trích xuất email\n",
    "print(\"\\n🔍 3.2: Trích xuất email\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Regex email đơn giản hơn\n",
    "email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "\n",
    "print(f\"📧 Pattern: {email_pattern}\")\n",
    "print(\"📝 Giải thích:\")\n",
    "print(\"   - [a-zA-Z0-9._%+-]+ = tên email\")\n",
    "print(\"   - @ = ký tự @\")\n",
    "print(\"   - [a-zA-Z0-9.-]+ = domain\")\n",
    "print(\"   - \\\\. = dấu chấm\")\n",
    "print(\"   - [a-zA-Z]{2,} = đuôi domain\")\n",
    "\n",
    "df_khachhang['Email'] = df_khachhang['ThongTin'].str.extract(email_pattern, expand=False)\n",
    "print(\"\\n📊 Kết quả:\")\n",
    "print(df_khachhang[['KhachHang', 'ThongTin', 'Email']])\n",
    "\n",
    "# 🔍 Bước 3.3: Kiểm tra có website không\n",
    "print(\"\\n🔍 3.3: Kiểm tra có website/URL\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Regex URL đơn giản\n",
    "url_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "print(f\"🌐 Pattern: {url_pattern}\")\n",
    "print(\"📝 Giải thích:\")\n",
    "print(\"   - https? = http hoặc https\")\n",
    "print(\"   - :// = ký tự ://\")\n",
    "print(\"   - [^\\\\s]+ = mọi ký tự không phải khoảng trắng\")\n",
    "\n",
    "df_khachhang['CoWebsite'] = df_khachhang['ThongTin'].str.contains(url_pattern, regex=True)\n",
    "print(\"\\n📊 Kết quả:\")\n",
    "print(df_khachhang[['KhachHang', 'ThongTin', 'CoWebsite']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✨ BƯỚC 4: CHUẨN HÓA SỐ ĐIỆN THOẠI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 🔧 Chuẩn hóa số điện thoại\n",
    "def chuan_hoa_so_dien_thoai(so_dt):\n",
    "    \"\"\"\n",
    "    Chuẩn hóa số điện thoại về định dạng: 0xxx-xxx-xxxx\n",
    "    \"\"\"\n",
    "    if pd.isna(so_dt) or so_dt is None:\n",
    "        return None\n",
    "    \n",
    "    # Chỉ giữ lại số\n",
    "    so_clean = ''.join(filter(str.isdigit, str(so_dt)))\n",
    "    \n",
    "    # Chuẩn hóa theo định dạng Việt Nam\n",
    "    if len(so_clean) >= 10:\n",
    "        if so_clean.startswith('84'):\n",
    "            # +84-xxx-xxx-xxxx\n",
    "            return f\"+84-{so_clean[2:5]}-{so_clean[5:8]}-{so_clean[8:]}\"\n",
    "        elif so_clean.startswith('0'):\n",
    "            # 0xxx-xxx-xxxx\n",
    "            return f\"{so_clean[:4]}-{so_clean[4:7]}-{so_clean[7:]}\"\n",
    "    \n",
    "    return so_clean if so_clean else None\n",
    "\n",
    "print(\"🔧 Chuẩn hóa số điện thoại:\")\n",
    "df_khachhang['SoDienThoaiChuan'] = df_khachhang['SoDienThoai'].apply(chuan_hoa_so_dien_thoai)\n",
    "\n",
    "print(\"\\n📊 Kết quả cuối cùng:\")\n",
    "result_columns = ['KhachHang', 'SoDienThoai', 'SoDienThoaiChuan', 'Email', 'CoWebsite']\n",
    "print(df_khachhang[result_columns])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎉 TỔNG KẾT: REGEX ĐÃ GIÚP CHÚNG TA\")\n",
    "print(\"=\"*70)\n",
    "print(\"✅ Trích xuất số điện thoại từ 5 định dạng khác nhau\")\n",
    "print(\"✅ Tìm email hợp lệ\")\n",
    "print(\"✅ Kiểm tra có website không\")\n",
    "print(\"✅ Chuẩn hóa số điện thoại về định dạng thống nhất\")\n",
    "print(\"✅ Tất cả chỉ trong vài dòng code!\")\n",
    "print(\"\\n💡 Regex giúp xử lý dữ liệu văn bản phức tạp một cách tự động và chính xác!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6308338",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a33472b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c50edd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f3b0923",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed53c7d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f196a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6b32509",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu phân loại (Categorical Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020f9e7",
   "metadata": {},
   "source": [
    "### Hiểu về dữ liệu phân loại"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a323b",
   "metadata": {},
   "source": [
    "**🏷️ Dữ liệu phân loại là gì?**\n",
    "\n",
    "Dữ liệu phân loại (*categorical data*) là loại dữ liệu có **số lượng giá trị hữu hạn** và thường được biểu diễn bằng **nhãn hoặc tên**:\n",
    "\n",
    "**📊 Các loại dữ liệu phân loại:**\n",
    "\n",
    "1. **Nominal** (Danh nghĩa): Không có thứ tự\n",
    "   - Giới tính: Nam, Nữ, Khác\n",
    "   - Màu sắc: Đỏ, Xanh, Vàng\n",
    "   - Quốc gia: Việt Nam, Mỹ, Nhật Bản\n",
    "\n",
    "2. **Ordinal** (Thứ tự): Có thứ tự ý nghĩa\n",
    "   - Học vị: Cử nhân < Thạc sĩ < Tiến sĩ\n",
    "   - Đánh giá: Kém < Trung bình < Tốt < Xuất sắc\n",
    "   - Kích cỡ: S < M < L < XL\n",
    "\n",
    "**🔧 Xử lý dữ liệu phân loại trong pandas:**\n",
    "\n",
    "- **Kiểu `category`**: Pandas có kiểu dữ liệu chuyên dụng cho categorical data\n",
    "- **Memory efficient**: Tiết kiệm bộ nhớ khi có nhiều giá trị lặp lại\n",
    "- **Performance**: Tăng tốc các phép toán groupby và merge\n",
    "- **Validation**: Kiểm soát các giá trị hợp lệ\n",
    "\n",
    "**⚙️ Khi nào sử dụng kiểu `category`:**\n",
    "\n",
    "- Cột có **ít giá trị duy nhất** so với tổng số hàng\n",
    "- **Nhiều giá trị lặp lại** (high cardinality)\n",
    "- Muốn **kiểm soát các giá trị** có thể xuất hiện\n",
    "- Cần **tối ưu hóa bộ nhớ** và hiệu suất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc6ba5",
   "metadata": {},
   "source": [
    "### Label Encoding - Mã hóa nhãn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd7819",
   "metadata": {},
   "source": [
    "**🔢 Label Encoding là gì?**\n",
    "\n",
    "Label Encoding là kỹ thuật chuyển đổi dữ liệu phân loại thành **số nguyên tuần tự**:\n",
    "\n",
    "- `\"Apple\"` → `0`\n",
    "- `\"Banana\"` → `1` \n",
    "- `\"Cherry\"` → `2`\n",
    "\n",
    "**✅ Ưu điểm:**\n",
    "- **Đơn giản**: Dễ hiểu và triển khai\n",
    "- **Tiết kiệm bộ nhớ**: Chỉ cần 1 cột\n",
    "- **Phù hợp với dữ liệu ordinal**: Bảo toàn thứ tự\n",
    "\n",
    "**❌ Nhược điểm:**\n",
    "- **Tạo thứ tự giả tạo**: Apple < Banana < Cherry (không đúng)\n",
    "- **Không phù hợp với nominal data**: Các thuật toán có thể hiểu sai quan hệ\n",
    "- **Bias trong mô hình**: Giá trị lớn hơn có thể được coi là \"quan trọng\" hơn\n",
    "\n",
    "**🎯 Khi nào sử dụng Label Encoding:**\n",
    "- **Dữ liệu ordinal** có thứ tự tự nhiên\n",
    "- **Tree-based algorithms** (Decision Tree, Random Forest) - ít bị ảnh hưởng bởi thứ tự\n",
    "- **Target variable** trong classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d25e7de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu categorical gốc:\n",
      "    Tên  Phòng ban Trình độ Thành phố\n",
      "0    An         IT  Cử nhân    Hà Nội\n",
      "1  Bình  Marketing  Thạc sĩ    TP.HCM\n",
      "2   Chi         IT  Cử nhân    Hà Nội\n",
      "3  Dũng         HR  Tiến sĩ   Đà Nẵng\n",
      "4   Eva  Marketing  Thạc sĩ    TP.HCM\n",
      "Sử dụng Label Encoding đối với dữ liệu categorical:\n",
      "Các categoricals đã được mã hóa đối với Phòng ban: ['HR' 'IT' 'Marketing']\n",
      "Các categoricals đã được mã hóa đối với Trình độ: ['Cử nhân' 'Thạc sĩ' 'Tiến sĩ']\n",
      "Các categoricals đã được mã hóa đối với Thành phố: ['Hà Nội' 'TP.HCM' 'Đà Nẵng']\n",
      "Kết quả Label Encoding:\n",
      "    Tên  Phòng ban  Trình độ  Thành phố\n",
      "0    An          1         0          0\n",
      "1  Bình          2         1          1\n",
      "2   Chi          1         0          0\n",
      "3  Dũng          0         2          2\n",
      "4   Eva          2         1          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Tạo dữ liệu categorical để demo One-Hot Encoding\n",
    "data_categorical = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Phòng ban': ['IT', 'Marketing', 'IT', 'HR', 'Marketing'],\n",
    "    'Trình độ': ['Cử nhân', 'Thạc sĩ', 'Cử nhân', 'Tiến sĩ', 'Thạc sĩ'],\n",
    "    'Thành phố': ['Hà Nội', 'TP.HCM', 'Hà Nội', 'Đà Nẵng', 'TP.HCM']\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data_categorical)\n",
    "print(\"Dữ liệu categorical gốc:\")\n",
    "print(df_categorical)\n",
    "\n",
    "print(\"Sử dụng Label Encoding đối với dữ liệu categorical:\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Khởi tạo LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Áp dụng Label Encoding cho từng cột categorical\n",
    "for col in ['Phòng ban', 'Trình độ', 'Thành phố']:\n",
    "    df_categorical[col] = label_encoder.fit_transform(df_categorical[col])\n",
    "    print(f\"Các categoricals đã được mã hóa đối với {col}: {label_encoder.classes_}\")\n",
    "\n",
    "print(\"Kết quả Label Encoding:\")\n",
    "print(df_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7abc1c",
   "metadata": {},
   "source": [
    "### **One-Hot Encoding - Mã hóa One-Hot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47859e9",
   "metadata": {},
   "source": [
    "**🔥 One-Hot Encoding là gì?**\n",
    "\n",
    "One-Hot Encoding tạo ra **binary columns** cho mỗi category:\n",
    "\n",
    "**Ví dụ:** `[\"Apple\", \"Banana\", \"Cherry\"]` → \n",
    "\n",
    "| Apple | Banana | Cherry |\n",
    "|-------|--------|--------|\n",
    "| 1     | 0      | 0      |\n",
    "| 0     | 1      | 0      |\n",
    "| 0     | 0      | 1      |\n",
    "\n",
    "**✅ Ưu điểm:**\n",
    "- **Không tạo thứ tự giả tạo**: Tất cả categories đều bình đẳng\n",
    "- **Phù hợp với nominal data**: Apple ≠ Banana ≠ Cherry\n",
    "- **Hoạt động tốt** với hầu hết machine learning algorithms\n",
    "- **Tránh bias**: Không có category nào được coi là \"quan trọng\" hơn\n",
    "\n",
    "**❌ Nhược điểm:**\n",
    "- **Curse of dimensionality**: Tăng số lượng features đáng kể  \n",
    "- **Sparse matrix**: Nhiều giá trị 0, tốn bộ nhớ\n",
    "- **Multicollinearity**: Các cột có correlation với nhau\n",
    "\n",
    "**🎯 Khi nào sử dụng One-Hot Encoding:**\n",
    "- **Dữ liệu nominal** không có thứ tự tự nhiên\n",
    "- **Ít categories** (< 10-15 giá trị duy nhất)\n",
    "- **Linear algorithms** (Linear/Logistic Regression, SVM)\n",
    "- **Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1f7870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu categorical gốc:\n",
      "    Tên  Phòng ban Trình độ Thành phố\n",
      "0    An         IT  Cử nhân    Hà Nội\n",
      "1  Bình  Marketing  Thạc sĩ    TP.HCM\n",
      "2   Chi         IT  Cử nhân    Hà Nội\n",
      "3  Dũng         HR  Tiến sĩ   Đà Nẵng\n",
      "4   Eva  Marketing  Thạc sĩ    TP.HCM\n",
      "PHƯƠNG PHÁP 1: SỬ DỤNG pandas.get_dummies()\n",
      "Kết quả One-Hot Encoding với pandas:\n",
      "    Tên  PB_HR  PB_IT  PB_Marketing  TD_Cử nhân  TD_Thạc sĩ  TD_Tiến sĩ  \\\n",
      "0    An  False   True         False        True       False       False   \n",
      "1  Bình  False  False          True       False        True       False   \n",
      "2   Chi  False   True         False        True       False       False   \n",
      "3  Dũng   True  False         False       False       False        True   \n",
      "4   Eva  False  False          True       False        True       False   \n",
      "\n",
      "   TP_Hà Nội  TP_TP.HCM  TP_Đà Nẵng  \n",
      "0       True      False       False  \n",
      "1      False       True       False  \n",
      "2       True      False       False  \n",
      "3      False      False        True  \n",
      "4      False       True       False  \n",
      "\n",
      "Số cột trước: 4\n",
      "Số cột sau: 10\n",
      "PHƯƠNG PHÁP 2: SỬ DỤNG sklearn.OneHotEncoder\n",
      "Kết quả One-Hot Encoding với sklearn:\n",
      "    Tên  Phòng ban_IT  Phòng ban_Marketing  Trình độ_Thạc sĩ  \\\n",
      "0    An           1.0                  0.0               0.0   \n",
      "1  Bình           0.0                  1.0               1.0   \n",
      "2   Chi           1.0                  0.0               0.0   \n",
      "3  Dũng           0.0                  0.0               0.0   \n",
      "4   Eva           0.0                  1.0               1.0   \n",
      "\n",
      "   Trình độ_Tiến sĩ  Thành phố_TP.HCM  Thành phố_Đà Nẵng  \n",
      "0               0.0               0.0                0.0  \n",
      "1               0.0               1.0                0.0  \n",
      "2               0.0               0.0                0.0  \n",
      "3               1.0               0.0                1.0  \n",
      "4               0.0               1.0                0.0  \n",
      "\n",
      "Lưu ý: sklearn với drop='first' giảm số cột để tránh multicollinearity\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Tạo dữ liệu categorical để demo One-Hot Encoding\n",
    "data_categorical = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Phòng ban': ['IT', 'Marketing', 'IT', 'HR', 'Marketing'],\n",
    "    'Trình độ': ['Cử nhân', 'Thạc sĩ', 'Cử nhân', 'Tiến sĩ', 'Thạc sĩ'],\n",
    "    'Thành phố': ['Hà Nội', 'TP.HCM', 'Hà Nội', 'Đà Nẵng', 'TP.HCM']\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data_categorical)\n",
    "print(\"Dữ liệu categorical gốc:\")\n",
    "print(df_categorical)\n",
    "\n",
    "print(\"PHƯƠNG PHÁP 1: SỬ DỤNG pandas.get_dummies()\")\n",
    "\n",
    "# Phương pháp 1: Sử dụng pandas.get_dummies()\n",
    "df_onehot_pandas = pd.get_dummies(df_categorical, \n",
    "                                  columns=['Phòng ban', 'Trình độ', 'Thành phố'],\n",
    "                                  prefix=['PB', 'TD', 'TP'])\n",
    "\n",
    "print(\"Kết quả One-Hot Encoding với pandas:\")\n",
    "print(df_onehot_pandas)\n",
    "\n",
    "print(f\"\\nSố cột trước: {len(df_categorical.columns)}\")\n",
    "print(f\"Số cột sau: {len(df_onehot_pandas.columns)}\")\n",
    "\n",
    "print(\"PHƯƠNG PHÁP 2: SỬ DỤNG sklearn.OneHotEncoder\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Phương pháp 2: Sử dụng sklearn OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' để tránh multicollinearity\n",
    "\n",
    "# Chỉ encode các cột categorical (bỏ qua cột 'Tên')\n",
    "categorical_cols = ['Phòng ban', 'Trình độ', 'Thành phố']\n",
    "encoded_data = encoder.fit_transform(df_categorical[categorical_cols])\n",
    "\n",
    "# Tạo tên cột cho kết quả\n",
    "feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Tạo DataFrame mới\n",
    "df_onehot_sklearn = pd.DataFrame(encoded_data, columns=feature_names)\n",
    "df_onehot_sklearn = pd.concat([df_categorical[['Tên']], df_onehot_sklearn], axis=1)\n",
    "\n",
    "print(\"Kết quả One-Hot Encoding với sklearn:\")\n",
    "print(df_onehot_sklearn)\n",
    "\n",
    "print(f\"\\nLưu ý: sklearn với drop='first' giảm số cột để tránh multicollinearity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011775ca",
   "metadata": {},
   "source": [
    "## Câu hỏi ôn tập"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750156b9",
   "metadata": {},
   "source": [
    "**📝 Hãy trả lời các câu hỏi sau để kiểm tra hiểu biết của bạn:**\n",
    "\n",
    "| **Phương thức nào dùng để phát hiện dữ liệu thiếu trong pandas?** | |\n",
    "|---|---|\n",
    "| `isna()` hoặc `isnull()` | |\n",
    "| `missing()` | |\n",
    "| `empty()` | |\n",
    "| `nan_check()` | |\n",
    "\n",
    "| **Phương thức `fillna()` được sử dụng để làm gì?** | |\n",
    "|---|---|\n",
    "| Loại bỏ dữ liệu thiếu | |\n",
    "| Thay thế dữ liệu thiếu | |\n",
    "| Phát hiện dữ liệu thiếu | |\n",
    "| Đếm dữ liệu thiếu | |\n",
    "\n",
    "| **MinMaxScaler đưa dữ liệu về khoảng giá trị nào?** | |\n",
    "|---|---|\n",
    "| [-1, 1] | |\n",
    "| [0, 1] | |\n",
    "| [0, 100] | |\n",
    "| [-100, 100] | |\n",
    "\n",
    "| **Phương thức nào dùng để loại bỏ hàng trùng lặp?** | |\n",
    "|---|---|\n",
    "| `remove_duplicates()` | |\n",
    "| `drop_duplicates()` | |\n",
    "| `delete_duplicates()` | |\n",
    "| `unique()` | |\n",
    "\n",
    "| **Trong pandas, để chuyển chuỗi về chữ thường ta sử dụng?** | |\n",
    "|---|---|\n",
    "| `.str.lowercase()` | |\n",
    "| `.str.lower()` | |\n",
    "| `.str.downcase()` | |\n",
    "| `.str.small()` | |\n",
    "\n",
    "| **Label Encoding phù hợp nhất với loại dữ liệu nào?** | |\n",
    "|---|---|\n",
    "| Dữ liệu số liên tục | |\n",
    "| Dữ liệu nominal | |\n",
    "| Dữ liệu ordinal | |\n",
    "| Dữ liệu thời gian | |\n",
    "\n",
    "| **StandardScaler chuẩn hóa dữ liệu có Mean và Standard Deviation là bao nhiêu?** | |\n",
    "|---|---|\n",
    "| Mean=1, Std=0 | |\n",
    "| Mean=0, Std=1 | |\n",
    "| Mean=0.5, Std=0.5 | |\n",
    "| Mean=100, Std=10 | |\n",
    "\n",
    "| **Khi nào nên sử dụng RobustScaler thay vì MinMaxScaler?** | |\n",
    "|---|---|\n",
    "| Khi dữ liệu có nhiều outliers | |\n",
    "| Khi dữ liệu đã chuẩn hóa | |\n",
    "| Khi dữ liệu là categorical | |\n",
    "| Khi dữ liệu có kích thước nhỏ | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee804b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🏋️ **BÀI TẬP THỰC HÀNH**\n",
    "\n",
    "> **📝 LƯU Ý:** Bài giảng này có **2 hình thức thực hành:**\n",
    "> 1. **🎯 Quiz trắc nghiệm trực tuyến** (30 câu hỏi) - Tự động chấm điểm\n",
    "> 2. **💻 Bài tập code tự do** (9 bài tập) - Thực hành sâu hơn\n",
    "\n",
    "---\n",
    "\n",
    "## **📱 Phần A: QUIZ TRẮC NGHIỆM (30 câu)**\n",
    "\n",
    "> **🎮 Làm quiz online tại:**  \n",
    "> **[Quiz Lecture 5 - Data Cleaning & Preprocessing](../../quiz/Lec05_quiz/index.html)**\n",
    "\n",
    "**Cấu trúc quiz:**\n",
    "- ✅ 30 câu hỏi trắc nghiệm\n",
    "- ✅ Tự động chấm điểm\n",
    "- ✅ Có gợi ý cho từng câu\n",
    "- ✅ Có thể xem đáp án ngay\n",
    "\n",
    "**Nội dung quiz bao gồm:**\n",
    "1. **Missing Data** (6 câu): Detection, Drop, Fill, ML Imputation\n",
    "2. **Duplicate Data** (3 câu): Detection, Removal, Subset handling\n",
    "3. **Data Normalization** (6 câu): MinMax, Standard, Robust Scaler\n",
    "4. **String Processing** (6 câu): Basic methods, Regex, Cleaning\n",
    "5. **Categorical Encoding** (6 câu): Label, One-Hot, Ordinal\n",
    "6. **Advanced** (3 câu): Pipeline, Feature Engineering, Best Practices\n",
    "\n",
    "**💡 Khuyến nghị:** Làm quiz TRƯỚC KHI làm bài tập code để kiểm tra hiểu biết cơ bản!\n",
    "\n",
    "---\n",
    "\n",
    "## **💻 Phần B: BÀI TẬP CODE TỰ DO (9 bài)**\n",
    "\n",
    "### **Nhóm 1: Bài tập cơ bản (⭐) - Tương ứng Quiz câu 1-10**\n",
    "\n",
    "### **Bài 1.1: Xử lý dữ liệu thiếu cơ bản**\n",
    "**Liên quan đến:** Quiz câu 1, 2, 3, 4\n",
    "\n",
    "**Đề bài:** Phân tích dữ liệu khảo sát khách hàng có nhiều giá trị thiếu\n",
    "\n",
    "```python\n",
    "# Dữ liệu khảo sát khách hàng (có missing values)\n",
    "data = {\n",
    "    'Customer_ID': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'Age': [25, None, 30, 28, None, 35, 32, 29],\n",
    "    'Income': [50000000, 60000000, None, 70000000, 55000000, None, 80000000, 65000000],\n",
    "    'Education': ['Bachelor', 'Master', 'Bachelor', None, 'PhD', 'Master', None, 'Bachelor'],\n",
    "    'Satisfaction': [4, 5, None, 3, 4, 5, 4, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. Kiểm tra số lượng missing values trong mỗi cột\n",
    "2. Tính tỷ lệ phần trăm missing values\n",
    "3. Tạo 3 phiên bản xử lý:\n",
    "   - Version 1: Loại bỏ tất cả dòng có missing values\n",
    "   - Version 2: Điền missing values bằng giá trị trung bình/median\n",
    "   - Version 3: Điền missing values bằng forward fill\n",
    "4. So sánh số dòng của 3 phiên bản\n",
    "\n",
    "**Gợi ý:** `.isnull().sum()`, `.dropna()`, `.fillna()`, `.ffill()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 1.2: Phát hiện và xử lý dữ liệu trùng lặp**\n",
    "**Liên quan đến:** Quiz câu 5, 6, 7\n",
    "\n",
    "**Đề bài:** Làm sạch database khách hàng có nhiều bản ghi trùng lặp\n",
    "\n",
    "```python\n",
    "# Dữ liệu khách hàng có duplicates\n",
    "data = {\n",
    "    'Customer_ID': [1, 2, 3, 1, 4, 2, 5, 3, 6],\n",
    "    'Name': ['An', 'Bình', 'Chi', 'An', 'Dũng', 'Bình', 'Eva', 'Chi', 'Giang'],\n",
    "    'Email': ['an@email.com', 'binh@email.com', 'chi@email.com', \n",
    "              'an@email.com', 'dung@email.com', 'binh@email.com', \n",
    "              'eva@email.com', 'chi@email.com', 'giang@email.com'],\n",
    "    'Phone': ['0123456789', '0987654321', '0111222333', \n",
    "              '0123456789', '0444555666', '0987654321', \n",
    "              '0777888999', '0111222333', '0555666777']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. Phát hiện các dòng trùng lặp hoàn toàn\n",
    "2. Phát hiện các dòng trùng lặp theo Email\n",
    "3. Phát hiện các dòng trùng lặp theo Phone\n",
    "4. Loại bỏ duplicates và giữ lại bản ghi đầu tiên\n",
    "5. Tạo báo cáo số lượng duplicates đã loại bỏ\n",
    "\n",
    "**Gợi ý:** `.duplicated()`, `.drop_duplicates()`, `subset` parameter\n",
    "\n",
    "---\n",
    "\n",
    "### **Nhóm 2: Bài tập trung bình (⭐⭐) - Tương ứng Quiz câu 11-20**\n",
    "\n",
    "### **Bài 2.1: Chuẩn hóa dữ liệu tài chính**\n",
    "**Liên quan đến:** Quiz câu 11, 12, 13, 14\n",
    "\n",
    "**Đề bài:** Chuẩn hóa dữ liệu tài chính của các công ty để so sánh\n",
    "\n",
    "```python\n",
    "# Dữ liệu tài chính các công ty (đơn vị: triệu VND)\n",
    "data = {\n",
    "    'Company': ['VinGroup', 'Viettel', 'FPT', 'Masan', 'VNM'],\n",
    "    'Revenue': [500000, 200000, 50000, 30000, 80000],\n",
    "    'Profit': [50000, 30000, 8000, 2000, 10000],\n",
    "    'Assets': [2000000, 800000, 200000, 100000, 300000],\n",
    "    'Employees': [50000, 20000, 10000, 5000, 15000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. Áp dụng MinMaxScaler cho tất cả cột số\n",
    "2. Áp dụng StandardScaler cho tất cả cột số\n",
    "3. Áp dụng RobustScaler cho tất cả cột số\n",
    "4. So sánh kết quả của 3 phương pháp\n",
    "5. Tạo biểu đồ so sánh (boxplot) trước và sau chuẩn hóa\n",
    "\n",
    "**Gợi ý:** `MinMaxScaler()`, `StandardScaler()`, `RobustScaler()`, `.fit_transform()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 2.2: Xử lý chuỗi ký tự trong dữ liệu khách hàng**\n",
    "**Liên quan đến:** Quiz câu 15, 16, 17, 18\n",
    "\n",
    "**Đề bài:** Làm sạch dữ liệu khách hàng có nhiều lỗi định dạng\n",
    "\n",
    "```python\n",
    "# Dữ liệu khách hàng cần làm sạch\n",
    "data = {\n",
    "    'Name': ['  NGUYỄN VĂN A  ', 'trần thị b', 'LÊ VĂN C', '  Phạm Thị D  '],\n",
    "    'Email': ['A@GMAIL.COM', 'b@yahoo.com', 'C@HOTMAIL.COM', 'd@gmail.com'],\n",
    "    'Phone': ['0123-456-789', '0987654321', '+84-987-654-321', '0911-222-333'],\n",
    "    'Address': ['Hà Nội', 'TP.HCM', 'Đà Nẵng', 'Cần Thơ']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. Chuẩn hóa tên: loại bỏ khoảng trắng thừa, viết hoa chữ cái đầu\n",
    "2. Chuẩn hóa email: chuyển về chữ thường\n",
    "3. Chuẩn hóa số điện thoại: loại bỏ ký tự đặc biệt, chỉ giữ số\n",
    "4. Trích xuất domain từ email\n",
    "5. Tạo cột \"Region\" dựa trên địa chỉ\n",
    "\n",
    "**Gợi ý:** `.str.strip()`, `.str.title()`, `.str.lower()`, `.str.replace()`, `.str.extract()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 2.3: Mã hóa dữ liệu phân loại**\n",
    "**Liên quan đến:** Quiz câu 19, 20\n",
    "\n",
    "**Đề bài:** Chuẩn bị dữ liệu sản phẩm cho machine learning\n",
    "\n",
    "```python\n",
    "# Dữ liệu sản phẩm\n",
    "data = {\n",
    "    'Product': ['iPhone 14', 'Samsung Galaxy', 'iPhone 13', 'Xiaomi Redmi', 'Oppo Reno'],\n",
    "    'Brand': ['Apple', 'Samsung', 'Apple', 'Xiaomi', 'Oppo'],\n",
    "    'Category': ['Smartphone', 'Smartphone', 'Smartphone', 'Smartphone', 'Smartphone'],\n",
    "    'Price': [25000000, 20000000, 20000000, 8000000, 12000000],\n",
    "    'Rating': ['Excellent', 'Good', 'Good', 'Average', 'Good']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. Label Encoding cho cột 'Brand'\n",
    "2. One-Hot Encoding cho cột 'Rating'\n",
    "3. Chuẩn hóa cột 'Price' với StandardScaler\n",
    "4. Tạo DataFrame cuối cùng sẵn sàng cho ML\n",
    "5. So sánh kích thước DataFrame trước và sau encoding\n",
    "\n",
    "**Gợi ý:** `LabelEncoder()`, `pd.get_dummies()`, `StandardScaler()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Nhóm 3: Bài tập nâng cao (⭐⭐⭐) - Tương ứng Quiz câu 21-30**\n",
    "\n",
    "### **Bài 3.1: Pipeline xử lý dữ liệu hoàn chỉnh**\n",
    "**Liên quan đến:** Quiz câu 21, 22, 23\n",
    "\n",
    "**Đề bài:** Xây dựng pipeline xử lý dữ liệu khảo sát thị trường\n",
    "\n",
    "```python\n",
    "# Dữ liệu khảo sát thị trường (có nhiều vấn đề)\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Name': ['An', 'Bình', 'Chi', 'Dũng', 'Eva', 'An', 'Bình', 'Giang', 'Hùng', 'Lan'],\n",
    "    'Age': [25, None, 30, 28, None, 25, 35, 32, 29, 27],\n",
    "    'Income': [50000000, 60000000, None, 70000000, 55000000, 50000000, 80000000, 65000000, 45000000, 75000000],\n",
    "    'City': ['Hà Nội', 'TP.HCM', 'Hà Nội', 'Đà Nẵng', 'TP.HCM', 'Hà Nội', 'TP.HCM', 'Hà Nội', 'Cần Thơ', 'Hải Phòng'],\n",
    "    'Satisfaction': ['Rất hài lòng', 'Hài lòng', 'Bình thường', 'Hài lòng', 'Rất hài lòng', 'Hài lòng', 'Bình thường', 'Hài lòng', 'Không hài lòng', 'Hài lòng']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. **Bước 1:** Phân tích dữ liệu (info, describe, missing values)\n",
    "2. **Bước 2:** Xử lý missing values (quyết định phương pháp phù hợp)\n",
    "3. **Bước 3:** Xử lý duplicates (loại bỏ theo ID)\n",
    "4. **Bước 4:** Chuẩn hóa dữ liệu số (Income)\n",
    "5. **Bước 5:** Encoding dữ liệu phân loại (City, Satisfaction)\n",
    "6. **Bước 6:** Tạo báo cáo tổng kết\n",
    "7. **Bước 7:** Lưu kết quả ra file CSV\n",
    "\n",
    "**Gợi ý:** Pipeline approach, `.info()`, `.describe()`, `.isnull().sum()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 3.2: Feature Engineering nâng cao**\n",
    "**Liên quan đến:** Quiz câu 24, 25, 26\n",
    "\n",
    "**Đề bài:** Tạo features mới từ dữ liệu gốc\n",
    "\n",
    "```python\n",
    "# Dữ liệu bán hàng\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone'],\n",
    "    'Price': [15000000, 8000000, 5000000, 16000000, 8500000],\n",
    "    'Quantity': [2, 5, 3, 1, 4],\n",
    "    'Customer_Age': [25, 30, 35, 28, 32],\n",
    "    'Customer_City': ['Hà Nội', 'TP.HCM', 'Đà Nẵng', 'Hà Nội', 'TP.HCM']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**Yêu cầu:**\n",
    "1. Tạo cột 'Total_Revenue' = Price × Quantity\n",
    "2. Tạo cột 'Price_Category' (High/Medium/Low) dựa trên Price\n",
    "3. Tạo cột 'Age_Group' (Young/Adult/Senior) dựa trên Customer_Age\n",
    "4. Tạo cột 'Region' (North/South/Central) dựa trên Customer_City\n",
    "5. Tạo cột 'Day_of_Week' từ Date\n",
    "6. Tạo cột 'Is_Weekend' (True/False)\n",
    "7. Chuẩn hóa tất cả cột số\n",
    "8. One-Hot encoding cho tất cả cột phân loại\n",
    "\n",
    "**Gợi ý:** `pd.to_datetime()`, `.dt.day_name()`, `pd.cut()`, `.map()`\n",
    "\n",
    "---\n",
    "\n",
    "### **Bài 3.3: Mini Project - Phân tích dữ liệu khảo sát khách hàng**\n",
    "**Liên quan đến:** Quiz câu 27-30 (Best practices, Pipeline, Advanced techniques)\n",
    "\n",
    "**Đề bài:** Xây dựng hệ thống phân tích và làm sạch dữ liệu khảo sát khách hàng\n",
    "\n",
    "**Yêu cầu chi tiết:**\n",
    "\n",
    "**Bước 1: Thu thập và phân tích dữ liệu**\n",
    "- Tạo dataset khảo sát khách hàng (100+ records) với các vấn đề:\n",
    "  - Missing values (5-15% mỗi cột)\n",
    "  - Duplicates (10-20%)\n",
    "  - Inconsistent formatting (names, emails, phones)\n",
    "  - Outliers trong dữ liệu số\n",
    "  - Categorical data cần encoding\n",
    "\n",
    "**Bước 2: Xây dựng Data Cleaning Pipeline**\n",
    "- Tạo class `DataCleaner` với các methods:\n",
    "  - `detect_missing()`: Phát hiện và báo cáo missing values\n",
    "  - `handle_missing()`: Xử lý missing values với nhiều phương pháp\n",
    "  - `detect_duplicates()`: Phát hiện duplicates\n",
    "  - `handle_duplicates()`: Xử lý duplicates\n",
    "  - `clean_strings()`: Làm sạch dữ liệu chuỗi\n",
    "  - `normalize_data()`: Chuẩn hóa dữ liệu số\n",
    "  - `encode_categorical()`: Mã hóa dữ liệu phân loại\n",
    "\n",
    "**Bước 3: Áp dụng Pipeline**\n",
    "- Áp dụng pipeline lên dataset\n",
    "- Tạo báo cáo chi tiết về:\n",
    "  - Số lượng records trước/sau cleaning\n",
    "  - Các thay đổi được thực hiện\n",
    "  - Chất lượng dữ liệu cuối cùng\n",
    "\n",
    "**Bước 4: Validation và Testing**\n",
    "- Tạo unit tests cho các methods\n",
    "- Validate kết quả cuối cùng\n",
    "- So sánh performance trước/sau cleaning\n",
    "\n",
    "**Bước 5: Visualization và Reporting**\n",
    "- Tạo visualizations:\n",
    "  - Missing values heatmap\n",
    "  - Before/after comparison charts\n",
    "  - Data quality metrics dashboard\n",
    "- Tạo báo cáo tổng kết (PDF/HTML)\n",
    "\n",
    "**Đánh giá:**\n",
    "- Correctness: 40%\n",
    "- Code quality & documentation: 30%\n",
    "- Pipeline design: 20%\n",
    "- Visualization & reporting: 10%\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78d269",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 💡 **TIPS & TRICKS CHO SINH VIÊN**\n",
    "\n",
    "## **📖 Cách học hiệu quả:**\n",
    "\n",
    "### **1. Học theo thứ tự độ khó tăng dần**\n",
    "```\n",
    "Missing Data → Duplicates → Normalization → String Processing → Categorical Encoding\n",
    "⭐⭐           ⭐           ⭐⭐            ⭐⭐⭐              ⭐⭐\n",
    "```\n",
    "\n",
    "### **2. Thực hành thường xuyên**\n",
    "- ✅ Chạy lại từng ví dụ trong bài giảng\n",
    "- ✅ Thay đổi tham số để xem kết quả khác nhau\n",
    "- ✅ Áp dụng vào dữ liệu thực tế (khảo sát khách hàng, dữ liệu tài chính, v.v.)\n",
    "\n",
    "### **3. Xử lý lỗi đúng cách**\n",
    "```python\n",
    "# Luôn kiểm tra dữ liệu trước khi xử lý\n",
    "print(\"Missing values:\", df.isnull().sum())\n",
    "print(\"Data types:\", df.dtypes)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Xử lý exception\n",
    "try:\n",
    "    df_clean = df.dropna()\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **⚠️ Những sai lầm thường gặp:**\n",
    "\n",
    "### **Top 5 lỗi phổ biến:**\n",
    "\n",
    "**1. Không kiểm tra dữ liệu trước khi xử lý**\n",
    "```python\n",
    "# ❌ SAI - Trực tiếp xử lý\n",
    "df['normalized'] = scaler.fit_transform(df[['price']])\n",
    "\n",
    "# ✅ ĐÚNG - Kiểm tra trước\n",
    "print(df.isnull().sum())\n",
    "df_clean = df.dropna()\n",
    "df['normalized'] = scaler.fit_transform(df_clean[['price']])\n",
    "```\n",
    "\n",
    "**2. Quên lưu lại DataFrame gốc**\n",
    "```python\n",
    "# ❌ SAI - Mất dữ liệu gốc\n",
    "df = df.dropna()  # Không thể quay lại\n",
    "\n",
    "# ✅ ĐÚNG - Giữ bản gốc\n",
    "df_original = df.copy()\n",
    "df_clean = df.dropna()\n",
    "```\n",
    "\n",
    "**3. Không hiểu sự khác biệt giữa các scaler**\n",
    "```python\n",
    "# ❌ SAI - Dùng sai scaler\n",
    "# MinMaxScaler cho dữ liệu có outliers\n",
    "\n",
    "# ✅ ĐÚNG - Chọn scaler phù hợp\n",
    "# MinMaxScaler: Dữ liệu không có outliers\n",
    "# StandardScaler: Dữ liệu có phân phối chuẩn\n",
    "# RobustScaler: Dữ liệu có outliers\n",
    "```\n",
    "\n",
    "**4. Encoding không phù hợp với loại dữ liệu**\n",
    "```python\n",
    "# ❌ SAI - Label encoding cho nominal data\n",
    "df['city_encoded'] = LabelEncoder().fit_transform(df['city'])\n",
    "\n",
    "# ✅ ĐÚNG - One-hot cho nominal, Label cho ordinal\n",
    "df_encoded = pd.get_dummies(df, columns=['city'])  # Nominal\n",
    "df['rating_encoded'] = LabelEncoder().fit_transform(df['rating'])  # Ordinal\n",
    "```\n",
    "\n",
    "**5. Không validate kết quả sau khi xử lý**\n",
    "```python\n",
    "# ❌ SAI - Không kiểm tra kết quả\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# ✅ ĐÚNG - Validate kết quả\n",
    "df_clean = df.dropna()\n",
    "print(f\"Trước: {df.shape[0]} dòng, Sau: {df_clean.shape[0]} dòng\")\n",
    "print(\"Missing values còn lại:\", df_clean.isnull().sum().sum())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **🔧 Best Practices:**\n",
    "\n",
    "### **1. Data Cleaning Pipeline**\n",
    "```python\n",
    "def clean_data(df):\n",
    "    \"\"\"Pipeline làm sạch dữ liệu\"\"\"\n",
    "    # Bước 1: Phân tích\n",
    "    print(\"=== PHÂN TÍCH DỮ LIỆU ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    \n",
    "    # Bước 2: Xử lý missing values\n",
    "    print(\"\\n=== XỬ LÝ MISSING VALUES ===\")\n",
    "    df_clean = df.dropna()  # hoặc fillna()\n",
    "    \n",
    "    # Bước 3: Xử lý duplicates\n",
    "    print(\"\\n=== XỬ LÝ DUPLICATES ===\")\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    \n",
    "    # Bước 4: Chuẩn hóa\n",
    "    print(\"\\n=== CHUẨN HÓA DỮ LIỆU ===\")\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])\n",
    "    \n",
    "    return df_clean\n",
    "```\n",
    "\n",
    "### **2. Validation Functions**\n",
    "```python\n",
    "def validate_cleaning(df_original, df_cleaned):\n",
    "    \"\"\"Validate kết quả làm sạch\"\"\"\n",
    "    print(\"=== VALIDATION REPORT ===\")\n",
    "    print(f\"Records: {df_original.shape[0]} → {df_cleaned.shape[0]}\")\n",
    "    print(f\"Columns: {df_original.shape[1]} → {df_cleaned.shape[1]}\")\n",
    "    print(f\"Missing values: {df_original.isnull().sum().sum()} → {df_cleaned.isnull().sum().sum()}\")\n",
    "    print(f\"Duplicates: {df_original.duplicated().sum()} → {df_cleaned.duplicated().sum()}\")\n",
    "```\n",
    "\n",
    "### **3. Visualization cho Data Quality**\n",
    "```python\n",
    "def plot_data_quality(df):\n",
    "    \"\"\"Vẽ biểu đồ chất lượng dữ liệu\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    sns.heatmap(df.isnull(), ax=axes[0,0], cbar=True)\n",
    "    axes[0,0].set_title('Missing Values Heatmap')\n",
    "    \n",
    "    # Missing values bar chart\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_counts[missing_counts > 0].plot(kind='bar', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Missing Values Count')\n",
    "    \n",
    "    # Data types distribution\n",
    "    df.dtypes.value_counts().plot(kind='pie', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Data Types Distribution')\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    axes[1,1].pie([duplicate_count, len(df)-duplicate_count], \n",
    "                   labels=['Duplicates', 'Unique'], autopct='%1.1f%%')\n",
    "    axes[1,1].set_title('Duplicate Records')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **🚀 Lộ trình học tiếp:**\n",
    "\n",
    "### **Bước tiếp theo:**\n",
    "1. **Bài 6: Data Visualization** - Trực quan hóa dữ liệu\n",
    "2. **Bài 7: Statistical Analysis** - Phân tích thống kê\n",
    "3. **Bài 8: Machine Learning** - Xây dựng mô hình dự đoán\n",
    "4. **Bài 9: Model Evaluation** - Đánh giá mô hình\n",
    "\n",
    "### **Tài liệu tham khảo:**\n",
    "- 📚 Pandas Documentation: https://pandas.pydata.org/docs/\n",
    "- 📚 Scikit-learn Preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- 📚 Data Cleaning Best Practices: https://realpython.com/python-data-cleaning-numpy-pandas/\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Checklist trước khi kết thúc:**\n",
    "\n",
    "- [ ] Đã chạy thử tất cả code cells\n",
    "- [ ] Hiểu rõ sự khác biệt giữa các phương pháp xử lý missing values\n",
    "- [ ] Biết cách chọn scaler phù hợp\n",
    "- [ ] Biết cách encoding dữ liệu phân loại đúng cách\n",
    "- [ ] Đã thử làm ít nhất 2 bài tập\n",
    "- [ ] Đã lưu notebook và kết quả\n",
    "\n",
    "---\n",
    "\n",
    "# 🎓 **KẾT THÚC BÀI GIẢNG**\n",
    "\n",
    "> **Chúc các bạn học tốt và thành công trong việc làm sạch dữ liệu!** 🚀\n",
    "> \n",
    "> **Câu hỏi?** Liên hệ giảng viên qua email hoặc trong giờ học.\n",
    "\n",
    "**Bài giảng tiếp theo:** Trực quan hóa dữ liệu (Data Visualization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26077b9f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr-datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
