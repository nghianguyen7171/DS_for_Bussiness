{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a35277-2812-41cc-a00e-c99ade49156f",
   "metadata": {},
   "source": [
    "# ğŸ“Š LÃ m sáº¡ch vÃ  chuáº©n bá»‹ dá»¯ liá»‡u trong Khoa há»c Dá»¯ liá»‡u\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Má»¥c tiÃªu há»c táº­p\n",
    "\n",
    "Sau khi hoÃ n thÃ nh bÃ i há»c nÃ y, báº¡n sáº½ cÃ³ thá»ƒ:\n",
    "\n",
    "âœ… **Hiá»ƒu vÃ  xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u** trong cÃ¡c bá»™ dá»¯ liá»‡u kinh táº¿  \n",
    "âœ… **PhÃ¡t hiá»‡n vÃ  loáº¡i bá» dá»¯ liá»‡u trÃ¹ng láº·p** trong kháº£o sÃ¡t khÃ¡ch hÃ ng  \n",
    "âœ… **Chuáº©n hÃ³a vÃ  biáº¿n Ä‘á»•i dá»¯ liá»‡u** Ä‘á»ƒ phÃ¹ há»£p vá»›i phÃ¢n tÃ­ch  \n",
    "âœ… **Xá»­ lÃ½ dá»¯ liá»‡u chuá»—i kÃ½ tá»±** tá»« cÃ¡c nguá»“n khÃ¡c nhau  \n",
    "âœ… **MÃ£ hÃ³a dá»¯ liá»‡u phÃ¢n loáº¡i** cho machine learning  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Lá»™ trÃ¬nh bÃ i giáº£ng\n",
    "\n",
    "```\n",
    "Pháº§n 1: Xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u                    â­â­ Trung bÃ¬nh\n",
    "    â”œâ”€â”€ PhÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u\n",
    "    â”œâ”€â”€ Loáº¡i bá» (dropna)\n",
    "    â”œâ”€â”€ Thay tháº¿ (fillna)\n",
    "    â””â”€â”€ Dá»± Ä‘oÃ¡n (ML methods)\n",
    "    \n",
    "Pháº§n 2: Xá»­ lÃ½ dá»¯ liá»‡u trÃ¹ng láº·p                â­ Dá»…\n",
    "    â”œâ”€â”€ PhÃ¡t hiá»‡n (duplicated)\n",
    "    â””â”€â”€ Loáº¡i bá» (drop_duplicates)\n",
    "    \n",
    "Pháº§n 3: Chuáº©n hÃ³a dá»¯ liá»‡u                      â­â­ Trung bÃ¬nh\n",
    "    â”œâ”€â”€ MinMaxScaler\n",
    "    â”œâ”€â”€ StandardScaler\n",
    "    â””â”€â”€ RobustScaler\n",
    "    \n",
    "Pháº§n 4: Xá»­ lÃ½ chuá»—i kÃ½ tá»±                       â­â­â­ KhÃ³\n",
    "    â”œâ”€â”€ String methods cÆ¡ báº£n\n",
    "    â””â”€â”€ Regular Expressions (Regex)\n",
    "    \n",
    "Pháº§n 5: Dá»¯ liá»‡u phÃ¢n loáº¡i                      â­â­ Trung bÃ¬nh\n",
    "    â”œâ”€â”€ Label Encoding\n",
    "    â””â”€â”€ One-Hot Encoding\n",
    "```\n",
    "\n",
    "> **ğŸ’¡ Khuyáº¿n nghá»‹:** Há»c tuáº§n tá»± tá»« Pháº§n 1 â†’ Pháº§n 5. Má»—i pháº§n xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n thá»©c cá»§a pháº§n trÆ°á»›c.\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ LÆ°u Ã½ quan trá»ng\n",
    "\n",
    "> **ğŸ’¡ Cho sinh viÃªn Kinh táº¿:** BÃ i há»c nÃ y táº­p trung vÃ o cÃ¡c ká»¹ thuáº­t thá»±c táº¿ mÃ  báº¡n sáº½ sá»­ dá»¥ng khi phÃ¢n tÃ­ch dá»¯ liá»‡u kinh táº¿, kháº£o sÃ¡t khÃ¡ch hÃ ng, vÃ  nghiÃªn cá»©u thá»‹ trÆ°á»ng.\n",
    "\n",
    "> **ğŸ”§ TÆ°Æ¡ng thÃ­ch:** Notebook nÃ y hoáº¡t Ä‘á»™ng tá»‘t trÃªn cáº£ **Jupyter Notebook**, **JupyterLab**, vÃ  **Google Colab**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Báº¯t Ä‘áº§u há»c táº­p\n",
    "\n",
    "HÃ£y báº¯t Ä‘áº§u vá»›i **Pháº§n 1: Xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u** ğŸ‘‡\n",
    "\n",
    "> **ğŸ’¡ Cho sinh viÃªn Kinh táº¿:** BÃ i há»c nÃ y táº­p trung vÃ o cÃ¡c ká»¹ thuáº­t thá»±c táº¿ mÃ  báº¡n sáº½ sá»­ dá»¥ng khi phÃ¢n tÃ­ch dá»¯ liá»‡u kinh táº¿, kháº£o sÃ¡t khÃ¡ch hÃ ng, vÃ  nghiÃªn cá»©u thá»‹ trÆ°á»ng.\n",
    "\n",
    "> **ğŸ”§ TÆ°Æ¡ng thÃ­ch:** Notebook nÃ y hoáº¡t Ä‘á»™ng tá»‘t trÃªn cáº£ **Jupyter Notebook**, **JupyterLab**, vÃ  **Google Colab**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b27ec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Thiáº¿t láº­p mÃ´i trÆ°á»ng\n",
    "\n",
    "> **ğŸ’¡ Má»¤C TIÃŠU:** Äáº£m báº£o notebook hoáº¡t Ä‘á»™ng tá»‘t trÃªn cáº£ mÃ´i trÆ°á»ng local vÃ  Google Colab\n",
    "\n",
    "### **CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t:**\n",
    "\n",
    "```python\n",
    "# Cháº¡y cell nÃ y náº¿u báº¡n Ä‘ang sá»­ dá»¥ng Google Colab\n",
    "# Hoáº·c náº¿u gáº·p lá»—i ImportError khi cháº¡y cÃ¡c cell khÃ¡c\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"CÃ i Ä‘áº·t package náº¿u chÆ°a cÃ³\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package} Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t\")\n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ Äang cÃ i Ä‘áº·t {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"âœ… ÄÃ£ cÃ i Ä‘áº·t {package} thÃ nh cÃ´ng\")\n",
    "\n",
    "# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "packages = [\n",
    "    \"pandas\",\n",
    "    \"numpy\", \n",
    "    \"scikit-learn\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"ğŸ‰ Thiáº¿t láº­p hoÃ n táº¥t! Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c vá»›i bÃ i há»c.\")\n",
    "```\n",
    "\n",
    "### **Import thÆ° viá»‡n:**\n",
    "\n",
    "```python\n",
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thiáº¿t láº­p hiá»ƒn thá»‹\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"âœ… ÄÃ£ import táº¥t cáº£ thÆ° viá»‡n cáº§n thiáº¿t!\")\n",
    "print(\"ğŸ“Š Sáºµn sÃ ng báº¯t Ä‘áº§u bÃ i há»c Data Cleaning!\")\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad714ca2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc92628e",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Thiáº¿t láº­p mÃ´i trÆ°á»ng\n",
    "\n",
    "TrÆ°á»›c khi báº¯t Ä‘áº§u, hÃ£y Ä‘áº£m báº£o báº¡n Ä‘Ã£ cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:\n",
    "\n",
    "**ğŸ“¦ CÃ i Ä‘áº·t thÆ° viá»‡n (cháº¡y cell nÃ y náº¿u báº¡n Ä‘ang sá»­ dá»¥ng Google Colab):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6aa4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Thiáº¿u thÆ° viá»‡n: cannot import name 'KNNImputer' from 'sklearn.preprocessing' (/Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages/sklearn/preprocessing/__init__.py)\n",
      "ğŸ”§ Äang cÃ i Ä‘áº·t...\n",
      "Requirement already satisfied: pandas in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/nguyennghia/miniconda3/envs/ehr-datasets/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "âœ… CÃ i Ä‘áº·t hoÃ n táº¥t! Vui lÃ²ng restart kernel vÃ  cháº¡y láº¡i cell nÃ y.\n"
     ]
    }
   ],
   "source": [
    "# CÃ i Ä‘áº·t thÆ° viá»‡n cho Google Colab (bá» qua náº¿u Ä‘Ã£ cÃ i Ä‘áº·t)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, KNNImputer\n",
    "    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "    print(\"âœ… Táº¥t cáº£ thÆ° viá»‡n Ä‘Ã£ sáºµn sÃ ng!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Thiáº¿u thÆ° viá»‡n: {e}\")\n",
    "    print(\"ğŸ”§ Äang cÃ i Ä‘áº·t...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "    packages = ['pandas', 'numpy', 'scikit-learn']\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "    \n",
    "    print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t! Vui lÃ²ng restart kernel vÃ  cháº¡y láº¡i cell nÃ y.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d87558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8867191",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79fbd8d0",
   "metadata": {},
   "source": [
    "# ğŸ” Pháº§n 1: Xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u (Missing Data)\n",
    "\n",
    "## ğŸ¯ Má»¥c tiÃªu pháº§n nÃ y\n",
    "- Hiá»ƒu táº¡i sao dá»¯ liá»‡u thiáº¿u lÃ  váº¥n Ä‘á» trong kinh táº¿\n",
    "- PhÃ¡t hiá»‡n missing data trong dá»¯ liá»‡u\n",
    "- Ãp dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ phÃ¹ há»£p\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š VÃ­ dá»¥ thá»±c táº¿: Táº¡i sao dá»¯ liá»‡u thiáº¿u quan trá»ng?\n",
    "\n",
    "Trong thá»±c táº¿ kinh doanh vÃ  nghiÃªn cá»©u kinh táº¿, **dá»¯ liá»‡u thiáº¿u** lÃ  váº¥n Ä‘á» ráº¥t phá»• biáº¿n:\n",
    "\n",
    "### ğŸ¢ VÃ­ dá»¥ thá»±c táº¿ tá»« doanh nghiá»‡p:\n",
    "- **Kháº£o sÃ¡t khÃ¡ch hÃ ng**: Má»™t sá»‘ khÃ¡ch hÃ ng khÃ´ng tráº£ lá»i cÃ¢u há»i vá» thu nháº­p\n",
    "- **BÃ¡o cÃ¡o tÃ i chÃ­nh**: Má»™t sá»‘ cÃ´ng ty khÃ´ng cÃ´ng bá»‘ Ä‘áº§y Ä‘á»§ thÃ´ng tin\n",
    "- **Dá»¯ liá»‡u thá»‹ trÆ°á»ng**: GiÃ¡ cá»• phiáº¿u cÃ³ thá»ƒ bá»‹ thiáº¿u trong ngÃ y nghá»‰ lá»…\n",
    "- **NghiÃªn cá»©u kinh táº¿**: Má»™t sá»‘ há»™ gia Ä‘Ã¬nh tá»« chá»‘i cung cáº¥p thÃ´ng tin chi tiÃªu\n",
    "\n",
    "### âš ï¸ TÃ¡c Ä‘á»™ng cá»§a dá»¯ liá»‡u thiáº¿u:\n",
    "- **Giáº£m Ä‘á»™ tin cáº­y** cá»§a phÃ¢n tÃ­ch\n",
    "- **ThiÃªn lá»‡ch káº¿t quáº£** nghiÃªn cá»©u\n",
    "- **KhÃ³ khÄƒn trong dá»± bÃ¡o** kinh táº¿\n",
    "- **áº¢nh hÆ°á»Ÿng Ä‘áº¿n quyáº¿t Ä‘á»‹nh** Ä‘áº§u tÆ°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb9881",
   "metadata": {},
   "source": [
    "## ğŸ¯ DEMO: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ³ missing values\n",
    "\n",
    "TrÆ°á»›c khi há»c lÃ½ thuyáº¿t, hÃ£y xem má»™t vÃ­ dá»¥ thá»±c táº¿ vá» dá»¯ liá»‡u thiáº¿u:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¢ VÃ Dá»¤: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty cÃ³ missing values\n",
      "============================================================\n",
      "ğŸ“‹ DataFrame nhÃ¢n viÃªn vá»›i dá»¯ liá»‡u thiáº¿u:\n",
      "          TenNV  Tuoi       Luong   PhongBan  KinhNghiem\n",
      "0  Nguyá»…n VÄƒn A  25.0  15000000.0         IT         2.0\n",
      "1    Tráº§n Thá»‹ B   NaN  18000000.0  Marketing         5.0\n",
      "2      LÃª VÄƒn C  30.0         NaN       None         NaN\n",
      "3    Pháº¡m Thá»‹ D  28.0  22000000.0         IT         7.0\n",
      "4   HoÃ ng VÄƒn E   NaN  16000000.0  Marketing         1.0\n",
      "\n",
      "ğŸ“Š ThÃ´ng tin tá»•ng quan:\n",
      "   - Tá»•ng sá»‘ nhÃ¢n viÃªn: 5\n",
      "   - Sá»‘ cá»™t: 5\n",
      "   - Kiá»ƒu dá»¯ liá»‡u:\n",
      "TenNV          object\n",
      "Tuoi          float64\n",
      "Luong         float64\n",
      "PhongBan       object\n",
      "KinhNghiem    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š VÃ­ dá»¥ thá»±c táº¿: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty cÃ³ missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Táº¡o DataFrame máº«u vá» nhÃ¢n viÃªn cÃ´ng ty (tÃ¬nh huá»‘ng thá»±c táº¿)\n",
    "print(\"ğŸ¢ VÃ Dá»¤: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty cÃ³ missing values\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyá»…n VÄƒn A', 'Tráº§n Thá»‹ B', 'LÃª VÄƒn C', 'Pháº¡m Thá»‹ D', 'HoÃ ng VÄƒn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],  # Má»™t sá»‘ nhÃ¢n viÃªn khÃ´ng cung cáº¥p tuá»•i\n",
    "    'Luong': [15000000, 18000000, None, 22000000, 16000000],  # LÆ°Æ¡ng bá»‹ thiáº¿u\n",
    "    'PhongBan': ['IT', 'Marketing', None, 'IT', 'Marketing'],  # PhÃ²ng ban khÃ´ng rÃµ\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]  # Kinh nghiá»‡m chÆ°a Ä‘Æ°á»£c cáº­p nháº­t\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"ğŸ“‹ DataFrame nhÃ¢n viÃªn vá»›i dá»¯ liá»‡u thiáº¿u:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\nğŸ“Š ThÃ´ng tin tá»•ng quan:\")\n",
    "print(f\"   - Tá»•ng sá»‘ nhÃ¢n viÃªn: {len(df_nhanvien)}\")\n",
    "print(f\"   - Sá»‘ cá»™t: {len(df_nhanvien.columns)}\")\n",
    "print(f\"   - Kiá»ƒu dá»¯ liá»‡u:\")\n",
    "print(df_nhanvien.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6d04b1",
   "metadata": {},
   "source": [
    "## ğŸ“š LÃ½ thuyáº¿t: Hiá»ƒu vá» dá»¯ liá»‡u thiáº¿u\n",
    "\n",
    "Sau khi tháº¥y vÃ­ dá»¥ thá»±c táº¿, hÃ£y tÃ¬m hiá»ƒu lÃ½ thuyáº¿t vá» dá»¯ liá»‡u thiáº¿u:\n",
    "\n",
    "* Trong thá»±c táº¿, khi thu tháº­p vÃ  lÆ°u trá»¯ dá»¯ liá»‡u, khÃ´ng pháº£i lÃºc nÃ o má»i giÃ¡ trá»‹ cÅ©ng Ä‘Æ°á»£c ghi nháº­n Ä‘áº§y Ä‘á»§.\n",
    "* Má»™t sá»‘ Ã´ cÃ³ thá»ƒ bá»‹ trá»‘ng hoáº·c mang cÃ¡c kÃ½ hiá»‡u Ä‘áº·c biá»‡t nhÆ° NA, NaN, NULL, hoáº·c chuá»—i rá»—ng \"\". ÄÃ¢y chÃ­nh lÃ  dá»¯ liá»‡u thiáº¿u (missing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a667638",
   "metadata": {},
   "source": [
    "### ğŸ” CÃ¡c dáº¡ng thiáº¿u dá»¯ liá»‡u trong kinh táº¿\n",
    "\n",
    "Trong nghiÃªn cá»©u kinh táº¿, chÃºng ta phÃ¢n loáº¡i dá»¯ liá»‡u thiáº¿u thÃ nh 3 loáº¡i chÃ­nh:\n",
    "\n",
    "#### 1ï¸âƒ£ **MCAR (Missing Completely At Random)** - Thiáº¿u hoÃ n toÃ n ngáº«u nhiÃªn\n",
    "- **VÃ­ dá»¥**: MÃ¡y tÃ­nh bá»‹ lá»—i khi thu tháº­p dá»¯ liá»‡u giÃ¡ cá»• phiáº¿u\n",
    "- **Äáº·c Ä‘iá»ƒm**: KhÃ´ng liÃªn quan Ä‘áº¿n báº¥t ká»³ yáº¿u tá»‘ nÃ o\n",
    "- **Xá»­ lÃ½**: CÃ³ thá»ƒ loáº¡i bá» an toÃ n\n",
    "\n",
    "#### 2ï¸âƒ£ **MAR (Missing At Random)** - Thiáº¿u cÃ³ Ä‘iá»u kiá»‡n\n",
    "- **VÃ­ dá»¥**: NgÆ°á»i cÃ³ thu nháº­p cao thÆ°á»ng khÃ´ng tráº£ lá»i cÃ¢u há»i vá» thu nháº­p\n",
    "- **Äáº·c Ä‘iá»ƒm**: Phá»¥ thuá»™c vÃ o cÃ¡c biáº¿n khÃ¡c cÃ³ thá»ƒ quan sÃ¡t Ä‘Æ°á»£c\n",
    "- **Xá»­ lÃ½**: Cáº§n phÃ¢n tÃ­ch cáº©n tháº­n\n",
    "\n",
    "#### 3ï¸âƒ£ **MNAR (Missing Not At Random)** - Thiáº¿u cÃ³ há»‡ thá»‘ng\n",
    "- **VÃ­ dá»¥**: CÃ´ng ty cÃ³ lá»£i nhuáº­n tháº¥p thÆ°á»ng khÃ´ng cÃ´ng bá»‘ bÃ¡o cÃ¡o tÃ i chÃ­nh\n",
    "- **Äáº·c Ä‘iá»ƒm**: LiÃªn quan trá»±c tiáº¿p Ä‘áº¿n giÃ¡ trá»‹ bá»‹ thiáº¿u\n",
    "- **Xá»­ lÃ½**: Cáº§n ká»¹ thuáº­t phá»©c táº¡p Ä‘á»ƒ xá»­ lÃ½\n",
    "\n",
    "### ğŸ“‹ Biá»ƒu diá»…n dá»¯ liá»‡u thiáº¿u trong Python:\n",
    "- `NaN` (*Not a Number*) - cho dá»¯ liá»‡u sá»‘\n",
    "- `None` - cho dá»¯ liá»‡u Ä‘á»‘i tÆ°á»£ng  \n",
    "- `NaT` (*Not a Time*) - cho dá»¯ liá»‡u thá»i gian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26c07b",
   "metadata": {},
   "source": [
    "### ğŸ¯ NguyÃªn nhÃ¢n gÃ¢y ra dá»¯ liá»‡u thiáº¿u trong kinh táº¿\n",
    "\n",
    "#### ğŸ“Š **Lá»—i thu tháº­p dá»¯ liá»‡u**\n",
    "- **VÃ­ dá»¥**: Há»‡ thá»‘ng giao dá»‹ch chá»©ng khoÃ¡n bá»‹ sáº­p trong giá» cao Ä‘iá»ƒm\n",
    "- **TÃ¡c Ä‘á»™ng**: Máº¥t dá»¯ liá»‡u giÃ¡ cá»• phiáº¿u quan trá»ng\n",
    "\n",
    "#### ğŸ‘¥ **NgÆ°á»i dÃ¹ng khÃ´ng cung cáº¥p**\n",
    "- **VÃ­ dá»¥**: KhÃ¡ch hÃ ng bá» qua cÃ¢u há»i vá» thu nháº­p trong kháº£o sÃ¡t\n",
    "- **TÃ¡c Ä‘á»™ng**: Thiáº¿u thÃ´ng tin Ä‘á»ƒ phÃ¢n tÃ­ch hÃ nh vi tiÃªu dÃ¹ng\n",
    "\n",
    "#### ğŸ“ˆ **Dá»¯ liá»‡u khÃ´ng tá»“n táº¡i**\n",
    "- **VÃ­ dá»¥**: CÃ´ng ty má»›i thÃ nh láº­p chÆ°a cÃ³ bÃ¡o cÃ¡o tÃ i chÃ­nh nÄƒm trÆ°á»›c\n",
    "- **TÃ¡c Ä‘á»™ng**: KhÃ³ so sÃ¡nh hiá»‡u suáº¥t vá»›i cÃ¡c cÃ´ng ty khÃ¡c\n",
    "\n",
    "#### ğŸ”„ **Lá»—i xá»­ lÃ½ dá»¯ liá»‡u**\n",
    "- **VÃ­ dá»¥**: Lá»—i khi chuyá»ƒn Ä‘á»•i Ä‘á»‹nh dáº¡ng tá»« Excel sang CSV\n",
    "- **TÃ¡c Ä‘á»™ng**: Máº¥t thÃ´ng tin quan trá»ng trong quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d455ee",
   "metadata": {},
   "source": [
    "### âš ï¸ TÃ¡c Ä‘á»™ng cá»§a dá»¯ liá»‡u thiáº¿u Ä‘áº¿n phÃ¢n tÃ­ch kinh táº¿\n",
    "\n",
    "#### ğŸ“‰ **Giáº£m kÃ­ch thÆ°á»›c máº«u**\n",
    "- **VÃ­ dá»¥**: Kháº£o sÃ¡t 1000 khÃ¡ch hÃ ng, nhÆ°ng chá»‰ cÃ³ 800 ngÆ°á»i tráº£ lá»i Ä‘áº§y Ä‘á»§\n",
    "- **TÃ¡c Ä‘á»™ng**: Giáº£m Ä‘á»™ tin cáº­y cá»§a káº¿t quáº£ nghiÃªn cá»©u\n",
    "\n",
    "#### ğŸ¯ **ThiÃªn lá»‡ch káº¿t quáº£**\n",
    "- **VÃ­ dá»¥**: Chá»‰ nhá»¯ng ngÆ°á»i cÃ³ thu nháº­p cao má»›i tráº£ lá»i cÃ¢u há»i vá» thu nháº­p\n",
    "- **TÃ¡c Ä‘á»™ng**: Káº¿t quáº£ phÃ¢n tÃ­ch khÃ´ng Ä‘áº¡i diá»‡n cho toÃ n bá»™ dÃ¢n sá»‘\n",
    "\n",
    "#### ğŸ¤– **Giáº£m hiá»‡u quáº£ phÃ¢n tÃ­ch**\n",
    "- **VÃ­ dá»¥**: Thuáº­t toÃ¡n machine learning khÃ´ng thá»ƒ xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u\n",
    "- **TÃ¡c Ä‘á»™ng**: KhÃ´ng thá»ƒ dá»± bÃ¡o xu hÆ°á»›ng thá»‹ trÆ°á»ng chÃ­nh xÃ¡c\n",
    "\n",
    "#### ğŸ’¼ **áº¢nh hÆ°á»Ÿng quyáº¿t Ä‘á»‹nh kinh doanh**\n",
    "- **VÃ­ dá»¥**: Thiáº¿u dá»¯ liá»‡u vá» Ä‘á»‘i thá»§ cáº¡nh tranh\n",
    "- **TÃ¡c Ä‘á»™ng**: Ra quyáº¿t Ä‘á»‹nh Ä‘áº§u tÆ° khÃ´ng chÃ­nh xÃ¡c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e720916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¢ VÃ Dá»¤: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty cÃ³ missing values\n",
      "============================================================\n",
      "ğŸ“‹ DataFrame nhÃ¢n viÃªn vá»›i dá»¯ liá»‡u thiáº¿u:\n",
      "          TenNV  Tuoi       Luong   PhongBan  KinhNghiem\n",
      "0  Nguyá»…n VÄƒn A  25.0  15000000.0         IT         2.0\n",
      "1    Tráº§n Thá»‹ B   NaN  18000000.0  Marketing         5.0\n",
      "2      LÃª VÄƒn C  30.0         NaN       None         NaN\n",
      "3    Pháº¡m Thá»‹ D  28.0  22000000.0         IT         7.0\n",
      "4   HoÃ ng VÄƒn E   NaN  16000000.0  Marketing         1.0\n",
      "\n",
      "ğŸ“Š ThÃ´ng tin tá»•ng quan:\n",
      "   - Tá»•ng sá»‘ nhÃ¢n viÃªn: 5\n",
      "   - Sá»‘ cá»™t: 5\n",
      "   - Kiá»ƒu dá»¯ liá»‡u:\n",
      "TenNV          object\n",
      "Tuoi          float64\n",
      "Luong         float64\n",
      "PhongBan       object\n",
      "KinhNghiem    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š VÃ­ dá»¥ thá»±c táº¿: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty cÃ³ missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Táº¡o DataFrame máº«u vá» nhÃ¢n viÃªn cÃ´ng ty (tÃ¬nh huá»‘ng thá»±c táº¿)\n",
    "print(\"ğŸ¢ VÃ Dá»¤: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty cÃ³ missing values\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyá»…n VÄƒn A', 'Tráº§n Thá»‹ B', 'LÃª VÄƒn C', 'Pháº¡m Thá»‹ D', 'HoÃ ng VÄƒn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],  # Má»™t sá»‘ nhÃ¢n viÃªn khÃ´ng cung cáº¥p tuá»•i\n",
    "    'Luong': [15000000, 18000000, None, 22000000, 16000000],  # LÆ°Æ¡ng bá»‹ thiáº¿u\n",
    "    'PhongBan': ['IT', 'Marketing', None, 'IT', 'Marketing'],  # PhÃ²ng ban khÃ´ng rÃµ\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]  # Kinh nghiá»‡m chÆ°a Ä‘Æ°á»£c cáº­p nháº­t\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"ğŸ“‹ DataFrame nhÃ¢n viÃªn vá»›i dá»¯ liá»‡u thiáº¿u:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\nğŸ“Š ThÃ´ng tin tá»•ng quan:\")\n",
    "print(f\"   - Tá»•ng sá»‘ nhÃ¢n viÃªn: {len(df_nhanvien)}\")\n",
    "print(f\"   - Sá»‘ cá»™t: {len(df_nhanvien.columns)}\")\n",
    "print(f\"   - Kiá»ƒu dá»¯ liá»‡u:\")\n",
    "print(df_nhanvien.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c84ff4",
   "metadata": {},
   "source": [
    "### ğŸ” CÃ¡c phÆ°Æ¡ng thá»©c phÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u trong pandas\n",
    "\n",
    "Pandas cung cáº¥p cÃ¡c phÆ°Æ¡ng thá»©c chuyÃªn dá»¥ng Ä‘á»ƒ **phÃ¡t hiá»‡n vÃ  kiá»ƒm tra dá»¯ liá»‡u thiáº¿u**:\n",
    "\n",
    "| PhÆ°Æ¡ng thá»©c | MÃ´ táº£ | Tráº£ vá» | VÃ­ dá»¥ sá»­ dá»¥ng |\n",
    "|-------------|-------|--------|---------------|\n",
    "| `isna()` / `isnull()` | Kiá»ƒm tra tá»«ng pháº§n tá»­ cÃ³ thiáº¿u khÃ´ng | Boolean DataFrame/Series | `df.isna()` |\n",
    "| `notna()` / `notnull()` | Kiá»ƒm tra tá»«ng pháº§n tá»­ cÃ³ dá»¯ liá»‡u khÃ´ng | Boolean DataFrame/Series | `df.notna()` |\n",
    "| `isna().sum()` | Äáº¿m sá»‘ lÆ°á»£ng dá»¯ liá»‡u thiáº¿u theo cá»™t | Series vá»›i sá»‘ lÆ°á»£ng | `df.isna().sum()` |\n",
    "| `isna().any()` | Kiá»ƒm tra cÃ³ cá»™t nÃ o thiáº¿u dá»¯ liá»‡u khÃ´ng | Boolean Series | `df.isna().any()` |\n",
    "\n",
    "**ğŸ“Š HÃ£y xem cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng thá»©c nÃ y vá»›i dá»¯ liá»‡u nhÃ¢n viÃªn:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ba1fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bda1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DEMO: CÃ¡c phÆ°Æ¡ng thá»©c phÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u\n",
      "============================================================\n",
      "ğŸ“‹ DataFrame gá»‘c:\n",
      "          TenNV  Tuoi       Luong   PhongBan  KinhNghiem\n",
      "0  Nguyá»…n VÄƒn A  25.0  15000000.0         IT         2.0\n",
      "1    Tráº§n Thá»‹ B   NaN  18000000.0  Marketing         5.0\n",
      "2      LÃª VÄƒn C  30.0         NaN       None         NaN\n",
      "3    Pháº¡m Thá»‹ D  28.0  22000000.0         IT         7.0\n",
      "4   HoÃ ng VÄƒn E   NaN  16000000.0  Marketing         1.0\n",
      "\n",
      "============================================================\n",
      "1ï¸âƒ£ KIá»‚M TRA Tá»ªNG PHáº¦N Tá»¬ CÃ“ THIáº¾U KHÃ”NG\n",
      "============================================================\n",
      "ğŸ” df_nhanvien.isna() - Kiá»ƒm tra tá»«ng Ã´ cÃ³ thiáº¿u khÃ´ng:\n",
      "   TenNV   Tuoi  Luong  PhongBan  KinhNghiem\n",
      "0  False  False  False     False       False\n",
      "1  False   True  False     False       False\n",
      "2  False  False   True      True        True\n",
      "3  False  False  False     False       False\n",
      "4  False   True  False     False       False\n",
      "\n",
      "ğŸ” df_nhanvien.notna() - Kiá»ƒm tra tá»«ng Ã´ cÃ³ dá»¯ liá»‡u khÃ´ng:\n",
      "   TenNV   Tuoi  Luong  PhongBan  KinhNghiem\n",
      "0   True   True   True      True        True\n",
      "1   True  False   True      True        True\n",
      "2   True   True  False     False       False\n",
      "3   True   True   True      True        True\n",
      "4   True  False   True      True        True\n",
      "\n",
      "============================================================\n",
      "2ï¸âƒ£ Äáº¾M Sá» LÆ¯á»¢NG Dá»® LIá»†U THIáº¾U THEO Cá»˜T\n",
      "============================================================\n",
      "ğŸ“Š df_nhanvien.isna().sum() - Sá»‘ lÆ°á»£ng missing values theo cá»™t:\n",
      "TenNV         0\n",
      "Tuoi          2\n",
      "Luong         1\n",
      "PhongBan      1\n",
      "KinhNghiem    1\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“ˆ Tá»· lá»‡ missing values (%):\n",
      "TenNV          0.0\n",
      "Tuoi          40.0\n",
      "Luong         20.0\n",
      "PhongBan      20.0\n",
      "KinhNghiem    20.0\n",
      "dtype: float64\n",
      "\n",
      "============================================================\n",
      "3ï¸âƒ£ KIá»‚M TRA Cá»˜T NÃ€O CÃ“ Dá»® LIá»†U THIáº¾U\n",
      "============================================================\n",
      "ğŸ” df_nhanvien.isna().any() - Cá»™t nÃ o cÃ³ missing values:\n",
      "TenNV         False\n",
      "Tuoi           True\n",
      "Luong          True\n",
      "PhongBan       True\n",
      "KinhNghiem     True\n",
      "dtype: bool\n",
      "\n",
      "============================================================\n",
      "4ï¸âƒ£ Tá»”NG Sá» Dá»® LIá»†U THIáº¾U\n",
      "============================================================\n",
      "ğŸ“Š Tá»•ng sá»‘ missing values: 5\n",
      "ğŸ“Š Tá»•ng sá»‘ Ã´ dá»¯ liá»‡u: 25\n",
      "ğŸ“Š Tá»· lá»‡ missing: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” DEMO: PhÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u trong DataFrame nhÃ¢n viÃªn\n",
    "print(\"ğŸ” DEMO: CÃ¡c phÆ°Æ¡ng thá»©c phÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sá»­ dá»¥ng DataFrame tá»« cell trÆ°á»›c\n",
    "print(\"ğŸ“‹ DataFrame gá»‘c:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1ï¸âƒ£ KIá»‚M TRA Tá»ªNG PHáº¦N Tá»¬ CÃ“ THIáº¾U KHÃ”NG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Kiá»ƒm tra dá»¯ liá»‡u thiáº¿u - tráº£ vá» Boolean DataFrame\n",
    "print(\"ğŸ” df_nhanvien.isna() - Kiá»ƒm tra tá»«ng Ã´ cÃ³ thiáº¿u khÃ´ng:\")\n",
    "print(df_nhanvien.isna())\n",
    "\n",
    "print(\"\\nğŸ” df_nhanvien.notna() - Kiá»ƒm tra tá»«ng Ã´ cÃ³ dá»¯ liá»‡u khÃ´ng:\")\n",
    "print(df_nhanvien.notna())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2ï¸âƒ£ Äáº¾M Sá» LÆ¯á»¢NG Dá»® LIá»†U THIáº¾U THEO Cá»˜T\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 2. Äáº¿m sá»‘ lÆ°á»£ng dá»¯ liá»‡u thiáº¿u theo tá»«ng cá»™t\n",
    "print(\"ğŸ“Š df_nhanvien.isna().sum() - Sá»‘ lÆ°á»£ng missing values theo cá»™t:\")\n",
    "missing_count = df_nhanvien.isna().sum()\n",
    "print(missing_count)\n",
    "\n",
    "# TÃ­nh pháº§n trÄƒm missing\n",
    "print(\"\\nğŸ“ˆ Tá»· lá»‡ missing values (%):\")\n",
    "missing_percent = (missing_count / len(df_nhanvien)) * 100\n",
    "print(missing_percent.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3ï¸âƒ£ KIá»‚M TRA Cá»˜T NÃ€O CÃ“ Dá»® LIá»†U THIáº¾U\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 3. Kiá»ƒm tra cá»™t nÃ o cÃ³ dá»¯ liá»‡u thiáº¿u\n",
    "print(\"ğŸ” df_nhanvien.isna().any() - Cá»™t nÃ o cÃ³ missing values:\")\n",
    "print(df_nhanvien.isna().any())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4ï¸âƒ£ Tá»”NG Sá» Dá»® LIá»†U THIáº¾U\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 4. Tá»•ng sá»‘ dá»¯ liá»‡u thiáº¿u trong toÃ n bá»™ DataFrame\n",
    "total_missing = df_nhanvien.isna().sum().sum()\n",
    "total_cells = df_nhanvien.shape[0] * df_nhanvien.shape[1]\n",
    "missing_percentage = (total_missing / total_cells) * 100\n",
    "\n",
    "print(f\"ğŸ“Š Tá»•ng sá»‘ missing values: {total_missing}\")\n",
    "print(f\"ğŸ“Š Tá»•ng sá»‘ Ã´ dá»¯ liá»‡u: {total_cells}\")\n",
    "print(f\"ğŸ“Š Tá»· lá»‡ missing: {missing_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23b439",
   "metadata": {},
   "source": [
    "### ğŸ› ï¸ CÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u trong kinh táº¿\n",
    "\n",
    "**ğŸ¯ CÃ³ 3 cÃ¡ch chÃ­nh Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u:**\n",
    "\n",
    "#### 1ï¸âƒ£ **Loáº¡i bá»** (*Deletion*) \n",
    "- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u thiáº¿u < 5%, thiáº¿u ngáº«u nhiÃªn\n",
    "- **VÃ­ dá»¥**: Loáº¡i bá» khÃ¡ch hÃ ng khÃ´ng tráº£ lá»i Ä‘áº§y Ä‘á»§ kháº£o sÃ¡t\n",
    "- **Æ¯u Ä‘iá»ƒm**: ÄÆ¡n giáº£n, khÃ´ng táº¡o bias\n",
    "- **NhÆ°á»£c Ä‘iá»ƒm**: Giáº£m kÃ­ch thÆ°á»›c máº«u\n",
    "\n",
    "#### 2ï¸âƒ£ **Thay tháº¿** (*Imputation*)\n",
    "- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u thiáº¿u 5-20%, cÃ³ pattern\n",
    "- **VÃ­ dá»¥**: Thay tháº¿ lÆ°Æ¡ng thiáº¿u báº±ng lÆ°Æ¡ng trung bÃ¬nh cá»§a phÃ²ng ban\n",
    "- **Æ¯u Ä‘iá»ƒm**: Giá»¯ nguyÃªn kÃ­ch thÆ°á»›c máº«u\n",
    "- **NhÆ°á»£c Ä‘iá»ƒm**: CÃ³ thá»ƒ táº¡o bias\n",
    "\n",
    "#### 3ï¸âƒ£ **Dá»± Ä‘oÃ¡n** (*Prediction*)\n",
    "- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u thiáº¿u > 20%, cÃ³ má»‘i quan há»‡ phá»©c táº¡p\n",
    "- **VÃ­ dá»¥**: DÃ¹ng machine learning Ä‘á»ƒ dá»± Ä‘oÃ¡n thu nháº­p dá»±a trÃªn cÃ¡c yáº¿u tá»‘ khÃ¡c\n",
    "- **Æ¯u Ä‘iá»ƒm**: ChÃ­nh xÃ¡c cao\n",
    "- **NhÆ°á»£c Ä‘iá»ƒm**: Phá»©c táº¡p, cáº§n hiá»ƒu biáº¿t vá» ML\n",
    "\n",
    "**âš–ï¸ HÆ°á»›ng dáº«n lá»±a chá»n phÆ°Æ¡ng phÃ¡p:**\n",
    "\n",
    "| Tá»· lá»‡ thiáº¿u | Loáº¡i dá»¯ liá»‡u | PhÆ°Æ¡ng phÃ¡p khuyáº¿n nghá»‹ |\n",
    "|-------------|--------------|------------------------|\n",
    "| < 5% | Báº¥t ká»³ | Loáº¡i bá» |\n",
    "| 5-20% | Sá»‘ | Mean/Median |\n",
    "| 5-20% | PhÃ¢n loáº¡i | Mode |\n",
    "| > 20% | CÃ³ quan há»‡ | Machine Learning |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7cb6a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š **So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ Missing Values**\n",
    "\n",
    "ÄÃ£ há»c xong cÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ missing values, hÃ£y so sÃ¡nh Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n:\n",
    "\n",
    "| PhÆ°Æ¡ng phÃ¡p | Khi nÃ o dÃ¹ng | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm | VÃ­ dá»¥ |\n",
    "|-------------|--------------|---------|------------|-------|\n",
    "| **Drop (Loáº¡i bá»)** | Missing < 5% tá»•ng dá»¯ liá»‡u | ÄÆ¡n giáº£n, khÃ´ng lÃ m mÃ©o dá»¯ liá»‡u | Máº¥t thÃ´ng tin, giáº£m kÃ­ch thÆ°á»›c dataset | Kháº£o sÃ¡t cÃ³ 2% khÃ´ng tráº£ lá»i |\n",
    "| **Fill Mean/Median** | Dá»¯ liá»‡u sá»‘, phÃ¢n phá»‘i chuáº©n | Giá»¯ nguyÃªn kÃ­ch thÆ°á»›c dataset | CÃ³ thá»ƒ táº¡o bias, khÃ´ng phÃ¹ há»£p vá»›i categorical | Thu nháº­p, tuá»•i tÃ¡c |\n",
    "| **Fill Mode** | Dá»¯ liá»‡u phÃ¢n loáº¡i | PhÃ¹ há»£p vá»›i categorical data | CÃ³ thá»ƒ táº¡o bias | Giá»›i tÃ­nh, nghá» nghiá»‡p |\n",
    "| **Forward Fill** | Dá»¯ liá»‡u thá»i gian | Giá»¯ nguyÃªn xu hÆ°á»›ng | CÃ³ thá»ƒ táº¡o bias náº¿u missing nhiá»u | GiÃ¡ cá»• phiáº¿u, doanh thu |\n",
    "| **ML Imputation** | Missing > 10%, cÃ³ má»‘i quan há»‡ giá»¯a cÃ¡c cá»™t | ChÃ­nh xÃ¡c, sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c cá»™t khÃ¡c | Phá»©c táº¡p, tá»‘n thá»i gian | KNN, Random Forest |\n",
    "\n",
    "### **ğŸ¤” Khi nÃ o dÃ¹ng gÃ¬?**\n",
    "\n",
    "**DÃ¹ng Drop khi:**\n",
    "- âœ… Missing values < 5% tá»•ng dá»¯ liá»‡u\n",
    "- âœ… KhÃ´ng cÃ³ má»‘i quan há»‡ giá»¯a cÃ¡c cá»™t\n",
    "- âœ… Cáº§n dá»¯ liá»‡u hoÃ n toÃ n chÃ­nh xÃ¡c\n",
    "\n",
    "**DÃ¹ng Fill khi:**\n",
    "- âœ… Missing values 5-15%\n",
    "- âœ… CÃ³ thá»ƒ Æ°á»›c lÆ°á»£ng Ä‘Æ°á»£c giÃ¡ trá»‹ thiáº¿u\n",
    "- âœ… Cáº§n giá»¯ nguyÃªn kÃ­ch thÆ°á»›c dataset\n",
    "\n",
    "**DÃ¹ng ML Imputation khi:**\n",
    "- âœ… Missing values > 10%\n",
    "- âœ… CÃ³ má»‘i quan há»‡ máº¡nh giá»¯a cÃ¡c cá»™t\n",
    "- âœ… Cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š **So sÃ¡nh cÃ¡c Scaler**\n",
    "\n",
    "| Scaler | Khoáº£ng giÃ¡ trá»‹ | Khi nÃ o dÃ¹ng | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |\n",
    "|--------|----------------|--------------|---------|------------|\n",
    "| **MinMaxScaler** | [0, 1] | Dá»¯ liá»‡u khÃ´ng cÃ³ outliers | Dá»… hiá»ƒu, giá»¯ nguyÃªn phÃ¢n phá»‘i | Nháº¡y cáº£m vá»›i outliers |\n",
    "| **StandardScaler** | Mean=0, Std=1 | Dá»¯ liá»‡u cÃ³ phÃ¢n phá»‘i chuáº©n | Chuáº©n hÃ³a theo phÃ¢n phá»‘i chuáº©n | Nháº¡y cáº£m vá»›i outliers |\n",
    "| **RobustScaler** | Median=0, IQR=1 | Dá»¯ liá»‡u cÃ³ outliers | KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers | KhÃ³ hiá»ƒu hÆ¡n |\n",
    "\n",
    "### **ğŸ¯ Chá»n Scaler phÃ¹ há»£p:**\n",
    "\n",
    "**MinMaxScaler:**\n",
    "- âœ… Dá»¯ liá»‡u khÃ´ng cÃ³ outliers\n",
    "- âœ… Cáº§n khoáº£ng giÃ¡ trá»‹ [0,1]\n",
    "- âœ… Neural networks\n",
    "\n",
    "**StandardScaler:**\n",
    "- âœ… Dá»¯ liá»‡u cÃ³ phÃ¢n phá»‘i chuáº©n\n",
    "- âœ… Machine learning algorithms\n",
    "- âœ… Cáº§n mean=0, std=1\n",
    "\n",
    "**RobustScaler:**\n",
    "- âœ… Dá»¯ liá»‡u cÃ³ outliers\n",
    "- âœ… Cáº§n tÃ­nh robust\n",
    "- âœ… Dá»¯ liá»‡u khÃ´ng chuáº©n\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27c281",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8cddba",
   "metadata": {},
   "source": [
    "#### **PhÆ°Æ¡ng phÃ¡p 1: Loáº¡i bá» dá»¯ liá»‡u thiáº¿u (`dropna`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b627f4",
   "metadata": {},
   "source": [
    "PhÆ°Æ¡ng thá»©c `dropna()` cho phÃ©p loáº¡i bá» cÃ¡c hÃ ng hoáº·c cá»™t cÃ³ dá»¯ liá»‡u thiáº¿u:\n",
    "\n",
    "**ğŸ“‹ CÃ¡c tham sá»‘ quan trá»ng cá»§a `dropna()`:**\n",
    "\n",
    "| Tham sá»‘ | GiÃ¡ trá»‹ | MÃ´ táº£ |\n",
    "|---------|---------|-------|\n",
    "| `axis` | 0 (default) / 1 | 0: loáº¡i bá» hÃ ng, 1: loáº¡i bá» cá»™t |\n",
    "| `how` | 'any' (default) / 'all' | 'any': cÃ³ Ã­t nháº¥t 1 NaN, 'all': toÃ n bá»™ lÃ  NaN |\n",
    "| `subset` | list | Chá»‰ xÃ©t dá»¯ liá»‡u thiáº¿u trong cÃ¡c cá»™t Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh |\n",
    "| `thresh` | int | Sá»‘ lÆ°á»£ng giÃ¡ trá»‹ khÃ´ng null tá»‘i thiá»ƒu cáº§n cÃ³ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8d8b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vá»›i dá»¯ liá»‡u thiáº¿u:\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  BÃ¬nh   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN       None\n",
      "3  DÅ©ng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "1. Loáº¡i bá» hÃ ng cÃ³ dá»¯ liá»‡u thiáº¿u (how='any'):\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng PhÃ²ng ban\n",
      "0    An  25.0  15000000.0        IT\n",
      "3  DÅ©ng  28.0  22000000.0        IT\n",
      "Sá»‘ hÃ ng cÃ²n láº¡i: 2\n",
      "2. Loáº¡i bá» hÃ ng khi táº¥t cáº£ giÃ¡ trá»‹ Ä‘á»u thiáº¿u (how='all'):\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  BÃ¬nh   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN       None\n",
      "3  DÅ©ng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "Sá»‘ hÃ ng cÃ²n láº¡i: 5\n",
      "3. Loáº¡i bá» cá»™t cÃ³ dá»¯ liá»‡u thiáº¿u (axis=1):\n",
      "    TÃªn\n",
      "0    An\n",
      "1  BÃ¬nh\n",
      "2   Chi\n",
      "3  DÅ©ng\n",
      "4   Eva\n",
      "Sá»‘ cá»™t cÃ²n láº¡i: 1\n"
     ]
    }
   ],
   "source": [
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Táº¡o DataFrame máº«u vá»›i dá»¯ liá»‡u thiáº¿u\n",
    "data_missing = {\n",
    "    'TÃªn': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva'],\n",
    "    'Tuá»•i': [25, None, 30, 28, None],\n",
    "    'LÆ°Æ¡ng': [15000000, 18000000, None, 22000000, 16000000],\n",
    "    'PhÃ²ng ban': ['IT', 'Marketing', None, 'IT', 'Marketing']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data_missing)\n",
    "print(\"DataFrame vá»›i dá»¯ liá»‡u thiáº¿u:\")\n",
    "print(df_missing)\n",
    "\n",
    "# 1. Loáº¡i bá» táº¥t cáº£ hÃ ng cÃ³ Ã­t nháº¥t 1 giÃ¡ trá»‹ thiáº¿u\n",
    "print(\"1. Loáº¡i bá» hÃ ng cÃ³ dá»¯ liá»‡u thiáº¿u (how='any'):\")\n",
    "df_drop_any = df_missing.dropna()\n",
    "print(df_drop_any)\n",
    "print(f\"Sá»‘ hÃ ng cÃ²n láº¡i: {len(df_drop_any)}\")\n",
    "\n",
    "# 2. Loáº¡i bá» hÃ ng chá»‰ khi Táº¤T Cáº¢ giÃ¡ trá»‹ Ä‘á»u thiáº¿u\n",
    "print(\"2. Loáº¡i bá» hÃ ng khi táº¥t cáº£ giÃ¡ trá»‹ Ä‘á»u thiáº¿u (how='all'):\")\n",
    "df_drop_all = df_missing.dropna(how='all')\n",
    "print(df_drop_all)\n",
    "print(f\"Sá»‘ hÃ ng cÃ²n láº¡i: {len(df_drop_all)}\")\n",
    "\n",
    "# 3. Loáº¡i bá» cá»™t cÃ³ dá»¯ liá»‡u thiáº¿u\n",
    "print(\"3. Loáº¡i bá» cá»™t cÃ³ dá»¯ liá»‡u thiáº¿u (axis=1):\")\n",
    "df_drop_cols = df_missing.dropna(axis=1)\n",
    "print(df_drop_cols)\n",
    "print(f\"Sá»‘ cá»™t cÃ²n láº¡i: {len(df_drop_cols.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee315f8",
   "metadata": {},
   "source": [
    "#### **PhÆ°Æ¡ng phÃ¡p 2: Thay tháº¿ dá»¯ liá»‡u thiáº¿u (`fillna`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff3235",
   "metadata": {},
   "source": [
    "PhÆ°Æ¡ng thá»©c `fillna()` cho phÃ©p **thay tháº¿ dá»¯ liá»‡u thiáº¿u** báº±ng cÃ¡c giÃ¡ trá»‹ cá»¥ thá»ƒ:\n",
    "\n",
    "**ğŸ”§ CÃ¡c chiáº¿n lÆ°á»£c thay tháº¿ phá»• biáº¿n:**\n",
    "\n",
    "| Chiáº¿n lÆ°á»£c | á»¨ng dá»¥ng | VÃ­ dá»¥ |\n",
    "|------------|----------|-------|\n",
    "| **GiÃ¡ trá»‹ cá»‘ Ä‘á»‹nh** | Thay tháº¿ báº±ng má»™t giÃ¡ trá»‹ nháº¥t Ä‘á»‹nh | `fillna(0)`, `fillna('Unknown')` |\n",
    "| **GiÃ¡ trá»‹ trung bÃ¬nh** | Dá»¯ liá»‡u sá»‘, phÃ¢n phá»‘i chuáº©n | `fillna(df['col'].mean())` |\n",
    "| **GiÃ¡ trá»‹ trung vá»‹** | Dá»¯ liá»‡u sá»‘, cÃ³ outliers | `fillna(df['col'].median())` |\n",
    "| **GiÃ¡ trá»‹ phá»• biáº¿n nháº¥t** | Dá»¯ liá»‡u phÃ¢n loáº¡i | `fillna(df['col'].mode()[0])` |\n",
    "| **Forward fill** | Dá»¯ liá»‡u chuá»—i thá»i gian | `fillna(method='ffill')` |\n",
    "| **Backward fill** | Dá»¯ liá»‡u chuá»—i thá»i gian | `fillna(method='bfill')` |\n",
    "\n",
    "**ğŸ“Š HÃ£y xem cÃ¡c vÃ­ dá»¥ cá»¥ thá»ƒ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d63477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame vá»›i dá»¯ liá»‡u thiáº¿u:\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  BÃ¬nh   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN       None\n",
      "3  DÅ©ng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "\n",
      "1. Thay tháº¿ báº±ng giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh:\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng      PhÃ²ng ban\n",
      "0    An  25.0  15000000.0             IT\n",
      "1  BÃ¬nh   0.0  18000000.0      Marketing\n",
      "2   Chi  30.0         0.0  ChÆ°a xÃ¡c Ä‘á»‹nh\n",
      "3  DÅ©ng  28.0  22000000.0             IT\n",
      "4   Eva   0.0  16000000.0      Marketing\n",
      "\n",
      "2. Thay tháº¿ báº±ng giÃ¡ trá»‹ trung bÃ¬nh:\n",
      "    TÃªn       Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban\n",
      "0    An  25.000000  15000000.0         IT\n",
      "1  BÃ¬nh  27.666667  18000000.0  Marketing\n",
      "2   Chi  30.000000  17750000.0       None\n",
      "3  DÅ©ng  28.000000  22000000.0         IT\n",
      "4   Eva  27.666667  16000000.0  Marketing\n",
      "Tuá»•i trung bÃ¬nh: 27.7\n",
      "LÆ°Æ¡ng trung bÃ¬nh: 17,750,000\n",
      "\n",
      "3. Thay tháº¿ báº±ng giÃ¡ trá»‹ trung vá»‹:\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  BÃ¬nh  28.0  18000000.0  Marketing\n",
      "2   Chi  30.0  17000000.0       None\n",
      "3  DÅ©ng  28.0  22000000.0         IT\n",
      "4   Eva  28.0  16000000.0  Marketing\n",
      "\n",
      "4. Thay tháº¿ báº±ng giÃ¡ trá»‹ phá»• biáº¿n nháº¥t (mode):\n",
      "    TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban\n",
      "0    An  25.0  15000000.0         IT\n",
      "1  BÃ¬nh   NaN  18000000.0  Marketing\n",
      "2   Chi  30.0         NaN         IT\n",
      "3  DÅ©ng  28.0  22000000.0         IT\n",
      "4   Eva   NaN  16000000.0  Marketing\n",
      "PhÃ²ng ban phá»• biáº¿n nháº¥t: IT\n"
     ]
    }
   ],
   "source": [
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Táº¡o DataFrame máº«u vá»›i dá»¯ liá»‡u thiáº¿u\n",
    "data_missing = {\n",
    "    'TÃªn': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva'],\n",
    "    'Tuá»•i': [25, None, 30, 28, None],\n",
    "    'LÆ°Æ¡ng': [15000000, 18000000, None, 22000000, 16000000],\n",
    "    'PhÃ²ng ban': ['IT', 'Marketing', None, 'IT', 'Marketing']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data_missing)\n",
    "print(\"DataFrame vá»›i dá»¯ liá»‡u thiáº¿u:\")\n",
    "print(df_missing)\n",
    "\n",
    "# 1. Thay tháº¿ báº±ng giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh\n",
    "print(\"\\n1. Thay tháº¿ báº±ng giÃ¡ trá»‹ cá»‘ Ä‘á»‹nh:\")\n",
    "df_fill_fixed = df_missing.fillna({'Tuá»•i': 0, 'LÆ°Æ¡ng': 0, 'PhÃ²ng ban': 'ChÆ°a xÃ¡c Ä‘á»‹nh'})\n",
    "print(df_fill_fixed)\n",
    "\n",
    "# 2. Thay tháº¿ báº±ng giÃ¡ trá»‹ trung bÃ¬nh (cho dá»¯ liá»‡u sá»‘)\n",
    "print(\"\\n2. Thay tháº¿ báº±ng giÃ¡ trá»‹ trung bÃ¬nh:\")\n",
    "df_fill_mean = df_missing.copy()\n",
    "df_fill_mean['Tuá»•i'] = df_fill_mean['Tuá»•i'].fillna(df_fill_mean['Tuá»•i'].mean())\n",
    "df_fill_mean['LÆ°Æ¡ng'] = df_fill_mean['LÆ°Æ¡ng'].fillna(df_fill_mean['LÆ°Æ¡ng'].mean())\n",
    "print(df_fill_mean)\n",
    "print(f\"Tuá»•i trung bÃ¬nh: {df_missing['Tuá»•i'].mean():.1f}\")\n",
    "print(f\"LÆ°Æ¡ng trung bÃ¬nh: {df_missing['LÆ°Æ¡ng'].mean():,.0f}\")\n",
    "\n",
    "# 3. Thay tháº¿ báº±ng giÃ¡ trá»‹ trung vá»‹ (bá»n vá»¯ng vá»›i outliers)\n",
    "print(\"\\n3. Thay tháº¿ báº±ng giÃ¡ trá»‹ trung vá»‹:\")\n",
    "df_fill_median = df_missing.copy()\n",
    "df_fill_median['Tuá»•i'] = df_fill_median['Tuá»•i'].fillna(df_fill_median['Tuá»•i'].median())\n",
    "df_fill_median['LÆ°Æ¡ng'] = df_fill_median['LÆ°Æ¡ng'].fillna(df_fill_median['LÆ°Æ¡ng'].median())\n",
    "print(df_fill_median)\n",
    "\n",
    "# 4. Thay tháº¿ báº±ng giÃ¡ trá»‹ phá»• biáº¿n nháº¥t (mode) - cho dá»¯ liá»‡u phÃ¢n loáº¡i\n",
    "print(\"\\n4. Thay tháº¿ báº±ng giÃ¡ trá»‹ phá»• biáº¿n nháº¥t (mode):\")\n",
    "df_fill_mode = df_missing.copy()\n",
    "df_fill_mode['PhÃ²ng ban'] = df_fill_mode['PhÃ²ng ban'].fillna(df_fill_mode['PhÃ²ng ban'].mode()[0])\n",
    "print(df_fill_mode)\n",
    "print(f\"PhÃ²ng ban phá»• biáº¿n nháº¥t: {df_missing['PhÃ²ng ban'].mode()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff8a4a",
   "metadata": {},
   "source": [
    "#### PhÆ°Æ¡ng phÃ¡p 3: Sá»­ dá»¥ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68faa286",
   "metadata": {},
   "source": [
    "Sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh **dá»± Ä‘oÃ¡n** Ä‘á»ƒ Æ°á»›c lÆ°á»£ng giÃ¡ trá»‹ thiáº¿u.\n",
    "\n",
    "**ğŸ”§ CÃ¡c chiáº¿n lÆ°á»£c thay tháº¿ phá»• biáº¿n:**\n",
    "\n",
    "| Chiáº¿n lÆ°á»£c | á»¨ng dá»¥ng | VÃ­ dá»¥ |\n",
    "|------------|----------|-------|\n",
    "| **Há»“i quy** | Dá»¯ liá»‡u sá»‘ | Sá»­ dá»¥ng há»“i quy tuyáº¿n tÃ­nh Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ |\n",
    "| **PhÃ¢n loáº¡i** | Dá»¯ liá»‡u phÃ¢n loáº¡i | Sá»­ dá»¥ng cÃ¢y quyáº¿t Ä‘á»‹nh Ä‘á»ƒ phÃ¢n loáº¡i giÃ¡ trá»‹ |\n",
    "| **PhÃ¢n tÃ­ch thá»‘ng kÃª** | Dá»¯ liá»‡u sá»‘ | Sá»­ dá»¥ng thá»‘ng kÃª Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ |\n",
    "\n",
    "**ğŸ“Š HÃ£y xem cÃ¡c vÃ­ dá»¥ cá»¥ thá»ƒ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b53ebe",
   "metadata": {},
   "source": [
    "**ğŸ¤– Khi nÃ o sá»­ dá»¥ng Machine Learning cho Missing Values:**\n",
    "\n",
    "- **Dá»¯ liá»‡u cÃ³ má»‘i quan há»‡ phá»©c táº¡p**: CÃ¡c biáº¿n cÃ³ correlation cao vá»›i nhau\n",
    "- **Dá»¯ liá»‡u missing khÃ´ng ngáº«u nhiÃªn**: Missing data cÃ³ pattern Ä‘áº·c biá»‡t\n",
    "- **Dá»¯ liá»‡u quan trá»ng**: KhÃ´ng muá»‘n máº¥t thÃ´ng tin báº±ng cÃ¡ch loáº¡i bá»\n",
    "- **YÃªu cáº§u Ä‘á»™ chÃ­nh xÃ¡c cao**: Muá»‘n dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c nháº¥t cÃ³ thá»ƒ\n",
    "\n",
    "**âš¡ CÃ¡c ká»¹ thuáº­t Machine Learning phá»• biáº¿n:**\n",
    "\n",
    "- **Regression**: Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ sá»‘ (Linear, Random Forest, XGBoost)\n",
    "- **Classification**: Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ phÃ¢n loáº¡i (Decision Tree, SVM)\n",
    "- **Clustering**: NhÃ³m cÃ¡c quan sÃ¡t tÆ°Æ¡ng tá»± (K-Means, DBSCAN)\n",
    "- **Deep Learning**: Neural Networks cho dá»¯ liá»‡u phá»©c táº¡p\n",
    "\n",
    "**ğŸ¯ Æ¯u Ä‘iá»ƒm vÃ  nhÆ°á»£c Ä‘iá»ƒm:**\n",
    "\n",
    "âœ… **Æ¯u Ä‘iá»ƒm:**\n",
    "- Äá»™ chÃ­nh xÃ¡c cao hÆ¡n mean/median/mode\n",
    "- Táº­n dá»¥ng Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a cÃ¡c biáº¿n\n",
    "- Linh hoáº¡t vá»›i nhiá»u loáº¡i dá»¯ liá»‡u\n",
    "\n",
    "âŒ **NhÆ°á»£c Ä‘iá»ƒm:**\n",
    "- Phá»©c táº¡p, cáº§n hiá»ƒu biáº¿t vá» ML\n",
    "- Tá»‘n thá»i gian training\n",
    "- CÃ³ thá»ƒ overfitting náº¿u khÃ´ng cáº©n tháº­n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf2cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Táº¡o dá»¯ liá»‡u máº«u cho cÃ¡c vÃ­ dá»¥ Machine Learning:\n",
      "Dá»¯ liá»‡u gá»‘c:\n",
      "     TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban  Kinh nghiá»‡m\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   BÃ¬nh   NaN  18000000.0  Marketing            5\n",
      "2    Chi  30.0         NaN       None            7\n",
      "3   DÅ©ng  28.0  22000000.0         IT            3\n",
      "4    Eva   NaN  16000000.0  Marketing            1\n",
      "5  Phong  35.0         NaN         IT           10\n",
      "6  Giang   NaN  25000000.0         HR            8\n",
      "7    Hoa  32.0         NaN         HR            6\n",
      "\n",
      "ğŸ“ˆ Tá»· lá»‡ missing data:\n",
      "Tuá»•i         37.5\n",
      "LÆ°Æ¡ng        37.5\n",
      "PhÃ²ng ban    12.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t cho machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Táº¡o DataFrame máº«u vá»›i dá»¯ liá»‡u thiáº¿u phá»©c táº¡p hÆ¡n\n",
    "print(\"ğŸ“Š Táº¡o dá»¯ liá»‡u máº«u cho cÃ¡c vÃ­ dá»¥ Machine Learning:\")\n",
    "\n",
    "data_advanced = {\n",
    "    'TÃªn': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva', 'Phong', 'Giang', 'Hoa'],\n",
    "    'Tuá»•i': [25, None, 30, 28, None, 35, None, 32],\n",
    "    'LÆ°Æ¡ng': [15000000, 18000000, None, 22000000, 16000000, None, 25000000, None],\n",
    "    'PhÃ²ng ban': ['IT', 'Marketing', None, 'IT', 'Marketing', 'IT', 'HR', 'HR'],\n",
    "    'Kinh nghiá»‡m': [2, 5, 7, 3, 1, 10, 8, 6]\n",
    "}\n",
    "\n",
    "df_advanced = pd.DataFrame(data_advanced)\n",
    "print(\"Dá»¯ liá»‡u gá»‘c:\")\n",
    "print(df_advanced)\n",
    "print(f\"\\nğŸ“ˆ Tá»· lá»‡ missing data:\")\n",
    "missing_percent = (df_advanced.isnull().sum() / len(df_advanced)) * 100\n",
    "print(missing_percent[missing_percent > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd93f66",
   "metadata": {},
   "source": [
    "#### **A. Random Forest Regression - Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ sá»‘**\n",
    "\n",
    "**ğŸŒ² Random Forest lÃ  gÃ¬?**\n",
    "\n",
    "Random Forest lÃ  thuáº­t toÃ¡n **ensemble learning** káº¿t há»£p nhiá»u **Decision Trees**:\n",
    "\n",
    "- **Ensemble**: Káº¿t há»£p nhiá»u mÃ´ hÃ¬nh yáº¿u thÃ nh má»™t mÃ´ hÃ¬nh máº¡nh\n",
    "- **Bootstrap Aggregating**: Má»—i tree Ä‘Æ°á»£c train trÃªn má»™t subset ngáº«u nhiÃªn cá»§a dá»¯ liá»‡u\n",
    "- **Feature Randomness**: Má»—i split chá»‰ xÃ©t má»™t subset ngáº«u nhiÃªn cá»§a features\n",
    "- **Voting**: Káº¿t quáº£ cuá»‘i cÃ¹ng lÃ  trung bÃ¬nh cá»§a táº¥t cáº£ trees (regression) hoáº·c vote Ä‘a sá»‘ (classification)\n",
    "\n",
    "**ğŸ¯ Æ¯u Ä‘iá»ƒm cá»§a Random Forest:**\n",
    "- **Robust**: Ãt bá»‹ overfitting nhá» averaging nhiá»u trees\n",
    "- **Handle Missing Values**: CÃ³ thá»ƒ xá»­ lÃ½ missing values trong quÃ¡ trÃ¬nh training\n",
    "- **Feature Importance**: Cung cáº¥p thÃ´ng tin vá» táº§m quan trá»ng cá»§a tá»«ng feature\n",
    "- **Non-linear**: CÃ³ thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phi tuyáº¿n phá»©c táº¡p\n",
    "\n",
    "**âš™ï¸ CÃ¡c tham sá»‘ quan trá»ng:**\n",
    "- `n_estimators`: Sá»‘ lÆ°á»£ng trees (default=100)\n",
    "- `max_depth`: Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a tree\n",
    "- `min_samples_split`: Sá»‘ sample tá»‘i thiá»ƒu Ä‘á»ƒ split node\n",
    "- `random_state`: Seed cho reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf59cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ DEMO 1: Dá»± Ä‘oÃ¡n Tuá»•i dá»±a trÃªn LÆ°Æ¡ng, PhÃ²ng ban vÃ  Kinh nghiá»‡m\n",
      "======================================================================\n",
      "ğŸ“‹ Mapping PhÃ²ng ban:\n",
      "{'HR': 0, 'IT': 1, 'Marketing': 2, 'Unknown': 3}\n",
      "\n",
      "ğŸ“Š Dá»¯ liá»‡u train: 5 samples\n",
      "ğŸ“Š Dá»¯ liá»‡u cáº§n dá»± Ä‘oÃ¡n: 3 samples\n",
      "\n",
      "ğŸ”§ Features sá»­ dá»¥ng: ['LÆ°Æ¡ng', 'PhÃ²ng ban_encoded', 'Kinh nghiá»‡m']\n",
      "ğŸ“ˆ Training data:\n",
      "        LÆ°Æ¡ng  PhÃ²ng ban_encoded  Kinh nghiá»‡m\n",
      "0  15000000.0                  1            2\n",
      "2         0.0                  3            7\n",
      "3  22000000.0                  1            3\n",
      "5         0.0                  1           10\n",
      "7         0.0                  0            6\n",
      "\n",
      "ğŸ¯ Target (Tuá»•i):\n",
      "[25. 30. 28. 35. 32.]\n",
      "\n",
      "ğŸ”® Dá»± Ä‘oÃ¡n cho 3 samples:\n",
      "   BÃ¬nh: 28.9 tuá»•i\n",
      "   Eva: 26.2 tuá»•i\n",
      "   Giang: 29.3 tuá»•i\n",
      "\n",
      "âœ… Káº¿t quáº£ cuá»‘i cÃ¹ng:\n",
      "     TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban  Kinh nghiá»‡m\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   BÃ¬nh  28.9  18000000.0  Marketing            5\n",
      "2    Chi  30.0         NaN       None            7\n",
      "3   DÅ©ng  28.0  22000000.0         IT            3\n",
      "4    Eva  26.2  16000000.0  Marketing            1\n",
      "5  Phong  35.0         NaN         IT           10\n",
      "6  Giang  29.3  25000000.0         HR            8\n",
      "7    Hoa  32.0         NaN         HR            6\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ DEMO 1: Dá»± Ä‘oÃ¡n Tuá»•i dá»±a trÃªn LÆ°Æ¡ng, PhÃ²ng ban vÃ  Kinh nghiá»‡m\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u\n",
    "df_predict_age = df_advanced.copy()\n",
    "\n",
    "# Encode categorical data (PhÃ²ng ban)\n",
    "le_dept = LabelEncoder()\n",
    "df_predict_age['PhÃ²ng ban_encoded'] = le_dept.fit_transform(df_predict_age['PhÃ²ng ban'].fillna('Unknown'))\n",
    "\n",
    "print(\"ğŸ“‹ Mapping PhÃ²ng ban:\")\n",
    "dept_mapping = dict(zip(le_dept.classes_, le_dept.transform(le_dept.classes_)))\n",
    "print(dept_mapping)\n",
    "\n",
    "# BÆ°á»›c 2: TÃ¡ch dá»¯ liá»‡u train vÃ  missing\n",
    "train_data = df_predict_age[df_predict_age['Tuá»•i'].notna()]\n",
    "missing_data = df_predict_age[df_predict_age['Tuá»•i'].isna()]\n",
    "\n",
    "print(f\"\\nğŸ“Š Dá»¯ liá»‡u train: {len(train_data)} samples\")\n",
    "print(f\"ğŸ“Š Dá»¯ liá»‡u cáº§n dá»± Ä‘oÃ¡n: {len(missing_data)} samples\")\n",
    "\n",
    "if len(train_data) > 0 and len(missing_data) > 0:\n",
    "    # BÆ°á»›c 3: Chuáº©n bá»‹ features vÃ  target\n",
    "    features = ['LÆ°Æ¡ng', 'PhÃ²ng ban_encoded', 'Kinh nghiá»‡m']\n",
    "    X_train = train_data[features].fillna(0)  # Fillna táº¡m thá»i cho missing features\n",
    "    y_train = train_data['Tuá»•i']\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Features sá»­ dá»¥ng: {features}\")\n",
    "    print(\"ğŸ“ˆ Training data:\")\n",
    "    print(X_train)\n",
    "    print(f\"\\nğŸ¯ Target (Tuá»•i):\")\n",
    "    print(y_train.values)\n",
    "    \n",
    "    # BÆ°á»›c 4: Training model\n",
    "    model_age = RandomForestRegressor(n_estimators=10, random_state=42, max_depth=3)\n",
    "    model_age.fit(X_train, y_train)\n",
    "    \n",
    "    # BÆ°á»›c 5: Dá»± Ä‘oÃ¡n\n",
    "    X_missing = missing_data[features].fillna(0)\n",
    "    predicted_ages = model_age.predict(X_missing)\n",
    "    \n",
    "    print(f\"\\nğŸ”® Dá»± Ä‘oÃ¡n cho {len(missing_data)} samples:\")\n",
    "    for i, (idx, row) in enumerate(missing_data.iterrows()):\n",
    "        print(f\"   {row['TÃªn']}: {predicted_ages[i]:.1f} tuá»•i\")\n",
    "    \n",
    "    # BÆ°á»›c 6: Cáº­p nháº­t dá»¯ liá»‡u\n",
    "    df_predict_age.loc[df_predict_age['Tuá»•i'].isna(), 'Tuá»•i'] = predicted_ages\n",
    "    \n",
    "    print(f\"\\nâœ… Káº¿t quáº£ cuá»‘i cÃ¹ng:\")\n",
    "    print(df_predict_age[['TÃªn', 'Tuá»•i', 'LÆ°Æ¡ng', 'PhÃ²ng ban', 'Kinh nghiá»‡m']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abcf633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ DEMO 2: Dá»± Ä‘oÃ¡n LÆ°Æ¡ng dá»±a trÃªn Tuá»•i, PhÃ²ng ban vÃ  Kinh nghiá»‡m\n",
      "======================================================================\n",
      "ğŸ“Š Dá»¯ liá»‡u train: 5 samples\n",
      "ğŸ“Š Dá»¯ liá»‡u cáº§n dá»± Ä‘oÃ¡n: 3 samples\n",
      "\n",
      "ğŸ”§ Features sá»­ dá»¥ng: ['Tuá»•i', 'PhÃ²ng ban_encoded', 'Kinh nghiá»‡m']\n",
      "ğŸ“ˆ Training data:\n",
      "   Tuá»•i  PhÃ²ng ban_encoded  Kinh nghiá»‡m       LÆ°Æ¡ng\n",
      "0  25.0                  1            2  15000000.0\n",
      "1   0.0                  2            5  18000000.0\n",
      "3  28.0                  1            3  22000000.0\n",
      "4   0.0                  2            1  16000000.0\n",
      "6   0.0                  0            8  25000000.0\n",
      "\n",
      "ğŸ“Š Feature Importance:\n",
      "   Tuá»•i: 0.140\n",
      "   PhÃ²ng ban_encoded: 0.380\n",
      "   Kinh nghiá»‡m: 0.480\n",
      "\n",
      "ğŸ”® Dá»± Ä‘oÃ¡n lÆ°Æ¡ng:\n",
      "   Chi: 20,300,000 VND\n",
      "   Phong: 23,100,000 VND\n",
      "   Hoa: 21,800,000 VND\n",
      "\n",
      "âœ… Káº¿t quáº£ cuá»‘i cÃ¹ng:\n",
      "     TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban  Kinh nghiá»‡m\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   BÃ¬nh   NaN  18000000.0  Marketing            5\n",
      "2    Chi  30.0  20300000.0       None            7\n",
      "3   DÅ©ng  28.0  22000000.0         IT            3\n",
      "4    Eva   NaN  16000000.0  Marketing            1\n",
      "5  Phong  35.0  23100000.0         IT           10\n",
      "6  Giang   NaN  25000000.0         HR            8\n",
      "7    Hoa  32.0  21800000.0         HR            6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ¯ DEMO 2: Dá»± Ä‘oÃ¡n LÆ°Æ¡ng dá»±a trÃªn Tuá»•i, PhÃ²ng ban vÃ  Kinh nghiá»‡m\") \n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sá»­ dá»¥ng dá»¯ liá»‡u gá»‘c (chÆ°a cÃ³ Tuá»•i Ä‘Æ°á»£c dá»± Ä‘oÃ¡n)\n",
    "df_predict_salary = df_advanced.copy()\n",
    "df_predict_salary['PhÃ²ng ban_encoded'] = le_dept.fit_transform(df_predict_salary['PhÃ²ng ban'].fillna('Unknown'))\n",
    "\n",
    "# TÃ¡ch dá»¯ liá»‡u train vÃ  missing cho LÆ°Æ¡ng\n",
    "train_salary = df_predict_salary[df_predict_salary['LÆ°Æ¡ng'].notna()]\n",
    "missing_salary = df_predict_salary[df_predict_salary['LÆ°Æ¡ng'].isna()]\n",
    "\n",
    "print(f\"ğŸ“Š Dá»¯ liá»‡u train: {len(train_salary)} samples\")\n",
    "print(f\"ğŸ“Š Dá»¯ liá»‡u cáº§n dá»± Ä‘oÃ¡n: {len(missing_salary)} samples\")\n",
    "\n",
    "if len(train_salary) > 0 and len(missing_salary) > 0:\n",
    "    # Features cho dá»± Ä‘oÃ¡n lÆ°Æ¡ng\n",
    "    salary_features = ['Tuá»•i', 'PhÃ²ng ban_encoded', 'Kinh nghiá»‡m'] \n",
    "    X_train_salary = train_salary[salary_features].fillna(0)\n",
    "    y_train_salary = train_salary['LÆ°Æ¡ng']\n",
    "    \n",
    "    print(f\"\\nğŸ”§ Features sá»­ dá»¥ng: {salary_features}\")\n",
    "    print(\"ğŸ“ˆ Training data:\")\n",
    "    combined_train = pd.concat([X_train_salary, y_train_salary], axis=1)\n",
    "    print(combined_train)\n",
    "    \n",
    "    # Training model cho lÆ°Æ¡ng\n",
    "    model_salary = RandomForestRegressor(n_estimators=10, random_state=42, max_depth=3)\n",
    "    model_salary.fit(X_train_salary, y_train_salary)\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = model_salary.feature_importances_\n",
    "    print(f\"\\nğŸ“Š Feature Importance:\")\n",
    "    for feature, imp in zip(salary_features, importance):\n",
    "        print(f\"   {feature}: {imp:.3f}\")\n",
    "    \n",
    "    # Dá»± Ä‘oÃ¡n lÆ°Æ¡ng\n",
    "    X_missing_salary = missing_salary[salary_features].fillna(0)\n",
    "    predicted_salaries = model_salary.predict(X_missing_salary)\n",
    "    \n",
    "    print(f\"\\nğŸ”® Dá»± Ä‘oÃ¡n lÆ°Æ¡ng:\")\n",
    "    for i, (idx, row) in enumerate(missing_salary.iterrows()):\n",
    "        print(f\"   {row['TÃªn']}: {predicted_salaries[i]:,.0f} VND\")\n",
    "    \n",
    "    # Cáº­p nháº­t dá»¯ liá»‡u\n",
    "    df_predict_salary.loc[df_predict_salary['LÆ°Æ¡ng'].isna(), 'LÆ°Æ¡ng'] = predicted_salaries\n",
    "    \n",
    "    print(f\"\\nâœ… Káº¿t quáº£ cuá»‘i cÃ¹ng:\")\n",
    "    print(df_predict_salary[['TÃªn', 'Tuá»•i', 'LÆ°Æ¡ng', 'PhÃ²ng ban', 'Kinh nghiá»‡m']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487b44c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Œ TÃ“M Táº®T PHáº¦N 1: Xá»¬ LÃ Dá»® LIá»†U THIáº¾U\n",
    "\n",
    "### âœ… Kiáº¿n thá»©c Ä‘Ã£ há»c:\n",
    "1. âœ… PhÃ¡t hiá»‡n missing data vá»›i `.isna()` vÃ  `.isnull()`\n",
    "2. âœ… Loáº¡i bá» vá»›i `.dropna(how='any'/'all', axis=0/1)`\n",
    "3. âœ… Thay tháº¿ vá»›i `.fillna(value/method/dict)`\n",
    "4. âœ… Dá»± Ä‘oÃ¡n vá»›i Random Forest vÃ  KNN Imputer\n",
    "\n",
    "### ğŸ”‘ HÃ m quan trá»ng:\n",
    "| HÃ m | Má»¥c Ä‘Ã­ch | VÃ­ dá»¥ |\n",
    "|-----|----------|-------|\n",
    "| `.isna().sum()` | Äáº¿m missing | `df.isna().sum()` |\n",
    "| `.dropna()` | Loáº¡i bá» | `df.dropna(how='any')` |\n",
    "| `.fillna()` | Thay tháº¿ | `df.fillna(0)` |\n",
    "\n",
    "### âš ï¸ Lá»—i thÆ°á»ng gáº·p:\n",
    "âŒ QuÃªn kiá»ƒm tra tá»· lá»‡ missing trÆ°á»›c khi dropna  \n",
    "âŒ DÃ¹ng mean cho dá»¯ liá»‡u cÃ³ outliers  \n",
    "âŒ Fillna khÃ´ng specify `inplace=True`\n",
    "\n",
    "### ğŸ’¡ Tips:\n",
    "- LuÃ´n kiá»ƒm tra `df.isna().sum()` trÆ°á»›c\n",
    "- DÃ¹ng median cho dá»¯ liá»‡u cÃ³ outliers\n",
    "- Save a copy trÆ°á»›c khi drop data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b745f",
   "metadata": {},
   "source": [
    "#### **B. KNN Imputation - K-Nearest Neighbors**\n",
    "\n",
    "**ğŸ” KNN Imputation lÃ  gÃ¬?**\n",
    "\n",
    "KNN Imputation sá»­ dá»¥ng thuáº­t toÃ¡n **K-Nearest Neighbors** Ä‘á»ƒ Ä‘iá»n missing values:\n",
    "\n",
    "1. **TÃ¬m K neighbors gáº§n nháº¥t**: Dá»±a trÃªn khoáº£ng cÃ¡ch Euclidean trong khÃ´ng gian features\n",
    "2. **TÃ­nh giÃ¡ trá»‹ trung bÃ¬nh**: Láº¥y trung bÃ¬nh cá»§a K neighbors (cho sá»‘) hoáº·c mode (cho categorical)\n",
    "3. **Äiá»n vÃ o missing values**: Thay tháº¿ missing value báº±ng giÃ¡ trá»‹ Ä‘Æ°á»£c tÃ­nh\n",
    "\n",
    "**ğŸ“ CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean:**\n",
    "\n",
    "$$d(x_i, x_j) = \\sqrt{\\sum_{k=1}^{n} (x_{ik} - x_{jk})^2}$$\n",
    "\n",
    "**ğŸ¯ Æ¯u Ä‘iá»ƒm cá»§a KNN Imputation:**\n",
    "- **Preserve relationships**: Giá»¯ nguyÃªn má»‘i quan há»‡ giá»¯a cÃ¡c features\n",
    "- **Non-parametric**: KhÃ´ng giáº£ Ä‘á»‹nh vá» phÃ¢n phá»‘i dá»¯ liá»‡u\n",
    "- **Local patterns**: Táº­n dá»¥ng patterns cá»¥c bá»™ trong dá»¯ liá»‡u\n",
    "- **Multivariate**: Xem xÃ©t táº¥t cáº£ features cÃ¹ng lÃºc\n",
    "\n",
    "**âš™ï¸ CÃ¡c tham sá»‘ quan trá»ng:**\n",
    "- `n_neighbors`: Sá»‘ lÆ°á»£ng neighbors (default=5)\n",
    "- `weights`: 'uniform' hoáº·c 'distance' weighted\n",
    "- `metric`: PhÆ°Æ¡ng phÃ¡p tÃ­nh distance ('nan_euclidean' cho missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0062f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ DEMO 3: KNN Imputation - Äiá»n táº¥t cáº£ missing values cÃ¹ng lÃºc\n",
      "======================================================================\n",
      "ğŸ“Š Dá»¯ liá»‡u trÆ°á»›c KNN Imputation:\n",
      "     TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban  Kinh nghiá»‡m\n",
      "0     An  25.0  15000000.0         IT            2\n",
      "1   BÃ¬nh   NaN  18000000.0  Marketing            5\n",
      "2    Chi  30.0         NaN       None            7\n",
      "3   DÅ©ng  28.0  22000000.0         IT            3\n",
      "4    Eva   NaN  16000000.0  Marketing            1\n",
      "5  Phong  35.0         NaN         IT           10\n",
      "6  Giang   NaN  25000000.0         HR            8\n",
      "7    Hoa  32.0         NaN         HR            6\n",
      "\n",
      "ğŸ”§ CÃ¡c cá»™t sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng: ['Tuá»•i', 'LÆ°Æ¡ng', 'Kinh nghiá»‡m', 'PhÃ²ng ban_encoded']\n",
      "ğŸ“ˆ Ma tráº­n dá»¯ liá»‡u sá»‘ (cÃ³ missing values):\n",
      "   Tuá»•i       LÆ°Æ¡ng  Kinh nghiá»‡m  PhÃ²ng ban_encoded\n",
      "0  25.0  15000000.0            2                  1\n",
      "1   NaN  18000000.0            5                  2\n",
      "2  30.0         NaN            7                  3\n",
      "3  28.0  22000000.0            3                  1\n",
      "4   NaN  16000000.0            1                  2\n",
      "5  35.0         NaN           10                  1\n",
      "6   NaN  25000000.0            8                  0\n",
      "7  32.0         NaN            6                  0\n",
      "\n",
      "ğŸ“Š Missing Data Pattern:\n",
      "    Tuá»•i  LÆ°Æ¡ng  Kinh nghiá»‡m  PhÃ²ng ban_encoded\n",
      "0  False  False        False              False\n",
      "1   True  False        False              False\n",
      "2  False   True        False              False\n",
      "3  False  False        False              False\n",
      "4   True  False        False              False\n",
      "5  False   True        False              False\n",
      "6   True  False        False              False\n",
      "7  False   True        False              False\n",
      "\n",
      "ğŸ¤– Ãp dá»¥ng KNN Imputation vá»›i k=2 neighbors:\n",
      "\n",
      "âœ… Káº¿t quáº£ sau KNN Imputation:\n",
      "     TÃªn  Tuá»•i       LÆ°Æ¡ng  PhÃ²ng ban  Kinh nghiá»‡m\n",
      "0     An  25.0  15000000.0         IT          2.0\n",
      "1   BÃ¬nh  31.0  18000000.0  Marketing          5.0\n",
      "2    Chi  30.0  21500000.0       None          7.0\n",
      "3   DÅ©ng  28.0  22000000.0         IT          3.0\n",
      "4    Eva  31.0  16000000.0  Marketing          1.0\n",
      "5  Phong  35.0  21500000.0         IT         10.0\n",
      "6  Giang  33.5  25000000.0         HR          8.0\n",
      "7    Hoa  32.0  21500000.0         HR          6.0\n",
      "\n",
      "ğŸ“Š So sÃ¡nh Missing Values:\n",
      "TrÆ°á»›c: 6 missing values\n",
      "Sau: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¯ DEMO 3: KNN Imputation - Äiá»n táº¥t cáº£ missing values cÃ¹ng lÃºc\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Chuáº©n bá»‹ dá»¯ liá»‡u cho KNN\n",
    "df_knn = df_advanced.copy()\n",
    "print(\"ğŸ“Š Dá»¯ liá»‡u trÆ°á»›c KNN Imputation:\")\n",
    "print(df_knn)\n",
    "\n",
    "# Encode categorical data\n",
    "df_knn['PhÃ²ng ban_encoded'] = le_dept.fit_transform(df_knn['PhÃ²ng ban'].fillna('Unknown'))\n",
    "\n",
    "# Chá»‰ láº¥y cÃ¡c cá»™t sá»‘ cho KNN Imputation\n",
    "numerical_cols = ['Tuá»•i', 'LÆ°Æ¡ng', 'Kinh nghiá»‡m', 'PhÃ²ng ban_encoded']\n",
    "df_numerical = df_knn[numerical_cols].copy()\n",
    "\n",
    "print(f\"\\nğŸ”§ CÃ¡c cá»™t sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng: {numerical_cols}\")\n",
    "print(\"ğŸ“ˆ Ma tráº­n dá»¯ liá»‡u sá»‘ (cÃ³ missing values):\")\n",
    "print(df_numerical)\n",
    "\n",
    "# Hiá»ƒn thá»‹ missing pattern\n",
    "print(f\"\\nğŸ“Š Missing Data Pattern:\")\n",
    "missing_pattern = df_numerical.isnull()\n",
    "print(missing_pattern)\n",
    "\n",
    "# Ãp dá»¥ng KNN Imputation\n",
    "print(f\"\\nğŸ¤– Ãp dá»¥ng KNN Imputation vá»›i k=2 neighbors:\")\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "df_knn_filled = knn_imputer.fit_transform(df_numerical)\n",
    "\n",
    "# Chuyá»ƒn Ä‘á»•i láº¡i thÃ nh DataFrame  \n",
    "df_knn_result = df_knn.copy()\n",
    "df_knn_result['Tuá»•i'] = df_knn_filled[:, 0]\n",
    "df_knn_result['LÆ°Æ¡ng'] = df_knn_filled[:, 1] \n",
    "df_knn_result['Kinh nghiá»‡m'] = df_knn_filled[:, 2]\n",
    "\n",
    "print(f\"\\nâœ… Káº¿t quáº£ sau KNN Imputation:\")\n",
    "result_display = df_knn_result[['TÃªn', 'Tuá»•i', 'LÆ°Æ¡ng', 'PhÃ²ng ban', 'Kinh nghiá»‡m']].copy()\n",
    "result_display['Tuá»•i'] = result_display['Tuá»•i'].round(1)\n",
    "result_display['LÆ°Æ¡ng'] = result_display['LÆ°Æ¡ng'].round(0)\n",
    "print(result_display)\n",
    "\n",
    "# So sÃ¡nh missing values trÆ°á»›c vÃ  sau\n",
    "print(f\"\\nğŸ“Š So sÃ¡nh Missing Values:\")\n",
    "print(f\"TrÆ°á»›c: {df_knn[numerical_cols[:-1]].isnull().sum().sum()} missing values\")\n",
    "print(f\"Sau: {pd.DataFrame(df_knn_filled[:, :-1]).isnull().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd82704",
   "metadata": {},
   "source": [
    "#### **C. So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ Missing Values**\n",
    "\n",
    "**ğŸ“Š Báº£ng tá»•ng há»£p so sÃ¡nh:**\n",
    "\n",
    "| PhÆ°Æ¡ng phÃ¡p | Äá»™ phá»©c táº¡p | Thá»i gian | Äá»™ chÃ­nh xÃ¡c | PhÃ¹ há»£p vá»›i |\n",
    "|-------------|-------------|-----------|--------------|-------------|\n",
    "| **Mean/Median** | Tháº¥p â­ | Nhanh âš¡âš¡âš¡ | Tháº¥p ğŸ“Š | Dá»¯ liá»‡u Ä‘Æ¡n giáº£n, missing ngáº«u nhiÃªn |\n",
    "| **Mode** | Tháº¥p â­ | Nhanh âš¡âš¡âš¡ | Tháº¥p ğŸ“Š | Categorical data vá»›i Ã­t categories |\n",
    "| **Forward/Backward Fill** | Tháº¥p â­ | Nhanh âš¡âš¡âš¡ | Trung bÃ¬nh ğŸ“ŠğŸ“Š | Time series data |\n",
    "| **Random Forest** | Cao â­â­â­ | Cháº­m âš¡ | Cao ğŸ“ŠğŸ“ŠğŸ“Š | Dá»¯ liá»‡u cÃ³ quan há»‡ phá»©c táº¡p |\n",
    "| **KNN Imputation** | Trung bÃ¬nh â­â­ | Trung bÃ¬nh âš¡âš¡ | Cao ğŸ“ŠğŸ“ŠğŸ“Š | Dá»¯ liá»‡u cÃ³ local patterns |\n",
    "\n",
    "**ğŸ¯ HÆ°á»›ng dáº«n lá»±a chá»n phÆ°Æ¡ng phÃ¡p:**\n",
    "\n",
    "**ğŸ“ˆ Dá»¯ liá»‡u sá»‘ (Numerical):**\n",
    "- **< 5% missing**: Mean/Median\n",
    "- **5-20% missing + cÃ³ correlation**: KNN hoáº·c Random Forest  \n",
    "- **> 20% missing**: CÃ¢n nháº¯c loáº¡i bá» cá»™t hoáº·c thu tháº­p thÃªm dá»¯ liá»‡u\n",
    "\n",
    "**ğŸ·ï¸ Dá»¯ liá»‡u phÃ¢n loáº¡i (Categorical):**\n",
    "- **< 10% missing**: Mode\n",
    "- **> 10% missing + cÃ³ relationship**: Random Forest Classification\n",
    "- **High cardinality**: Táº¡o category \"Unknown\"\n",
    "\n",
    "**â° Dá»¯ liá»‡u thá»i gian (Time Series):**\n",
    "- **Forward fill**: Cho dá»¯ liá»‡u stable (giÃ¡ cá»• phiáº¿u)\n",
    "- **Backward fill**: Cho dá»¯ liá»‡u cÃ³ trend  \n",
    "- **Interpolation**: Cho dá»¯ liá»‡u smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372d7dc",
   "metadata": {},
   "source": [
    "## Xá»­ lÃ½ dá»¯ liá»‡u trÃ¹ng láº·p (Duplicate Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77a20c",
   "metadata": {},
   "source": [
    "### Hiá»ƒu vá» dá»¯ liá»‡u trÃ¹ng láº·p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf5e95",
   "metadata": {},
   "source": [
    "**ğŸ”„ Dá»¯ liá»‡u trÃ¹ng láº·p lÃ  gÃ¬?**\n",
    "\n",
    "Dá»¯ liá»‡u trÃ¹ng láº·p (*duplicate data*) lÃ  nhá»¯ng **hÃ ng cÃ³ giÃ¡ trá»‹ giá»‘ng há»‡t nhau** trÃªn táº¥t cáº£ hoáº·c má»™t sá»‘ cá»™t nháº¥t Ä‘á»‹nh. Dá»¯ liá»‡u trÃ¹ng láº·p cÃ³ thá»ƒ xuáº¥t hiá»‡n do:\n",
    "\n",
    "- **Lá»—i nháº­p liá»‡u**: NgÆ°á»i dÃ¹ng vÃ´ tÃ¬nh nháº­p cÃ¹ng má»™t thÃ´ng tin nhiá»u láº§n\n",
    "- **Lá»—i há»‡ thá»‘ng**: Há»‡ thá»‘ng ghi nháº­n cÃ¹ng má»™t sá»± kiá»‡n nhiá»u láº§n  \n",
    "- **Gá»™p dá»¯ liá»‡u**: Khi káº¿t há»£p nhiá»u nguá»“n dá»¯ liá»‡u cÃ³ thÃ´ng tin chá»“ng chÃ©o\n",
    "- **Lá»—i thu tháº­p**: Cáº£m biáº¿n hoáº·c thiáº¿t bá»‹ ghi nháº­n dá»¯ liá»‡u bá»‹ láº·p\n",
    "\n",
    "**âš ï¸ TÃ¡c Ä‘á»™ng cá»§a dá»¯ liá»‡u trÃ¹ng láº·p**\n",
    "\n",
    "- **ThiÃªn lá»‡ch phÃ¢n tÃ­ch**: Má»™t quan sÃ¡t Ä‘Æ°á»£c tÃ­nh nhiá»u láº§n, lÃ m mÃ©o mÃ³ káº¿t quáº£\n",
    "- **Giáº£m hiá»‡u quáº£ tÃ­nh toÃ¡n**: Xá»­ lÃ½ dá»¯ liá»‡u thá»«a lÃ m cháº­m thuáº­t toÃ¡n\n",
    "- **TÄƒng kÃ­ch thÆ°á»›c dá»¯ liá»‡u**: LÃ£ng phÃ­ bá»™ nhá»› vÃ  khÃ´ng gian lÆ°u trá»¯\n",
    "- **áº¢nh hÆ°á»Ÿng mÃ´ hÃ¬nh**: Machine learning cÃ³ thá»ƒ há»c sai tá»« dá»¯ liá»‡u láº·p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a749036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "3    Alice   25     New York\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Khá»Ÿi táº¡o dá»¯ liá»‡u máº«u\n",
    "duplicate_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "    'age': [25, 30, 35, 25],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "duplicate_data = pd.DataFrame(duplicate_data)\n",
    "\n",
    "# In dá»¯ liá»‡u máº«u\n",
    "print(duplicate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed9e8f",
   "metadata": {},
   "source": [
    "### CÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¡t hiá»‡n vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÃ¹ng láº·p trong pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9479d87",
   "metadata": {},
   "source": [
    "Pandas cung cáº¥p cÃ¡c phÆ°Æ¡ng thá»©c Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÃ¹ng láº·p:\n",
    "\n",
    "| PhÆ°Æ¡ng thá»©c | MÃ´ táº£ | Tráº£ vá» |\n",
    "|-------------|-------|--------|\n",
    "| `duplicated()` | Kiá»ƒm tra tá»«ng hÃ ng cÃ³ bá»‹ trÃ¹ng láº·p khÃ´ng | Boolean Series |\n",
    "| `drop_duplicates()` | Loáº¡i bá» cÃ¡c hÃ ng trÃ¹ng láº·p | DataFrame khÃ´ng trÃ¹ng láº·p |\n",
    "\n",
    "**ğŸ“Š HÃ£y xem cÃ¡ch sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng thá»©c nÃ y:**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bdb44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n",
      "3    Alice   25     New York\n",
      "PhÃ¡t hiá»‡n duplicate rows:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "CÃ¡c hÃ ng bá»‹ duplicate:\n",
      "    name  age      city\n",
      "3  Alice   25  New York\n",
      "\n",
      "Äáº¿m sá»‘ lÆ°á»£ng duplicate:\n",
      "Tá»•ng sá»‘ duplicate: 1\n",
      "\n",
      " Xá»­ lÃ½ duplicate báº±ng cÃ¡ch loáº¡i bá»:\n",
      "      name  age         city\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Khá»Ÿi táº¡o dá»¯ liá»‡u máº«u\n",
    "duplicate_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "    'age': [25, 30, 35, 25],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "duplicate_data = pd.DataFrame(duplicate_data)\n",
    "\n",
    "# In dá»¯ liá»‡u máº«u\n",
    "print(duplicate_data)\n",
    "\n",
    "# PhÃ¡t hiá»‡n duplicate rows\n",
    "print(\"PhÃ¡t hiá»‡n duplicate rows:\")\n",
    "print(duplicate_data.duplicated())\n",
    "\n",
    "print(\"\\nCÃ¡c hÃ ng bá»‹ duplicate:\")\n",
    "print(duplicate_data[duplicate_data.duplicated()])\n",
    "\n",
    "print(\"\\nÄáº¿m sá»‘ lÆ°á»£ng duplicate:\")\n",
    "print(f\"Tá»•ng sá»‘ duplicate: {duplicate_data.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n Xá»­ lÃ½ duplicate báº±ng cÃ¡ch loáº¡i bá»:\")\n",
    "print(duplicate_data.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e951b8d",
   "metadata": {},
   "source": [
    "## Biáº¿n Ä‘á»•i vÃ  chuáº©n hÃ³a dá»¯ liá»‡u (Data Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b07aa",
   "metadata": {},
   "source": [
    "### Tá»•ng quan vá» biáº¿n Ä‘á»•i dá»¯ liá»‡u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449fd38",
   "metadata": {},
   "source": [
    "**ğŸ”„ Biáº¿n Ä‘á»•i dá»¯ liá»‡u lÃ  gÃ¬?**\n",
    "\n",
    "Biáº¿n Ä‘á»•i dá»¯ liá»‡u (*data transformation*) lÃ  quÃ¡ trÃ¬nh **chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u** tá»« Ä‘á»‹nh dáº¡ng nÃ y sang Ä‘á»‹nh dáº¡ng khÃ¡c Ä‘á»ƒ:\n",
    "\n",
    "- **Cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»¯ liá»‡u**: LÃ m cho dá»¯ liá»‡u phÃ¹ há»£p hÆ¡n cho phÃ¢n tÃ­ch\n",
    "- **Chuáº©n hÃ³a thang Ä‘o**: ÄÆ°a cÃ¡c biáº¿n vá» cÃ¹ng má»™t thang Ä‘o\n",
    "- **Giáº£m nhiá»…u**: Loáº¡i bá» cÃ¡c biáº¿n Ä‘á»™ng khÃ´ng mong muá»‘n\n",
    "- **Táº¡o biáº¿n má»›i**: Káº¿t há»£p hoáº·c biáº¿n Ä‘á»•i biáº¿n hiá»‡n cÃ³ Ä‘á»ƒ táº¡o thÃ´ng tin má»›i\n",
    "\n",
    "**ğŸ¯ CÃ¡c má»¥c tiÃªu chÃ­nh:**\n",
    "\n",
    "1. **Normalization**: ÄÆ°a dá»¯ liá»‡u vá» khoáº£ng [0,1]\n",
    "2. **Standardization**: ÄÆ°a dá»¯ liá»‡u vá» phÃ¢n phá»‘i chuáº©n (mean=0, std=1) \n",
    "3. **Scaling**: Äiá»u chá»‰nh thang Ä‘o cho phÃ¹ há»£p\n",
    "4. **Encoding**: Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u phÃ¢n loáº¡i thÃ nh sá»‘\n",
    "\n",
    "**ğŸ“‹ Khi nÃ o cáº§n biáº¿n Ä‘á»•i dá»¯ liá»‡u:**\n",
    "\n",
    "- CÃ¡c biáº¿n cÃ³ **Ä‘Æ¡n vá»‹ Ä‘o khÃ¡c nhau** (VND, USD, kg, cm)\n",
    "- Dá»¯ liá»‡u cÃ³ **pháº¡m vi giÃ¡ trá»‹ chÃªnh lá»‡ch lá»›n** (1-10 vs 1000-10000)\n",
    "- Sá»­ dá»¥ng **thuáº­t toÃ¡n nháº¡y cáº£m vá»›i thang Ä‘o** (KNN, SVM, Neural Networks)\n",
    "- **Cáº£i thiá»‡n hiá»‡u suáº¥t** cá»§a mÃ´ hÃ¬nh machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529a255",
   "metadata": {},
   "source": [
    "## ğŸ“Š DEMO: Táº¡i sao cáº§n chuáº©n hÃ³a dá»¯ liá»‡u?\n",
    "\n",
    "TrÆ°á»›c khi há»c cÃ¡c phÆ°Æ¡ng phÃ¡p, hÃ£y xem vÃ­ dá»¥ thá»±c táº¿:\n",
    "\n",
    "### ğŸ¢ VÃ­ dá»¥: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty\n",
    "```\n",
    "NhÃ¢n viÃªn A: LÆ°Æ¡ng 15,000,000 VND, Tuá»•i 25, Kinh nghiá»‡m 2 nÄƒm\n",
    "NhÃ¢n viÃªn B: LÆ°Æ¡ng 25,000,000 VND, Tuá»•i 35, Kinh nghiá»‡m 8 nÄƒm\n",
    "```\n",
    "\n",
    "**âŒ Váº¥n Ä‘á»:** Thuáº­t toÃ¡n sáº½ coi LÆ°Æ¡ng quan trá»ng hÆ¡n vÃ¬ giÃ¡ trá»‹ lá»›n!\n",
    "\n",
    "**âœ… Giáº£i phÃ¡p:** Chuáº©n hÃ³a Ä‘á»ƒ Ä‘Æ°a vá» cÃ¹ng thang Ä‘o [0,1]\n",
    "\n",
    "---\n",
    "\n",
    "### Min-Max Normalization (Chuáº©n hÃ³a Min-Max)\n",
    "\n",
    "**ğŸ“ CÃ´ng thá»©c Ä‘Æ¡n giáº£n:**\n",
    "```\n",
    "GiÃ¡ trá»‹ má»›i = (GiÃ¡ trá»‹ cÅ© - Min) / (Max - Min)\n",
    "```\n",
    "\n",
    "**ğŸ¯ Káº¿t quáº£:** Táº¥t cáº£ giÃ¡ trá»‹ náº±m trong khoáº£ng [0, 1]\n",
    "\n",
    "**âœ… Æ¯u Ä‘iá»ƒm:**\n",
    "- Dá»… hiá»ƒu vÃ  tÃ­nh toÃ¡n\n",
    "- Báº£o toÃ n phÃ¢n phá»‘i gá»‘c\n",
    "- PhÃ¹ há»£p vá»›i dá»¯ liá»‡u khÃ´ng cÃ³ outliers\n",
    "\n",
    "**âŒ NhÆ°á»£c Ä‘iá»ƒm:**\n",
    "- Nháº¡y cáº£m vá»›i outliers (giÃ¡ trá»‹ ngoáº¡i lai)\n",
    "- Náº¿u cÃ³ giÃ¡ trá»‹ ráº¥t lá»›n, cÃ¡c giÃ¡ trá»‹ khÃ¡c sáº½ bá»‹ \"nÃ©n\" vá» gáº§n 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05eac5",
   "metadata": {},
   "source": [
    "**ğŸ“ CÃ´ng thá»©c chi tiáº¿t:**\n",
    "\n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "**ğŸ” Giáº£i thÃ­ch tá»«ng pháº§n:**\n",
    "- $X$ = giÃ¡ trá»‹ gá»‘c\n",
    "- $X_{min}$ = giÃ¡ trá»‹ nhá» nháº¥t trong cá»™t\n",
    "- $X_{max}$ = giÃ¡ trá»‹ lá»›n nháº¥t trong cá»™t\n",
    "- Káº¿t quáº£ luÃ´n náº±m trong khoáº£ng [0, 1]\n",
    "\n",
    "**ğŸ“Š VÃ­ dá»¥ minh há»a:**\n",
    "```\n",
    "Dá»¯ liá»‡u gá»‘c: [10, 20, 30, 40, 50]\n",
    "Min = 10, Max = 50\n",
    "\n",
    "GiÃ¡ trá»‹ 20 â†’ (20-10)/(50-10) = 10/40 = 0.25\n",
    "GiÃ¡ trá»‹ 40 â†’ (40-10)/(50-10) = 30/40 = 0.75\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a39c847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¢ VÃ Dá»¤: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty\n",
      "==================================================\n",
      "ğŸ“‹ Dá»¯ liá»‡u gá»‘c:\n",
      "    Ten     Luong  Tuoi  KinhNghiem\n",
      "0    An  15000000    25           2\n",
      "1  BÃ¬nh  25000000    35           8\n",
      "2   Chi  30000000    40          12\n",
      "3  DÅ©ng  18000000    28           3\n",
      "4   Eva  22000000    32           6\n",
      "\n",
      "ğŸ“Š Thá»‘ng kÃª mÃ´ táº£:\n",
      "              Luong      Tuoi  KinhNghiem\n",
      "count  5.000000e+00   5.00000    5.000000\n",
      "mean   2.200000e+07  32.00000    6.200000\n",
      "std    5.873670e+06   5.87367    4.024922\n",
      "min    1.500000e+07  25.00000    2.000000\n",
      "25%    1.800000e+07  28.00000    3.000000\n",
      "50%    2.200000e+07  32.00000    6.000000\n",
      "75%    2.500000e+07  35.00000    8.000000\n",
      "max    3.000000e+07  40.00000   12.000000\n",
      "\n",
      "ğŸ”§ Ãp dá»¥ng Min-Max Normalization:\n",
      "âœ… Káº¿t quáº£ sau chuáº©n hÃ³a:\n",
      "    Ten     Luong      Tuoi  KinhNghiem\n",
      "0    An  0.000000  0.000000         0.0\n",
      "1  BÃ¬nh  0.666667  0.666667         0.6\n",
      "2   Chi  1.000000  1.000000         1.0\n",
      "3  DÅ©ng  0.200000  0.200000         0.1\n",
      "4   Eva  0.466667  0.466667         0.4\n",
      "\n",
      "ğŸ“ˆ So sÃ¡nh trÆ°á»›c vÃ  sau:\n",
      "TrÆ°á»›c: LÆ°Æ¡ng cÃ³ giÃ¡ trá»‹ tá»« 15M-30M, Tuá»•i tá»« 25-40\n",
      "Sau: Táº¥t cáº£ giÃ¡ trá»‹ tá»« 0.0-1.0\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š DEMO: Min-Max Normalization vá»›i dá»¯ liá»‡u thá»±c táº¿\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Táº¡o dá»¯ liá»‡u nhÃ¢n viÃªn vá»›i cÃ¡c thang Ä‘o khÃ¡c nhau\n",
    "print(\"ğŸ¢ VÃ Dá»¤: Dá»¯ liá»‡u nhÃ¢n viÃªn cÃ´ng ty\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'Ten': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva'],\n",
    "    'Luong': [15000000, 25000000, 30000000, 18000000, 22000000],  # VND/thÃ¡ng\n",
    "    'Tuoi': [25, 35, 40, 28, 32],  # nÄƒm\n",
    "    'KinhNghiem': [2, 8, 12, 3, 6]  # nÄƒm\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"ğŸ“‹ Dá»¯ liá»‡u gá»‘c:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\nğŸ“Š Thá»‘ng kÃª mÃ´ táº£:\")\n",
    "print(df_nhanvien[['Luong', 'Tuoi', 'KinhNghiem']].describe())\n",
    "\n",
    "# Ãp dá»¥ng Min-Max Normalization\n",
    "print(f\"\\nğŸ”§ Ãp dá»¥ng Min-Max Normalization:\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Chuáº©n hÃ³a cÃ¡c cá»™t sá»‘\n",
    "df_normalized = df_nhanvien.copy()\n",
    "df_normalized[['Luong', 'Tuoi', 'KinhNghiem']] = scaler.fit_transform(\n",
    "    df_nhanvien[['Luong', 'Tuoi', 'KinhNghiem']]\n",
    ")\n",
    "\n",
    "print(\"âœ… Káº¿t quáº£ sau chuáº©n hÃ³a:\")\n",
    "print(df_normalized)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ So sÃ¡nh trÆ°á»›c vÃ  sau:\")\n",
    "print(\"TrÆ°á»›c: LÆ°Æ¡ng cÃ³ giÃ¡ trá»‹ tá»« 15M-30M, Tuá»•i tá»« 25-40\")\n",
    "print(\"Sau: Táº¥t cáº£ giÃ¡ trá»‹ tá»« 0.0-1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068c457",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Œ TÃ“M Táº®T PHáº¦N 3: CHUáº¨N HÃ“A Dá»® LIá»†U\n",
    "\n",
    "### âœ… Kiáº¿n thá»©c Ä‘Ã£ há»c:\n",
    "1. âœ… MinMaxScaler: ÄÆ°a dá»¯ liá»‡u vá» [0,1]\n",
    "2. âœ… StandardScaler: Mean=0, Std=1\n",
    "3. âœ… RobustScaler: Sá»­ dá»¥ng median vÃ  IQR\n",
    "\n",
    "### ğŸ“Š So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p Scaling:\n",
    "\n",
    "| PhÆ°Æ¡ng phÃ¡p | Khoáº£ng giÃ¡ trá»‹ | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm | Khi nÃ o dÃ¹ng |\n",
    "|-------------|----------------|---------|------------|--------------|\n",
    "| **MinMaxScaler** | [0, 1] | ÄÆ¡n giáº£n, báº£o toÃ n phÃ¢n phá»‘i | Nháº¡y cáº£m vá»›i outliers | Dá»¯ liá»‡u khÃ´ng cÃ³ outliers |\n",
    "| **StandardScaler** | Mean=0, Std=1 | PhÃ¹ há»£p vá»›i thuáº­t toÃ¡n tuyáº¿n tÃ­nh | Váº«n bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers | Dá»¯ liá»‡u cÃ³ phÃ¢n phá»‘i chuáº©n |\n",
    "| **RobustScaler** | Median=0, IQR=1 | Bá»n vá»¯ng vá»›i outliers | Phá»©c táº¡p hÆ¡n | Dá»¯ liá»‡u cÃ³ nhiá»u outliers |\n",
    "\n",
    "### âš ï¸ Lá»—i thÆ°á»ng gáº·p:\n",
    "âŒ QuÃªn fit scaler trÃªn training data trÆ°á»›c khi transform  \n",
    "âŒ DÃ¹ng MinMaxScaler cho dá»¯ liá»‡u cÃ³ outliers  \n",
    "âŒ Transform cáº£ training vÃ  test data cÃ¹ng lÃºc\n",
    "\n",
    "### ğŸ’¡ Tips:\n",
    "- LuÃ´n fit scaler trÃªn training data\n",
    "- DÃ¹ng RobustScaler khi cÃ³ outliers\n",
    "- Save scaler Ä‘á»ƒ transform test data sau\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978ba47",
   "metadata": {},
   "source": [
    "### Standard Scaler (Z-score Standardization)\n",
    "\n",
    "**ğŸ“ CÃ´ng thá»©c Ä‘Æ¡n giáº£n:**\n",
    "```\n",
    "GiÃ¡ trá»‹ má»›i = (GiÃ¡ trá»‹ cÅ© - Trung bÃ¬nh) / Äá»™ lá»‡ch chuáº©n\n",
    "```\n",
    "\n",
    "**ğŸ¯ Káº¿t quáº£:** Mean = 0, Standard Deviation = 1\n",
    "\n",
    "**âœ… Æ¯u Ä‘iá»ƒm:**\n",
    "- KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng nhiá»u bá»Ÿi outliers\n",
    "- PhÃ¹ há»£p vá»›i thuáº­t toÃ¡n tuyáº¿n tÃ­nh (Linear Regression, Logistic Regression)\n",
    "- Báº£o toÃ n thÃ´ng tin vá» phÃ¢n phá»‘i gá»‘c\n",
    "\n",
    "**âŒ NhÆ°á»£c Ä‘iá»ƒm:**\n",
    "- Váº«n bá»‹ áº£nh hÆ°á»Ÿng má»™t pháº§n bá»Ÿi outliers\n",
    "- Phá»©c táº¡p hÆ¡n Min-Max\n",
    "\n",
    "**ğŸ“Š VÃ­ dá»¥ minh há»a:**\n",
    "```\n",
    "Dá»¯ liá»‡u gá»‘c: [10, 20, 30, 40, 50]\n",
    "Mean = 30, Std = 15.81\n",
    "\n",
    "GiÃ¡ trá»‹ 20 â†’ (20-30)/15.81 = -0.63\n",
    "GiÃ¡ trá»‹ 40 â†’ (40-30)/15.81 = 0.63\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce3d87",
   "metadata": {},
   "source": [
    "**ğŸ“Š CÃ´ng thá»©c Z-score Standardization:**\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- $X$ = giÃ¡ trá»‹ gá»‘c\n",
    "- $\\mu$ = giÃ¡ trá»‹ trung bÃ¬nh (mean)\n",
    "- $\\sigma$ = Ä‘á»™ lá»‡ch chuáº©n (standard deviation)\n",
    "\n",
    "**ğŸ¯ Äáº·c Ä‘iá»ƒm:**\n",
    "- ÄÆ°a dá»¯ liá»‡u vá» **phÃ¢n phá»‘i chuáº©n** vá»›i mean=0, std=1\n",
    "- **KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng** bá»Ÿi outliers nhiá»u nhÆ° Min-Max\n",
    "- **Báº£o toÃ n thÃ´ng tin** vá» phÃ¢n phá»‘i gá»‘c\n",
    "- PhÃ¹ há»£p vá»›i **cÃ¡c thuáº­t toÃ¡n giáº£ Ä‘á»‹nh phÃ¢n phá»‘i chuáº©n** (Linear Regression, Logistic Regression)\n",
    "\n",
    "**ğŸ”§ Sá»­ dá»¥ng `StandardScaler` tá»« scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01fb4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¢ VÃ Dá»¤: Standard Scaler vá»›i dá»¯ liá»‡u nhÃ¢n viÃªn\n",
      "=======================================================\n",
      "ğŸ“‹ Dá»¯ liá»‡u gá»‘c:\n",
      "    Ten     Luong  Tuoi  KinhNghiem\n",
      "0    An  15000000    25           2\n",
      "1  BÃ¬nh  25000000    35           8\n",
      "2   Chi  30000000    40          12\n",
      "3  DÅ©ng  18000000    28           3\n",
      "4   Eva  22000000    32           6\n",
      "\n",
      "ğŸ”§ Ãp dá»¥ng Standard Scaler:\n",
      "âœ… Káº¿t quáº£ sau standardization:\n",
      "    Ten     Luong      Tuoi  KinhNghiem\n",
      "0    An -1.332427 -1.332427   -1.166667\n",
      "1  BÃ¬nh  0.571040  0.571040    0.500000\n",
      "2   Chi  1.522774  1.522774    1.611111\n",
      "3  DÅ©ng -0.761387 -0.761387   -0.888889\n",
      "4   Eva  0.000000  0.000000   -0.055556\n",
      "\n",
      "ğŸ“Š Kiá»ƒm tra Mean vÃ  Std:\n",
      "Mean cá»§a cÃ¡c cá»™t: [ 0. -0. -0.]\n",
      "Std cá»§a cÃ¡c cá»™t: [1.118 1.118 1.118]\n",
      "âœ… Mean â‰ˆ 0, Std â‰ˆ 1 (nhÆ° mong Ä‘á»£i!)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š DEMO: Standard Scaler vá»›i dá»¯ liá»‡u thá»±c táº¿\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sá»­ dá»¥ng dá»¯ liá»‡u nhÃ¢n viÃªn tá»« vÃ­ dá»¥ trÆ°á»›c\n",
    "print(\"ğŸ¢ VÃ Dá»¤: Standard Scaler vá»›i dá»¯ liá»‡u nhÃ¢n viÃªn\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'Ten': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva'],\n",
    "    'Luong': [15000000, 25000000, 30000000, 18000000, 22000000],\n",
    "    'Tuoi': [25, 35, 40, 28, 32],\n",
    "    'KinhNghiem': [2, 8, 12, 3, 6]\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"ğŸ“‹ Dá»¯ liá»‡u gá»‘c:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "# Ãp dá»¥ng Standard Scaler\n",
    "print(f\"\\nğŸ”§ Ãp dá»¥ng Standard Scaler:\")\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "df_standardized = df_nhanvien.copy()\n",
    "df_standardized[['Luong', 'Tuoi', 'KinhNghiem']] = scaler_std.fit_transform(\n",
    "    df_nhanvien[['Luong', 'Tuoi', 'KinhNghiem']]\n",
    ")\n",
    "\n",
    "print(\"âœ… Káº¿t quáº£ sau standardization:\")\n",
    "print(df_standardized)\n",
    "\n",
    "# Kiá»ƒm tra mean â‰ˆ 0 vÃ  std â‰ˆ 1\n",
    "print(f\"\\nğŸ“Š Kiá»ƒm tra Mean vÃ  Std:\")\n",
    "print(\"Mean cá»§a cÃ¡c cá»™t:\", df_standardized[['Luong', 'Tuoi', 'KinhNghiem']].mean().round(4).values)\n",
    "print(\"Std cá»§a cÃ¡c cá»™t:\", df_standardized[['Luong', 'Tuoi', 'KinhNghiem']].std().round(4).values)\n",
    "print(\"âœ… Mean â‰ˆ 0, Std â‰ˆ 1 (nhÆ° mong Ä‘á»£i!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d372e",
   "metadata": {},
   "source": [
    "### Robust Scaler (Sá»­ dá»¥ng Median vÃ  IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d20b9",
   "metadata": {},
   "source": [
    "**ğŸ“ˆ CÃ´ng thá»©c Robust Scaling:**\n",
    "\n",
    "$$X_{robust} = \\frac{X - X_{median}}{IQR}$$\n",
    "\n",
    "Trong Ä‘Ã³:\n",
    "- $X_{median}$ = giÃ¡ trá»‹ trung vá»‹ (median)\n",
    "- $IQR$ = Interquartile Range = Q3 - Q1\n",
    "\n",
    "**ğŸ›¡ï¸ Äáº·c Ä‘iá»ƒm:**\n",
    "- **Ráº¥t bá»n vá»¯ng** (*robust*) trÆ°á»›c outliers\n",
    "- Sá»­ dá»¥ng **median thay vÃ¬ mean**, **IQR thay vÃ¬ std**\n",
    "- **KhÃ´ng bá»‹ mÃ©o** bá»Ÿi cÃ¡c giÃ¡ trá»‹ ngoáº¡i lai\n",
    "- PhÃ¹ há»£p khi dá»¯ liá»‡u cÃ³ **nhiá»u outliers**\n",
    "\n",
    "**ğŸ¯ Khi nÃ o sá»­ dá»¥ng Robust Scaler:**\n",
    "- **Dá»¯ liá»‡u cÃ³ nhiá»u outliers** \n",
    "- **KhÃ´ng muá»‘n loáº¡i bá» outliers** nhÆ°ng váº«n cáº§n chuáº©n hÃ³a\n",
    "- **Dá»¯ liá»‡u khÃ´ng tuÃ¢n theo phÃ¢n phá»‘i chuáº©n**\n",
    "\n",
    "**ğŸ”§ Sá»­ dá»¥ng `RobustScaler` tá»« scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a796d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»¯ liá»‡u cÃ³ outliers:\n",
      "       LÆ°Æ¡ng  Tuá»•i  Kinh nghiá»‡m\n",
      "0   15000000    25            2\n",
      "1   25000000    35            8\n",
      "2   30000000    40           12\n",
      "3   18000000    28            3\n",
      "4   22000000    32            6\n",
      "5  200000000    22            1\n",
      "\n",
      "MÃ´ táº£ thá»‘ng kÃª:\n",
      "              LÆ°Æ¡ng       Tuá»•i  Kinh nghiá»‡m\n",
      "count  6.000000e+00   6.000000     6.000000\n",
      "mean   5.166667e+07  30.333333     5.333333\n",
      "std    7.285785e+07   6.653320     4.179314\n",
      "min    1.500000e+07  22.000000     1.000000\n",
      "25%    1.900000e+07  25.750000     2.250000\n",
      "50%    2.350000e+07  30.000000     4.500000\n",
      "75%    2.875000e+07  34.250000     7.500000\n",
      "max    2.000000e+08  40.000000    12.000000\n",
      "\n",
      "============================================================\n",
      "SO SÃNH CÃC PHÆ¯Æ NG PHÃP SCALING Vá»šI OUTLIERS\n",
      "============================================================\n",
      "\n",
      "1. MinMax Scaler (bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers):\n",
      "      LÆ°Æ¡ng      Tuá»•i  Kinh nghiá»‡m\n",
      "0  0.000000  0.166667     0.090909\n",
      "1  0.054054  0.722222     0.636364\n",
      "2  0.081081  1.000000     1.000000\n",
      "3  0.016216  0.333333     0.181818\n",
      "4  0.037838  0.555556     0.454545\n",
      "5  1.000000  0.000000     0.000000\n",
      "\n",
      "2. Standard Scaler (bá»‹ áº£nh hÆ°á»Ÿng má»™t pháº§n):\n",
      "      LÆ°Æ¡ng      Tuá»•i  Kinh nghiá»‡m\n",
      "0 -0.551297 -0.878114    -0.873704\n",
      "1 -0.400943  0.768350     0.698963\n",
      "2 -0.325766  1.591582     1.747408\n",
      "3 -0.506191 -0.384175    -0.611593\n",
      "4 -0.446049  0.274411     0.174741\n",
      "5  2.230247 -1.372053    -1.135815\n",
      "\n",
      "3. Robust Scaler (bá»n vá»¯ng trÆ°á»›c outliers):\n",
      "       LÆ°Æ¡ng      Tuá»•i  Kinh nghiá»‡m\n",
      "0  -0.871795 -0.588235    -0.476190\n",
      "1   0.153846  0.588235     0.666667\n",
      "2   0.666667  1.176471     1.428571\n",
      "3  -0.564103 -0.235294    -0.285714\n",
      "4  -0.153846  0.235294     0.285714\n",
      "5  18.102564 -0.941176    -0.666667\n"
     ]
    }
   ],
   "source": [
    "# Import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Táº¡o dá»¯ liá»‡u cÃ³ outliers\n",
    "data_with_outliers = {\n",
    "    'LÆ°Æ¡ng': [15000000, 25000000, 30000000, 18000000, 22000000, 200000000],  # outlier: 200M\n",
    "    'Tuá»•i': [25, 35, 40, 28, 32, 22],\n",
    "    'Kinh nghiá»‡m': [2, 8, 12, 3, 6, 1]\n",
    "}\n",
    "\n",
    "df_outliers = pd.DataFrame(data_with_outliers)\n",
    "print(\"Dá»¯ liá»‡u cÃ³ outliers:\")\n",
    "print(df_outliers)\n",
    "print(f\"\\nMÃ´ táº£ thá»‘ng kÃª:\")\n",
    "print(df_outliers.describe())\n",
    "\n",
    "# So sÃ¡nh 3 phÆ°Æ¡ng phÃ¡p scaling\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SO SÃNH CÃC PHÆ¯Æ NG PHÃP SCALING Vá»šI OUTLIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# MinMax Scaler (bá»‹ áº£nh hÆ°á»Ÿng máº¡nh bá»Ÿi outliers)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaled_minmax = scaler_minmax.fit_transform(df_outliers[['LÆ°Æ¡ng', 'Tuá»•i', 'Kinh nghiá»‡m']])\n",
    "print(\"\\n1. MinMax Scaler (bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers):\")\n",
    "print(pd.DataFrame(scaled_minmax, columns=['LÆ°Æ¡ng', 'Tuá»•i', 'Kinh nghiá»‡m']))\n",
    "\n",
    "# Standard Scaler (bá»‹ áº£nh hÆ°á»Ÿng má»™t pháº§n bá»Ÿi outliers)\n",
    "scaler_std = StandardScaler()\n",
    "scaled_std = scaler_std.fit_transform(df_outliers[['LÆ°Æ¡ng', 'Tuá»•i', 'Kinh nghiá»‡m']])\n",
    "print(\"\\n2. Standard Scaler (bá»‹ áº£nh hÆ°á»Ÿng má»™t pháº§n):\")\n",
    "print(pd.DataFrame(scaled_std, columns=['LÆ°Æ¡ng', 'Tuá»•i', 'Kinh nghiá»‡m']))\n",
    "\n",
    "# Robust Scaler (Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi outliers)\n",
    "scaler_robust = RobustScaler()\n",
    "scaled_robust = scaler_robust.fit_transform(df_outliers[['LÆ°Æ¡ng', 'Tuá»•i', 'Kinh nghiá»‡m']])\n",
    "print(\"\\n3. Robust Scaler (bá»n vá»¯ng trÆ°á»›c outliers):\")\n",
    "print(pd.DataFrame(scaled_robust, columns=['LÆ°Æ¡ng', 'Tuá»•i', 'Kinh nghiá»‡m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe95fbe",
   "metadata": {},
   "source": [
    "## Xá»­ lÃ½ chuá»—i kÃ½ tá»± (String Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544b9d0",
   "metadata": {},
   "source": [
    "### Táº§m quan trá»ng cá»§a viá»‡c xá»­ lÃ½ chuá»—i kÃ½ tá»±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4834c8a",
   "metadata": {},
   "source": [
    "**ğŸ“ Dá»¯ liá»‡u chuá»—i kÃ½ tá»± trong thá»±c táº¿**\n",
    "\n",
    "Dá»¯ liá»‡u chuá»—i kÃ½ tá»± (*string data*) chiáº¿m má»™t pháº§n lá»›n trong cÃ¡c bá»™ dá»¯ liá»‡u thá»±c táº¿:\n",
    "\n",
    "- **TÃªn ngÆ°á»i, Ä‘á»‹a chá»‰**: ThÃ´ng tin cÃ¡ nhÃ¢n\n",
    "- **MÃ´ táº£ sáº£n pháº©m**: Trong thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­\n",
    "- **BÃ¬nh luáº­n, Ä‘Ã¡nh giÃ¡**: Trong phÃ¢n tÃ­ch sentiment\n",
    "- **Danh má»¥c, nhÃ£n**: Dá»¯ liá»‡u phÃ¢n loáº¡i\n",
    "\n",
    "**ğŸ§¹ CÃ¡c váº¥n Ä‘á» thÆ°á»ng gáº·p vá»›i dá»¯ liá»‡u chuá»—i:**\n",
    "\n",
    "1. **KhÃ´ng nháº¥t quÃ¡n vá» Ä‘á»‹nh dáº¡ng**: \"iPhone\", \"iphone\", \"IPHONE\"\n",
    "2. **Khoáº£ng tráº¯ng thá»«a**: \"  Apple  \", \"Apple \"\n",
    "3. **KÃ½ tá»± Ä‘áº·c biá»‡t**: \"email@domain.com\", \"phone: +84-123-456-789\"\n",
    "4. **Viáº¿t táº¯t khÃ¡c nhau**: \"Dr.\", \"Doctor\", \"BS\"\n",
    "5. **Lá»—i chÃ­nh táº£**: \"Compnay\" thay vÃ¬ \"Company\"\n",
    "\n",
    "**ğŸ”§ Pandas String Accessor (`.str`)**\n",
    "\n",
    "Pandas cung cáº¥p **accessor `.str`** cho phÃ©p Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng thá»©c xá»­ lÃ½ chuá»—i lÃªn toÃ n bá»™ Series:\n",
    "\n",
    "```python\n",
    "# Thay vÃ¬ lÃ m thá»§ cÃ´ng tá»«ng pháº§n tá»­\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'column'] = df.loc[i, 'column'].upper()\n",
    "\n",
    "# Sá»­ dá»¥ng .str accessor\n",
    "df['column'] = df['column'].str.upper()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bfbce",
   "metadata": {},
   "source": [
    "### CÃ¡c phÆ°Æ¡ng thá»©c cÆ¡ báº£n xá»­ lÃ½ chuá»—i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337bbe7",
   "metadata": {},
   "source": [
    "**ğŸ“‹ Báº£ng tá»•ng há»£p cÃ¡c phÆ°Æ¡ng thá»©c quan trá»ng:**\n",
    "\n",
    "| PhÆ°Æ¡ng thá»©c | MÃ´ táº£ | VÃ­ dá»¥ |\n",
    "|-------------|-------|-------|\n",
    "| `.str.lower()` | Chuyá»ƒn vá» chá»¯ thÆ°á»ng | `\"HELLO\"` â†’ `\"hello\"` |\n",
    "| `.str.upper()` | Chuyá»ƒn vá» chá»¯ hoa | `\"hello\"` â†’ `\"HELLO\"` |\n",
    "| `.str.title()` | Viáº¿t hoa chá»¯ cÃ¡i Ä‘áº§u | `\"hello world\"` â†’ `\"Hello World\"` |\n",
    "| `.str.strip()` | Loáº¡i bá» khoáº£ng tráº¯ng Ä‘áº§u/cuá»‘i | `\"  hello  \"` â†’ `\"hello\"` |\n",
    "| `.str.replace()` | Thay tháº¿ chuá»—i con | `\"hello\"` â†’ `\"hi\"` |\n",
    "| `.str.contains()` | Kiá»ƒm tra chá»©a chuá»—i con | `\"hello world\"` contains `\"world\"` â†’ `True` |\n",
    "| `.str.startswith()` | Kiá»ƒm tra báº¯t Ä‘áº§u báº±ng | `\"hello\"` startswith `\"he\"` â†’ `True` |\n",
    "| `.str.endswith()` | Kiá»ƒm tra káº¿t thÃºc báº±ng | `\"hello\"` endswith `\"lo\"` â†’ `True` |\n",
    "| `.str.len()` | Äá»™ dÃ i chuá»—i | `\"hello\"` â†’ `5` |\n",
    "| `.str.split()` | TÃ¡ch chuá»—i | `\"a,b,c\"` â†’ `[\"a\", \"b\", \"c\"]` |\n",
    "\n",
    "**ğŸ”¥ HÃ£y xem cÃ¡c vÃ­ dá»¥ thá»±c táº¿:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c701e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»¯ liá»‡u gá»‘c vÃ  kiá»ƒu dá»¯ liá»‡u:\n",
      "id          object\n",
      "score       object\n",
      "date        object\n",
      "category    object\n",
      "dtype: object\n",
      "\n",
      "  id score        date category\n",
      "0  1  85.5  2023-01-01        A\n",
      "1  2  90.0  2023-01-02        B\n",
      "2  3  78.5  2023-01-03        A\n",
      "3  4  92.0  2023-01-04        C\n",
      "4  5  88.5  2023-01-05        B\n",
      "\n",
      "Sau khi chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u:\n",
      "id                   int64\n",
      "score              float64\n",
      "date        datetime64[ns]\n",
      "category          category\n",
      "dtype: object\n",
      "\n",
      "   id  score       date category\n",
      "0   1   85.5 2023-01-01        A\n",
      "1   2   90.0 2023-01-02        B\n",
      "2   3   78.5 2023-01-03        A\n",
      "3   4   92.0 2023-01-04        C\n",
      "4   5   88.5 2023-01-05        B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': ['1', '2', '3', '4', '5'],\n",
    "    'score': ['85.5', '90.0', '78.5', '92.0', '88.5'],\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'category': ['A', 'B', 'A', 'C', 'B']\n",
    "})\n",
    "\n",
    "print(\"Dá»¯ liá»‡u gá»‘c vÃ  kiá»ƒu dá»¯ liá»‡u:\")\n",
    "print(sample_data.dtypes)\n",
    "print()\n",
    "print(sample_data)\n",
    "\n",
    "# Chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u\n",
    "sample_data['id'] = sample_data['id'].astype('int64')\n",
    "sample_data['score'] = sample_data['score'].astype('float64')\n",
    "sample_data['date'] = pd.to_datetime(sample_data['date'])\n",
    "sample_data['category'] = sample_data['category'].astype('category')\n",
    "\n",
    "print(\"\\nSau khi chuyá»ƒn Ä‘á»•i kiá»ƒu dá»¯ liá»‡u:\")\n",
    "print(sample_data.dtypes)\n",
    "print()\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c64432",
   "metadata": {},
   "source": [
    "### Normalization vÃ  Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d22fbc",
   "metadata": {},
   "source": [
    "Normalization vÃ  standardization lÃ  cÃ¡c ká»¹ thuáº­t quan trá»ng Ä‘á»ƒ Ä‘Æ°a dá»¯ liá»‡u vá» cÃ¹ng má»™t thang Ä‘o, Ä‘áº·c biá»‡t há»¯u Ã­ch cho machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cbffc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»¯ liá»‡u gá»‘c:\n",
      "   height  weight  income\n",
      "0     150      50   30000\n",
      "1     160      60   45000\n",
      "2     170      70   60000\n",
      "3     180      80   75000\n",
      "4     190      90   90000\n",
      "\n",
      "MÃ´ táº£ thá»‘ng kÃª:\n",
      "           height     weight        income\n",
      "count    5.000000   5.000000      5.000000\n",
      "mean   170.000000  70.000000  60000.000000\n",
      "std     15.811388  15.811388  23717.082451\n",
      "min    150.000000  50.000000  30000.000000\n",
      "25%    160.000000  60.000000  45000.000000\n",
      "50%    170.000000  70.000000  60000.000000\n",
      "75%    180.000000  80.000000  75000.000000\n",
      "max    190.000000  90.000000  90000.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Táº¡o dá»¯ liá»‡u máº«u cho normalization\n",
    "norm_data = pd.DataFrame({\n",
    "    'height': [150, 160, 170, 180, 190],  # cm\n",
    "    'weight': [50, 60, 70, 80, 90],       # kg  \n",
    "    'income': [30000, 45000, 60000, 75000, 90000]  # VND/month\n",
    "})\n",
    "\n",
    "print(\"Dá»¯ liá»‡u gá»‘c:\")\n",
    "print(norm_data)\n",
    "print(\"\\nMÃ´ táº£ thá»‘ng kÃª:\")\n",
    "print(norm_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2fc07",
   "metadata": {},
   "source": [
    "### ğŸ” Regular Expressions (Regex) - TÃ¬m kiáº¿m thÃ´ng minh trong vÄƒn báº£n\n",
    "\n",
    "## ğŸ“š Regex lÃ  gÃ¬ vÃ  táº¡i sao cáº§n thiáº¿t?\n",
    "\n",
    "**ğŸ” Regular Expressions (Regex)** lÃ  má»™t **cÃ´ng cá»¥ tÃ¬m kiáº¿m thÃ´ng minh** giÃºp báº¡n tÃ¬m vÃ  xá»­ lÃ½ cÃ¡c máº«u vÄƒn báº£n má»™t cÃ¡ch tá»± Ä‘á»™ng.\n",
    "\n",
    "### ğŸ¢ VÃ­ dá»¥ thá»±c táº¿ trong kinh doanh:\n",
    "\n",
    "**TÃ¬nh huá»‘ng:** Báº¡n cÃ³ 1000 email khÃ¡ch hÃ ng vÃ  cáº§n:\n",
    "- âœ… TÃ¬m táº¥t cáº£ sá»‘ Ä‘iá»‡n thoáº¡i trong email\n",
    "- âœ… Kiá»ƒm tra email cÃ³ há»£p lá»‡ khÃ´ng  \n",
    "- âœ… TÃ¡ch tÃªn vÃ  Ä‘á»‹a chá»‰ tá»« chuá»—i vÄƒn báº£n\n",
    "- âœ… TÃ¬m cÃ¡c tá»« khÃ³a quan trá»ng\n",
    "\n",
    "**âŒ LÃ m thá»§ cÃ´ng:** Máº¥t hÃ ng giá», dá»… sai sÃ³t  \n",
    "**âœ… DÃ¹ng Regex:** Chá»‰ vÃ i dÃ²ng code, chÃ­nh xÃ¡c 100%\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Hiá»ƒu Regex qua vÃ­ dá»¥ Ä‘Æ¡n giáº£n\n",
    "\n",
    "### VÃ­ dá»¥ 1: TÃ¬m sá»‘ Ä‘iá»‡n thoáº¡i\n",
    "```\n",
    "VÄƒn báº£n: \"LiÃªn há»‡ tÃ´i qua 0123-456-789 hoáº·c 0987654321\"\n",
    "Regex: \\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}\n",
    "Káº¿t quáº£: \"0123-456-789\", \"0987654321\"\n",
    "```\n",
    "\n",
    "### VÃ­ dá»¥ 2: TÃ¬m email\n",
    "```\n",
    "VÄƒn báº£n: \"Email: john@gmail.com hoáº·c contact@company.vn\"\n",
    "Regex: [a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\n",
    "Káº¿t quáº£: \"john@gmail.com\", \"contact@company.vn\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ CÃ¡c kÃ½ hiá»‡u Regex cÆ¡ báº£n (Dá»… hiá»ƒu)\n",
    "\n",
    "| KÃ½ hiá»‡u | Ã nghÄ©a | VÃ­ dá»¥ thá»±c táº¿ |\n",
    "|---------|---------|---------------|\n",
    "| `\\d` | **Sá»‘** (0-9) | `\\d\\d\\d` â†’ tÃ¬m \"123\", \"456\" |\n",
    "| `\\w` | **Chá»¯ cÃ¡i vÃ  sá»‘** | `\\w+` â†’ tÃ¬m \"hello\", \"abc123\" |\n",
    "| `\\s` | **Khoáº£ng tráº¯ng** | `\\s+` â†’ tÃ¬m spaces, tabs |\n",
    "| `+` | **1 hoáº·c nhiá»u** | `\\d+` â†’ \"1\", \"123\", \"12345\" |\n",
    "| `*` | **0 hoáº·c nhiá»u** | `\\d*` â†’ \"\", \"1\", \"123\" |\n",
    "| `?` | **0 hoáº·c 1** | `\\d?` â†’ \"\", \"1\" |\n",
    "| `[]` | **Chá»n má»™t trong** | `[0-9]` â†’ sá»‘ tá»« 0-9 |\n",
    "| `^` | **Báº¯t Ä‘áº§u** | `^Hello` â†’ chuá»—i báº¯t Ä‘áº§u \"Hello\" |\n",
    "| `$` | **Káº¿t thÃºc** | `world$` â†’ chuá»—i káº¿t thÃºc \"world\" |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ CÃ¡ch sá»­ dá»¥ng Regex vá»›i Pandas\n",
    "\n",
    "Pandas cÃ³ 4 phÆ°Æ¡ng thá»©c chÃ­nh Ä‘á»ƒ lÃ m viá»‡c vá»›i Regex:\n",
    "\n",
    "| PhÆ°Æ¡ng thá»©c | Má»¥c Ä‘Ã­ch | VÃ­ dá»¥ |\n",
    "|-------------|----------|-------|\n",
    "| `.str.contains()` | **Kiá»ƒm tra** cÃ³ chá»©a pattern khÃ´ng | CÃ³ email há»£p lá»‡ khÃ´ng? |\n",
    "| `.str.extract()` | **TrÃ­ch xuáº¥t** thÃ´ng tin | Láº¥y sá»‘ Ä‘iá»‡n thoáº¡i ra |\n",
    "| `.str.replace()` | **Thay tháº¿** text | Äá»•i format sá»‘ Ä‘iá»‡n thoáº¡i |\n",
    "| `.str.findall()` | **TÃ¬m táº¥t cáº£** matches | TÃ¬m táº¥t cáº£ email |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Máº¹o há»c Regex hiá»‡u quáº£\n",
    "\n",
    "1. **Báº¯t Ä‘áº§u Ä‘Æ¡n giáº£n**: Há»c tá»«ng kÃ½ hiá»‡u má»™t\n",
    "2. **Thá»±c hÃ nh nhiá»u**: DÃ¹ng cÃ¡c vÃ­ dá»¥ thá»±c táº¿\n",
    "3. **Test online**: DÃ¹ng regex101.com Ä‘á»ƒ test\n",
    "4. **Copy-paste**: Sá»­ dá»¥ng patterns cÃ³ sáºµn\n",
    "5. **KhÃ´ng cáº§n nhá»› háº¿t**: Chá»‰ cáº§n hiá»ƒu cÆ¡ báº£n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5f680",
   "metadata": {},
   "source": [
    "## ğŸ¯ DEMO: Regex tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao\n",
    "\n",
    "### ğŸ“± TÃ¬nh huá»‘ng thá»±c táº¿: Xá»­ lÃ½ dá»¯ liá»‡u khÃ¡ch hÃ ng\n",
    "\n",
    "Báº¡n lÃ  nhÃ¢n viÃªn marketing vÃ  nháº­n Ä‘Æ°á»£c danh sÃ¡ch liÃªn há»‡ khÃ¡ch hÃ ng tá»« nhiá»u nguá»“n khÃ¡c nhau. Dá»¯ liá»‡u ráº¥t lá»™n xá»™n vÃ  cáº§n Ä‘Æ°á»£c lÃ m sáº¡ch.\n",
    "\n",
    "**ğŸ¯ Má»¥c tiÃªu:**\n",
    "1. **TrÃ­ch xuáº¥t sá»‘ Ä‘iá»‡n thoáº¡i** tá»« cÃ¡c Ä‘á»‹nh dáº¡ng khÃ¡c nhau\n",
    "2. **TÃ¬m email há»£p lá»‡** \n",
    "3. **Kiá»ƒm tra website/URL**\n",
    "4. **Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i** vá» Ä‘á»‹nh dáº¡ng thá»‘ng nháº¥t\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Dá»¯ liá»‡u máº«u (TÃ¬nh huá»‘ng thá»±c táº¿)\n",
    "\n",
    "ChÃºng ta cÃ³ 5 dÃ²ng dá»¯ liá»‡u khÃ¡ch hÃ ng vá»›i thÃ´ng tin liÃªn há»‡ lá»™n xá»™n:\n",
    "\n",
    "```\n",
    "1. \"LiÃªn há»‡: 0123-456-789 hoáº·c email: john@gmail.com\"\n",
    "2. \"SDT: +84 98 765 4321, Ä‘á»‹a chá»‰: 123 LÃª Lá»£i, Q1, TP.HCM\"  \n",
    "3. \"Phone: (024) 3825-7863, email: info@company.vn\"\n",
    "4. \"Mobile: 0987654321, website: https://example.com\"\n",
    "5. \"Hotline: 1900-1234, fax: (028) 3829-5678\"\n",
    "```\n",
    "\n",
    "**â“ CÃ¢u há»i:** LÃ m sao Ä‘á»ƒ tá»± Ä‘á»™ng trÃ­ch xuáº¥t thÃ´ng tin tá»« nhá»¯ng chuá»—i vÄƒn báº£n phá»©c táº¡p nÃ y?\n",
    "\n",
    "**âœ… Tráº£ lá»i:** Sá»­ dá»¥ng Regex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ce829d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¢ DEMO: Xá»­ lÃ½ dá»¯ liá»‡u liÃªn há»‡ khÃ¡ch hÃ ng vá»›i Regex\n",
      "======================================================================\n",
      "ğŸ“‹ BÆ¯á»šC 1: Dá»¯ liá»‡u khÃ¡ch hÃ ng gá»‘c (lá»™n xá»™n)\n",
      "--------------------------------------------------\n",
      "ğŸ“Š DataFrame khÃ¡ch hÃ ng:\n",
      "        KhachHang                                           ThongTin\n",
      "0       CÃ´ng ty A   LiÃªn há»‡: 0123-456-789 hoáº·c email: john@gmail.com\n",
      "1    KhÃ¡ch hÃ ng B  SDT: +84 98 765 4321, Ä‘á»‹a chá»‰: 123 LÃª Lá»£i, Q1,...\n",
      "2  Doanh nghiá»‡p C     Phone: (024) 3825-7863, email: info@company.vn\n",
      "3       CÃ¡ nhÃ¢n D   Mobile: 0987654321, website: https://example.com\n",
      "4       Tá»• chá»©c E           Hotline: 1900-1234, fax: (028) 3829-5678\n",
      "\n",
      "======================================================================\n",
      "ğŸ” BÆ¯á»šC 2: Há»ŒC REGEX QUA VÃ Dá»¤ ÄÆ N GIáº¢N\n",
      "======================================================================\n",
      "ğŸ“š HIá»‚U REGEX QUA VÃ Dá»¤:\n",
      "\n",
      "1ï¸âƒ£ TÃ¬m sá»‘ Ä‘iá»‡n thoáº¡i:\n",
      "   VÄƒn báº£n: '0123-456-789'\n",
      "   Regex: r'\\d{3,4}[-.]?\\d{3,4}[-.]?\\d{3,4}'\n",
      "   Giáº£i thÃ­ch:\n",
      "   - \\d{3,4} = 3 hoáº·c 4 sá»‘\n",
      "   - [-.]? = cÃ³ thá»ƒ cÃ³ dáº¥u - hoáº·c . (hoáº·c khÃ´ng)\n",
      "   - Káº¿t quáº£: '0123-456-789'\n",
      "\n",
      "2ï¸âƒ£ TÃ¬m email:\n",
      "   VÄƒn báº£n: 'john@gmail.com'\n",
      "   Regex: r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
      "   Giáº£i thÃ­ch:\n",
      "   - [a-zA-Z0-9._%+-]+ = tÃªn email (chá»¯, sá»‘, kÃ½ tá»± Ä‘áº·c biá»‡t)\n",
      "   - @ = kÃ½ tá»± @\n",
      "   - [a-zA-Z0-9.-]+ = tÃªn domain\n",
      "   - \\. = dáº¥u cháº¥m\n",
      "   - [a-zA-Z]{2,} = Ä‘uÃ´i domain (Ã­t nháº¥t 2 chá»¯)\n",
      "   - Káº¿t quáº£: 'john@gmail.com'\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ› ï¸ BÆ¯á»šC 3: ÃP Dá»¤NG REGEX VÃ€O Dá»® LIá»†U THá»°C Táº¾\n",
      "======================================================================\n",
      "ğŸ” 3.1: TrÃ­ch xuáº¥t sá»‘ Ä‘iá»‡n thoáº¡i\n",
      "----------------------------------------\n",
      "ğŸ“± Pattern: (\\+?84[\\s\\-]?)?\\(?0?\\d{2,3}\\)?[\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4}\n",
      "ğŸ“ Giáº£i thÃ­ch:\n",
      "   - (\\+?84[\\s\\-]?)? = mÃ£ quá»‘c gia +84 (cÃ³ thá»ƒ cÃ³ hoáº·c khÃ´ng)\n",
      "   - \\(?0?\\d{2,3}\\)? = mÃ£ vÃ¹ng (cÃ³ thá»ƒ cÃ³ dáº¥u ngoáº·c)\n",
      "   - [\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4} = sá»‘ Ä‘iá»‡n thoáº¡i\n",
      "\n",
      "ğŸ“Š Káº¿t quáº£:\n",
      "        KhachHang                                           ThongTin  \\\n",
      "0       CÃ´ng ty A   LiÃªn há»‡: 0123-456-789 hoáº·c email: john@gmail.com   \n",
      "1    KhÃ¡ch hÃ ng B  SDT: +84 98 765 4321, Ä‘á»‹a chá»‰: 123 LÃª Lá»£i, Q1,...   \n",
      "2  Doanh nghiá»‡p C     Phone: (024) 3825-7863, email: info@company.vn   \n",
      "3       CÃ¡ nhÃ¢n D   Mobile: 0987654321, website: https://example.com   \n",
      "4       Tá»• chá»©c E           Hotline: 1900-1234, fax: (028) 3829-5678   \n",
      "\n",
      "  SoDienThoai  \n",
      "0        None  \n",
      "1        +84   \n",
      "2        None  \n",
      "3        None  \n",
      "4        None  \n",
      "\n",
      "ğŸ” 3.2: TrÃ­ch xuáº¥t email\n",
      "----------------------------------------\n",
      "ğŸ“§ Pattern: ([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})\n",
      "ğŸ“ Giáº£i thÃ­ch:\n",
      "   - [a-zA-Z0-9._%+-]+ = tÃªn email\n",
      "   - @ = kÃ½ tá»± @\n",
      "   - [a-zA-Z0-9.-]+ = domain\n",
      "   - \\. = dáº¥u cháº¥m\n",
      "   - [a-zA-Z]{2,} = Ä‘uÃ´i domain\n",
      "\n",
      "ğŸ“Š Káº¿t quáº£:\n",
      "        KhachHang                                           ThongTin  \\\n",
      "0       CÃ´ng ty A   LiÃªn há»‡: 0123-456-789 hoáº·c email: john@gmail.com   \n",
      "1    KhÃ¡ch hÃ ng B  SDT: +84 98 765 4321, Ä‘á»‹a chá»‰: 123 LÃª Lá»£i, Q1,...   \n",
      "2  Doanh nghiá»‡p C     Phone: (024) 3825-7863, email: info@company.vn   \n",
      "3       CÃ¡ nhÃ¢n D   Mobile: 0987654321, website: https://example.com   \n",
      "4       Tá»• chá»©c E           Hotline: 1900-1234, fax: (028) 3829-5678   \n",
      "\n",
      "             Email  \n",
      "0   john@gmail.com  \n",
      "1              NaN  \n",
      "2  info@company.vn  \n",
      "3              NaN  \n",
      "4              NaN  \n",
      "\n",
      "ğŸ” 3.3: Kiá»ƒm tra cÃ³ website/URL\n",
      "----------------------------------------\n",
      "ğŸŒ Pattern: https?://[^\\s]+\n",
      "ğŸ“ Giáº£i thÃ­ch:\n",
      "   - https? = http hoáº·c https\n",
      "   - :// = kÃ½ tá»± ://\n",
      "   - [^\\s]+ = má»i kÃ½ tá»± khÃ´ng pháº£i khoáº£ng tráº¯ng\n",
      "\n",
      "ğŸ“Š Káº¿t quáº£:\n",
      "        KhachHang                                           ThongTin  \\\n",
      "0       CÃ´ng ty A   LiÃªn há»‡: 0123-456-789 hoáº·c email: john@gmail.com   \n",
      "1    KhÃ¡ch hÃ ng B  SDT: +84 98 765 4321, Ä‘á»‹a chá»‰: 123 LÃª Lá»£i, Q1,...   \n",
      "2  Doanh nghiá»‡p C     Phone: (024) 3825-7863, email: info@company.vn   \n",
      "3       CÃ¡ nhÃ¢n D   Mobile: 0987654321, website: https://example.com   \n",
      "4       Tá»• chá»©c E           Hotline: 1900-1234, fax: (028) 3829-5678   \n",
      "\n",
      "   CoWebsite  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3       True  \n",
      "4      False  \n",
      "\n",
      "======================================================================\n",
      "âœ¨ BÆ¯á»šC 4: CHUáº¨N HÃ“A Sá» ÄIá»†N THOáº I\n",
      "======================================================================\n",
      "ğŸ”§ Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i:\n",
      "\n",
      "ğŸ“Š Káº¿t quáº£ cuá»‘i cÃ¹ng:\n",
      "        KhachHang SoDienThoai SoDienThoaiChuan            Email  CoWebsite\n",
      "0       CÃ´ng ty A        None             None   john@gmail.com      False\n",
      "1    KhÃ¡ch hÃ ng B        +84                84              NaN      False\n",
      "2  Doanh nghiá»‡p C        None             None  info@company.vn      False\n",
      "3       CÃ¡ nhÃ¢n D        None             None              NaN       True\n",
      "4       Tá»• chá»©c E        None             None              NaN      False\n",
      "\n",
      "======================================================================\n",
      "ğŸ‰ Tá»”NG Káº¾T: REGEX ÄÃƒ GIÃšP CHÃšNG TA\n",
      "======================================================================\n",
      "âœ… TrÃ­ch xuáº¥t sá»‘ Ä‘iá»‡n thoáº¡i tá»« 5 Ä‘á»‹nh dáº¡ng khÃ¡c nhau\n",
      "âœ… TÃ¬m email há»£p lá»‡\n",
      "âœ… Kiá»ƒm tra cÃ³ website khÃ´ng\n",
      "âœ… Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i vá» Ä‘á»‹nh dáº¡ng thá»‘ng nháº¥t\n",
      "âœ… Táº¥t cáº£ chá»‰ trong vÃ i dÃ²ng code!\n",
      "\n",
      "ğŸ’¡ Regex giÃºp xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n phá»©c táº¡p má»™t cÃ¡ch tá»± Ä‘á»™ng vÃ  chÃ­nh xÃ¡c!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ DEMO: Regex tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao\n",
    "# TÃ¬nh huá»‘ng: Xá»­ lÃ½ dá»¯ liá»‡u liÃªn há»‡ khÃ¡ch hÃ ng\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "print(\"ğŸ¢ DEMO: Xá»­ lÃ½ dá»¯ liá»‡u liÃªn há»‡ khÃ¡ch hÃ ng vá»›i Regex\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ğŸ“‹ BÆ°á»›c 1: Táº¡o dá»¯ liá»‡u máº«u (thá»±c táº¿ tá»« nhiá»u nguá»“n khÃ¡c nhau)\n",
    "print(\"ğŸ“‹ BÆ¯á»šC 1: Dá»¯ liá»‡u khÃ¡ch hÃ ng gá»‘c (lá»™n xá»™n)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "data_khachhang = {\n",
    "    'KhachHang': ['CÃ´ng ty A', 'KhÃ¡ch hÃ ng B', 'Doanh nghiá»‡p C', 'CÃ¡ nhÃ¢n D', 'Tá»• chá»©c E'],\n",
    "    'ThongTin': [\n",
    "        'LiÃªn há»‡: 0123-456-789 hoáº·c email: john@gmail.com',\n",
    "        'SDT: +84 98 765 4321, Ä‘á»‹a chá»‰: 123 LÃª Lá»£i, Q1, TP.HCM', \n",
    "        'Phone: (024) 3825-7863, email: info@company.vn',\n",
    "        'Mobile: 0987654321, website: https://example.com',\n",
    "        'Hotline: 1900-1234, fax: (028) 3829-5678'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_khachhang = pd.DataFrame(data_khachhang)\n",
    "print(\"ğŸ“Š DataFrame khÃ¡ch hÃ ng:\")\n",
    "print(df_khachhang)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” BÆ¯á»šC 2: Há»ŒC REGEX QUA VÃ Dá»¤ ÄÆ N GIáº¢N\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ğŸ“š Giáº£i thÃ­ch Regex cÆ¡ báº£n\n",
    "print(\"ğŸ“š HIá»‚U REGEX QUA VÃ Dá»¤:\")\n",
    "print()\n",
    "\n",
    "print(\"1ï¸âƒ£ TÃ¬m sá»‘ Ä‘iá»‡n thoáº¡i:\")\n",
    "print(\"   VÄƒn báº£n: '0123-456-789'\")\n",
    "print(\"   Regex: r'\\\\d{3,4}[-.]?\\\\d{3,4}[-.]?\\\\d{3,4}'\")\n",
    "print(\"   Giáº£i thÃ­ch:\")\n",
    "print(\"   - \\\\d{3,4} = 3 hoáº·c 4 sá»‘\")\n",
    "print(\"   - [-.]? = cÃ³ thá»ƒ cÃ³ dáº¥u - hoáº·c . (hoáº·c khÃ´ng)\")\n",
    "print(\"   - Káº¿t quáº£: '0123-456-789'\")\n",
    "print()\n",
    "\n",
    "print(\"2ï¸âƒ£ TÃ¬m email:\")\n",
    "print(\"   VÄƒn báº£n: 'john@gmail.com'\")\n",
    "print(\"   Regex: r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}'\")\n",
    "print(\"   Giáº£i thÃ­ch:\")\n",
    "print(\"   - [a-zA-Z0-9._%+-]+ = tÃªn email (chá»¯, sá»‘, kÃ½ tá»± Ä‘áº·c biá»‡t)\")\n",
    "print(\"   - @ = kÃ½ tá»± @\")\n",
    "print(\"   - [a-zA-Z0-9.-]+ = tÃªn domain\")\n",
    "print(\"   - \\\\. = dáº¥u cháº¥m\")\n",
    "print(\"   - [a-zA-Z]{2,} = Ä‘uÃ´i domain (Ã­t nháº¥t 2 chá»¯)\")\n",
    "print(\"   - Káº¿t quáº£: 'john@gmail.com'\")\n",
    "print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ› ï¸ BÆ¯á»šC 3: ÃP Dá»¤NG REGEX VÃ€O Dá»® LIá»†U THá»°C Táº¾\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ğŸ” BÆ°á»›c 3.1: TrÃ­ch xuáº¥t sá»‘ Ä‘iá»‡n thoáº¡i\n",
    "print(\"ğŸ” 3.1: TrÃ­ch xuáº¥t sá»‘ Ä‘iá»‡n thoáº¡i\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Regex Ä‘Æ¡n giáº£n hÆ¡n Ä‘á»ƒ dá»… hiá»ƒu\n",
    "phone_pattern = r'(\\+?84[\\s\\-]?)?\\(?0?\\d{2,3}\\)?[\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4}'\n",
    "\n",
    "print(f\"ğŸ“± Pattern: {phone_pattern}\")\n",
    "print(\"ğŸ“ Giáº£i thÃ­ch:\")\n",
    "print(\"   - (\\\\+?84[\\\\s\\\\-]?)? = mÃ£ quá»‘c gia +84 (cÃ³ thá»ƒ cÃ³ hoáº·c khÃ´ng)\")\n",
    "print(\"   - \\\\(?0?\\\\d{2,3}\\\\)? = mÃ£ vÃ¹ng (cÃ³ thá»ƒ cÃ³ dáº¥u ngoáº·c)\")\n",
    "print(\"   - [\\\\s\\\\-]?\\\\d{3,4}[\\\\s\\\\-]?\\\\d{3,4} = sá»‘ Ä‘iá»‡n thoáº¡i\")\n",
    "\n",
    "df_khachhang['SoDienThoai'] = df_khachhang['ThongTin'].str.extract(phone_pattern, expand=False)\n",
    "print(\"\\nğŸ“Š Káº¿t quáº£:\")\n",
    "print(df_khachhang[['KhachHang', 'ThongTin', 'SoDienThoai']])\n",
    "\n",
    "# ğŸ” BÆ°á»›c 3.2: TrÃ­ch xuáº¥t email\n",
    "print(\"\\nğŸ” 3.2: TrÃ­ch xuáº¥t email\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Regex email Ä‘Æ¡n giáº£n hÆ¡n\n",
    "email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "\n",
    "print(f\"ğŸ“§ Pattern: {email_pattern}\")\n",
    "print(\"ğŸ“ Giáº£i thÃ­ch:\")\n",
    "print(\"   - [a-zA-Z0-9._%+-]+ = tÃªn email\")\n",
    "print(\"   - @ = kÃ½ tá»± @\")\n",
    "print(\"   - [a-zA-Z0-9.-]+ = domain\")\n",
    "print(\"   - \\\\. = dáº¥u cháº¥m\")\n",
    "print(\"   - [a-zA-Z]{2,} = Ä‘uÃ´i domain\")\n",
    "\n",
    "df_khachhang['Email'] = df_khachhang['ThongTin'].str.extract(email_pattern, expand=False)\n",
    "print(\"\\nğŸ“Š Káº¿t quáº£:\")\n",
    "print(df_khachhang[['KhachHang', 'ThongTin', 'Email']])\n",
    "\n",
    "# ğŸ” BÆ°á»›c 3.3: Kiá»ƒm tra cÃ³ website khÃ´ng\n",
    "print(\"\\nğŸ” 3.3: Kiá»ƒm tra cÃ³ website/URL\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Regex URL Ä‘Æ¡n giáº£n\n",
    "url_pattern = r'https?://[^\\s]+'\n",
    "\n",
    "print(f\"ğŸŒ Pattern: {url_pattern}\")\n",
    "print(\"ğŸ“ Giáº£i thÃ­ch:\")\n",
    "print(\"   - https? = http hoáº·c https\")\n",
    "print(\"   - :// = kÃ½ tá»± ://\")\n",
    "print(\"   - [^\\\\s]+ = má»i kÃ½ tá»± khÃ´ng pháº£i khoáº£ng tráº¯ng\")\n",
    "\n",
    "df_khachhang['CoWebsite'] = df_khachhang['ThongTin'].str.contains(url_pattern, regex=True)\n",
    "print(\"\\nğŸ“Š Káº¿t quáº£:\")\n",
    "print(df_khachhang[['KhachHang', 'ThongTin', 'CoWebsite']])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ¨ BÆ¯á»šC 4: CHUáº¨N HÃ“A Sá» ÄIá»†N THOáº I\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ğŸ”§ Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i\n",
    "def chuan_hoa_so_dien_thoai(so_dt):\n",
    "    \"\"\"\n",
    "    Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i vá» Ä‘á»‹nh dáº¡ng: 0xxx-xxx-xxxx\n",
    "    \"\"\"\n",
    "    if pd.isna(so_dt) or so_dt is None:\n",
    "        return None\n",
    "    \n",
    "    # Chá»‰ giá»¯ láº¡i sá»‘\n",
    "    so_clean = ''.join(filter(str.isdigit, str(so_dt)))\n",
    "    \n",
    "    # Chuáº©n hÃ³a theo Ä‘á»‹nh dáº¡ng Viá»‡t Nam\n",
    "    if len(so_clean) >= 10:\n",
    "        if so_clean.startswith('84'):\n",
    "            # +84-xxx-xxx-xxxx\n",
    "            return f\"+84-{so_clean[2:5]}-{so_clean[5:8]}-{so_clean[8:]}\"\n",
    "        elif so_clean.startswith('0'):\n",
    "            # 0xxx-xxx-xxxx\n",
    "            return f\"{so_clean[:4]}-{so_clean[4:7]}-{so_clean[7:]}\"\n",
    "    \n",
    "    return so_clean if so_clean else None\n",
    "\n",
    "print(\"ğŸ”§ Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i:\")\n",
    "df_khachhang['SoDienThoaiChuan'] = df_khachhang['SoDienThoai'].apply(chuan_hoa_so_dien_thoai)\n",
    "\n",
    "print(\"\\nğŸ“Š Káº¿t quáº£ cuá»‘i cÃ¹ng:\")\n",
    "result_columns = ['KhachHang', 'SoDienThoai', 'SoDienThoaiChuan', 'Email', 'CoWebsite']\n",
    "print(df_khachhang[result_columns])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ Tá»”NG Káº¾T: REGEX ÄÃƒ GIÃšP CHÃšNG TA\")\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… TrÃ­ch xuáº¥t sá»‘ Ä‘iá»‡n thoáº¡i tá»« 5 Ä‘á»‹nh dáº¡ng khÃ¡c nhau\")\n",
    "print(\"âœ… TÃ¬m email há»£p lá»‡\")\n",
    "print(\"âœ… Kiá»ƒm tra cÃ³ website khÃ´ng\")\n",
    "print(\"âœ… Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i vá» Ä‘á»‹nh dáº¡ng thá»‘ng nháº¥t\")\n",
    "print(\"âœ… Táº¥t cáº£ chá»‰ trong vÃ i dÃ²ng code!\")\n",
    "print(\"\\nğŸ’¡ Regex giÃºp xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n phá»©c táº¡p má»™t cÃ¡ch tá»± Ä‘á»™ng vÃ  chÃ­nh xÃ¡c!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6308338",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a33472b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c50edd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f3b0923",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed53c7d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f196a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6b32509",
   "metadata": {},
   "source": [
    "## Xá»­ lÃ½ dá»¯ liá»‡u phÃ¢n loáº¡i (Categorical Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020f9e7",
   "metadata": {},
   "source": [
    "### Hiá»ƒu vá» dá»¯ liá»‡u phÃ¢n loáº¡i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a323b",
   "metadata": {},
   "source": [
    "**ğŸ·ï¸ Dá»¯ liá»‡u phÃ¢n loáº¡i lÃ  gÃ¬?**\n",
    "\n",
    "Dá»¯ liá»‡u phÃ¢n loáº¡i (*categorical data*) lÃ  loáº¡i dá»¯ liá»‡u cÃ³ **sá»‘ lÆ°á»£ng giÃ¡ trá»‹ há»¯u háº¡n** vÃ  thÆ°á»ng Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng **nhÃ£n hoáº·c tÃªn**:\n",
    "\n",
    "**ğŸ“Š CÃ¡c loáº¡i dá»¯ liá»‡u phÃ¢n loáº¡i:**\n",
    "\n",
    "1. **Nominal** (Danh nghÄ©a): KhÃ´ng cÃ³ thá»© tá»±\n",
    "   - Giá»›i tÃ­nh: Nam, Ná»¯, KhÃ¡c\n",
    "   - MÃ u sáº¯c: Äá», Xanh, VÃ ng\n",
    "   - Quá»‘c gia: Viá»‡t Nam, Má»¹, Nháº­t Báº£n\n",
    "\n",
    "2. **Ordinal** (Thá»© tá»±): CÃ³ thá»© tá»± Ã½ nghÄ©a\n",
    "   - Há»c vá»‹: Cá»­ nhÃ¢n < Tháº¡c sÄ© < Tiáº¿n sÄ©\n",
    "   - ÄÃ¡nh giÃ¡: KÃ©m < Trung bÃ¬nh < Tá»‘t < Xuáº¥t sáº¯c\n",
    "   - KÃ­ch cá»¡: S < M < L < XL\n",
    "\n",
    "**ğŸ”§ Xá»­ lÃ½ dá»¯ liá»‡u phÃ¢n loáº¡i trong pandas:**\n",
    "\n",
    "- **Kiá»ƒu `category`**: Pandas cÃ³ kiá»ƒu dá»¯ liá»‡u chuyÃªn dá»¥ng cho categorical data\n",
    "- **Memory efficient**: Tiáº¿t kiá»‡m bá»™ nhá»› khi cÃ³ nhiá»u giÃ¡ trá»‹ láº·p láº¡i\n",
    "- **Performance**: TÄƒng tá»‘c cÃ¡c phÃ©p toÃ¡n groupby vÃ  merge\n",
    "- **Validation**: Kiá»ƒm soÃ¡t cÃ¡c giÃ¡ trá»‹ há»£p lá»‡\n",
    "\n",
    "**âš™ï¸ Khi nÃ o sá»­ dá»¥ng kiá»ƒu `category`:**\n",
    "\n",
    "- Cá»™t cÃ³ **Ã­t giÃ¡ trá»‹ duy nháº¥t** so vá»›i tá»•ng sá»‘ hÃ ng\n",
    "- **Nhiá»u giÃ¡ trá»‹ láº·p láº¡i** (high cardinality)\n",
    "- Muá»‘n **kiá»ƒm soÃ¡t cÃ¡c giÃ¡ trá»‹** cÃ³ thá»ƒ xuáº¥t hiá»‡n\n",
    "- Cáº§n **tá»‘i Æ°u hÃ³a bá»™ nhá»›** vÃ  hiá»‡u suáº¥t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc6ba5",
   "metadata": {},
   "source": [
    "### Label Encoding - MÃ£ hÃ³a nhÃ£n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd7819",
   "metadata": {},
   "source": [
    "**ğŸ”¢ Label Encoding lÃ  gÃ¬?**\n",
    "\n",
    "Label Encoding lÃ  ká»¹ thuáº­t chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u phÃ¢n loáº¡i thÃ nh **sá»‘ nguyÃªn tuáº§n tá»±**:\n",
    "\n",
    "- `\"Apple\"` â†’ `0`\n",
    "- `\"Banana\"` â†’ `1` \n",
    "- `\"Cherry\"` â†’ `2`\n",
    "\n",
    "**âœ… Æ¯u Ä‘iá»ƒm:**\n",
    "- **ÄÆ¡n giáº£n**: Dá»… hiá»ƒu vÃ  triá»ƒn khai\n",
    "- **Tiáº¿t kiá»‡m bá»™ nhá»›**: Chá»‰ cáº§n 1 cá»™t\n",
    "- **PhÃ¹ há»£p vá»›i dá»¯ liá»‡u ordinal**: Báº£o toÃ n thá»© tá»±\n",
    "\n",
    "**âŒ NhÆ°á»£c Ä‘iá»ƒm:**\n",
    "- **Táº¡o thá»© tá»± giáº£ táº¡o**: Apple < Banana < Cherry (khÃ´ng Ä‘Ãºng)\n",
    "- **KhÃ´ng phÃ¹ há»£p vá»›i nominal data**: CÃ¡c thuáº­t toÃ¡n cÃ³ thá»ƒ hiá»ƒu sai quan há»‡\n",
    "- **Bias trong mÃ´ hÃ¬nh**: GiÃ¡ trá»‹ lá»›n hÆ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c coi lÃ  \"quan trá»ng\" hÆ¡n\n",
    "\n",
    "**ğŸ¯ Khi nÃ o sá»­ dá»¥ng Label Encoding:**\n",
    "- **Dá»¯ liá»‡u ordinal** cÃ³ thá»© tá»± tá»± nhiÃªn\n",
    "- **Tree-based algorithms** (Decision Tree, Random Forest) - Ã­t bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi thá»© tá»±\n",
    "- **Target variable** trong classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d25e7de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»¯ liá»‡u categorical gá»‘c:\n",
      "    TÃªn  PhÃ²ng ban TrÃ¬nh Ä‘á»™ ThÃ nh phá»‘\n",
      "0    An         IT  Cá»­ nhÃ¢n    HÃ  Ná»™i\n",
      "1  BÃ¬nh  Marketing  Tháº¡c sÄ©    TP.HCM\n",
      "2   Chi         IT  Cá»­ nhÃ¢n    HÃ  Ná»™i\n",
      "3  DÅ©ng         HR  Tiáº¿n sÄ©   ÄÃ  Náºµng\n",
      "4   Eva  Marketing  Tháº¡c sÄ©    TP.HCM\n",
      "Sá»­ dá»¥ng Label Encoding Ä‘á»‘i vá»›i dá»¯ liá»‡u categorical:\n",
      "CÃ¡c categoricals Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a Ä‘á»‘i vá»›i PhÃ²ng ban: ['HR' 'IT' 'Marketing']\n",
      "CÃ¡c categoricals Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a Ä‘á»‘i vá»›i TrÃ¬nh Ä‘á»™: ['Cá»­ nhÃ¢n' 'Tháº¡c sÄ©' 'Tiáº¿n sÄ©']\n",
      "CÃ¡c categoricals Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a Ä‘á»‘i vá»›i ThÃ nh phá»‘: ['HÃ  Ná»™i' 'TP.HCM' 'ÄÃ  Náºµng']\n",
      "Káº¿t quáº£ Label Encoding:\n",
      "    TÃªn  PhÃ²ng ban  TrÃ¬nh Ä‘á»™  ThÃ nh phá»‘\n",
      "0    An          1         0          0\n",
      "1  BÃ¬nh          2         1          1\n",
      "2   Chi          1         0          0\n",
      "3  DÅ©ng          0         2          2\n",
      "4   Eva          2         1          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Táº¡o dá»¯ liá»‡u categorical Ä‘á»ƒ demo One-Hot Encoding\n",
    "data_categorical = {\n",
    "    'TÃªn': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva'],\n",
    "    'PhÃ²ng ban': ['IT', 'Marketing', 'IT', 'HR', 'Marketing'],\n",
    "    'TrÃ¬nh Ä‘á»™': ['Cá»­ nhÃ¢n', 'Tháº¡c sÄ©', 'Cá»­ nhÃ¢n', 'Tiáº¿n sÄ©', 'Tháº¡c sÄ©'],\n",
    "    'ThÃ nh phá»‘': ['HÃ  Ná»™i', 'TP.HCM', 'HÃ  Ná»™i', 'ÄÃ  Náºµng', 'TP.HCM']\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data_categorical)\n",
    "print(\"Dá»¯ liá»‡u categorical gá»‘c:\")\n",
    "print(df_categorical)\n",
    "\n",
    "print(\"Sá»­ dá»¥ng Label Encoding Ä‘á»‘i vá»›i dá»¯ liá»‡u categorical:\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Khá»Ÿi táº¡o LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ãp dá»¥ng Label Encoding cho tá»«ng cá»™t categorical\n",
    "for col in ['PhÃ²ng ban', 'TrÃ¬nh Ä‘á»™', 'ThÃ nh phá»‘']:\n",
    "    df_categorical[col] = label_encoder.fit_transform(df_categorical[col])\n",
    "    print(f\"CÃ¡c categoricals Ä‘Ã£ Ä‘Æ°á»£c mÃ£ hÃ³a Ä‘á»‘i vá»›i {col}: {label_encoder.classes_}\")\n",
    "\n",
    "print(\"Káº¿t quáº£ Label Encoding:\")\n",
    "print(df_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7abc1c",
   "metadata": {},
   "source": [
    "### **One-Hot Encoding - MÃ£ hÃ³a One-Hot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47859e9",
   "metadata": {},
   "source": [
    "**ğŸ”¥ One-Hot Encoding lÃ  gÃ¬?**\n",
    "\n",
    "One-Hot Encoding táº¡o ra **binary columns** cho má»—i category:\n",
    "\n",
    "**VÃ­ dá»¥:** `[\"Apple\", \"Banana\", \"Cherry\"]` â†’ \n",
    "\n",
    "| Apple | Banana | Cherry |\n",
    "|-------|--------|--------|\n",
    "| 1     | 0      | 0      |\n",
    "| 0     | 1      | 0      |\n",
    "| 0     | 0      | 1      |\n",
    "\n",
    "**âœ… Æ¯u Ä‘iá»ƒm:**\n",
    "- **KhÃ´ng táº¡o thá»© tá»± giáº£ táº¡o**: Táº¥t cáº£ categories Ä‘á»u bÃ¬nh Ä‘áº³ng\n",
    "- **PhÃ¹ há»£p vá»›i nominal data**: Apple â‰  Banana â‰  Cherry\n",
    "- **Hoáº¡t Ä‘á»™ng tá»‘t** vá»›i háº§u háº¿t machine learning algorithms\n",
    "- **TrÃ¡nh bias**: KhÃ´ng cÃ³ category nÃ o Ä‘Æ°á»£c coi lÃ  \"quan trá»ng\" hÆ¡n\n",
    "\n",
    "**âŒ NhÆ°á»£c Ä‘iá»ƒm:**\n",
    "- **Curse of dimensionality**: TÄƒng sá»‘ lÆ°á»£ng features Ä‘Ã¡ng ká»ƒ  \n",
    "- **Sparse matrix**: Nhiá»u giÃ¡ trá»‹ 0, tá»‘n bá»™ nhá»›\n",
    "- **Multicollinearity**: CÃ¡c cá»™t cÃ³ correlation vá»›i nhau\n",
    "\n",
    "**ğŸ¯ Khi nÃ o sá»­ dá»¥ng One-Hot Encoding:**\n",
    "- **Dá»¯ liá»‡u nominal** khÃ´ng cÃ³ thá»© tá»± tá»± nhiÃªn\n",
    "- **Ãt categories** (< 10-15 giÃ¡ trá»‹ duy nháº¥t)\n",
    "- **Linear algorithms** (Linear/Logistic Regression, SVM)\n",
    "- **Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1f7870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dá»¯ liá»‡u categorical gá»‘c:\n",
      "    TÃªn  PhÃ²ng ban TrÃ¬nh Ä‘á»™ ThÃ nh phá»‘\n",
      "0    An         IT  Cá»­ nhÃ¢n    HÃ  Ná»™i\n",
      "1  BÃ¬nh  Marketing  Tháº¡c sÄ©    TP.HCM\n",
      "2   Chi         IT  Cá»­ nhÃ¢n    HÃ  Ná»™i\n",
      "3  DÅ©ng         HR  Tiáº¿n sÄ©   ÄÃ  Náºµng\n",
      "4   Eva  Marketing  Tháº¡c sÄ©    TP.HCM\n",
      "PHÆ¯Æ NG PHÃP 1: Sá»¬ Dá»¤NG pandas.get_dummies()\n",
      "Káº¿t quáº£ One-Hot Encoding vá»›i pandas:\n",
      "    TÃªn  PB_HR  PB_IT  PB_Marketing  TD_Cá»­ nhÃ¢n  TD_Tháº¡c sÄ©  TD_Tiáº¿n sÄ©  \\\n",
      "0    An  False   True         False        True       False       False   \n",
      "1  BÃ¬nh  False  False          True       False        True       False   \n",
      "2   Chi  False   True         False        True       False       False   \n",
      "3  DÅ©ng   True  False         False       False       False        True   \n",
      "4   Eva  False  False          True       False        True       False   \n",
      "\n",
      "   TP_HÃ  Ná»™i  TP_TP.HCM  TP_ÄÃ  Náºµng  \n",
      "0       True      False       False  \n",
      "1      False       True       False  \n",
      "2       True      False       False  \n",
      "3      False      False        True  \n",
      "4      False       True       False  \n",
      "\n",
      "Sá»‘ cá»™t trÆ°á»›c: 4\n",
      "Sá»‘ cá»™t sau: 10\n",
      "PHÆ¯Æ NG PHÃP 2: Sá»¬ Dá»¤NG sklearn.OneHotEncoder\n",
      "Káº¿t quáº£ One-Hot Encoding vá»›i sklearn:\n",
      "    TÃªn  PhÃ²ng ban_IT  PhÃ²ng ban_Marketing  TrÃ¬nh Ä‘á»™_Tháº¡c sÄ©  \\\n",
      "0    An           1.0                  0.0               0.0   \n",
      "1  BÃ¬nh           0.0                  1.0               1.0   \n",
      "2   Chi           1.0                  0.0               0.0   \n",
      "3  DÅ©ng           0.0                  0.0               0.0   \n",
      "4   Eva           0.0                  1.0               1.0   \n",
      "\n",
      "   TrÃ¬nh Ä‘á»™_Tiáº¿n sÄ©  ThÃ nh phá»‘_TP.HCM  ThÃ nh phá»‘_ÄÃ  Náºµng  \n",
      "0               0.0               0.0                0.0  \n",
      "1               0.0               1.0                0.0  \n",
      "2               0.0               0.0                0.0  \n",
      "3               1.0               0.0                1.0  \n",
      "4               0.0               1.0                0.0  \n",
      "\n",
      "LÆ°u Ã½: sklearn vá»›i drop='first' giáº£m sá»‘ cá»™t Ä‘á»ƒ trÃ¡nh multicollinearity\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Táº¡o dá»¯ liá»‡u categorical Ä‘á»ƒ demo One-Hot Encoding\n",
    "data_categorical = {\n",
    "    'TÃªn': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva'],\n",
    "    'PhÃ²ng ban': ['IT', 'Marketing', 'IT', 'HR', 'Marketing'],\n",
    "    'TrÃ¬nh Ä‘á»™': ['Cá»­ nhÃ¢n', 'Tháº¡c sÄ©', 'Cá»­ nhÃ¢n', 'Tiáº¿n sÄ©', 'Tháº¡c sÄ©'],\n",
    "    'ThÃ nh phá»‘': ['HÃ  Ná»™i', 'TP.HCM', 'HÃ  Ná»™i', 'ÄÃ  Náºµng', 'TP.HCM']\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data_categorical)\n",
    "print(\"Dá»¯ liá»‡u categorical gá»‘c:\")\n",
    "print(df_categorical)\n",
    "\n",
    "print(\"PHÆ¯Æ NG PHÃP 1: Sá»¬ Dá»¤NG pandas.get_dummies()\")\n",
    "\n",
    "# PhÆ°Æ¡ng phÃ¡p 1: Sá»­ dá»¥ng pandas.get_dummies()\n",
    "df_onehot_pandas = pd.get_dummies(df_categorical, \n",
    "                                  columns=['PhÃ²ng ban', 'TrÃ¬nh Ä‘á»™', 'ThÃ nh phá»‘'],\n",
    "                                  prefix=['PB', 'TD', 'TP'])\n",
    "\n",
    "print(\"Káº¿t quáº£ One-Hot Encoding vá»›i pandas:\")\n",
    "print(df_onehot_pandas)\n",
    "\n",
    "print(f\"\\nSá»‘ cá»™t trÆ°á»›c: {len(df_categorical.columns)}\")\n",
    "print(f\"Sá»‘ cá»™t sau: {len(df_onehot_pandas.columns)}\")\n",
    "\n",
    "print(\"PHÆ¯Æ NG PHÃP 2: Sá»¬ Dá»¤NG sklearn.OneHotEncoder\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# PhÆ°Æ¡ng phÃ¡p 2: Sá»­ dá»¥ng sklearn OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' Ä‘á»ƒ trÃ¡nh multicollinearity\n",
    "\n",
    "# Chá»‰ encode cÃ¡c cá»™t categorical (bá» qua cá»™t 'TÃªn')\n",
    "categorical_cols = ['PhÃ²ng ban', 'TrÃ¬nh Ä‘á»™', 'ThÃ nh phá»‘']\n",
    "encoded_data = encoder.fit_transform(df_categorical[categorical_cols])\n",
    "\n",
    "# Táº¡o tÃªn cá»™t cho káº¿t quáº£\n",
    "feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Táº¡o DataFrame má»›i\n",
    "df_onehot_sklearn = pd.DataFrame(encoded_data, columns=feature_names)\n",
    "df_onehot_sklearn = pd.concat([df_categorical[['TÃªn']], df_onehot_sklearn], axis=1)\n",
    "\n",
    "print(\"Káº¿t quáº£ One-Hot Encoding vá»›i sklearn:\")\n",
    "print(df_onehot_sklearn)\n",
    "\n",
    "print(f\"\\nLÆ°u Ã½: sklearn vá»›i drop='first' giáº£m sá»‘ cá»™t Ä‘á»ƒ trÃ¡nh multicollinearity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011775ca",
   "metadata": {},
   "source": [
    "## CÃ¢u há»i Ã´n táº­p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750156b9",
   "metadata": {},
   "source": [
    "**ğŸ“ HÃ£y tráº£ lá»i cÃ¡c cÃ¢u há»i sau Ä‘á»ƒ kiá»ƒm tra hiá»ƒu biáº¿t cá»§a báº¡n:**\n",
    "\n",
    "| **PhÆ°Æ¡ng thá»©c nÃ o dÃ¹ng Ä‘á»ƒ phÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u trong pandas?** | |\n",
    "|---|---|\n",
    "| `isna()` hoáº·c `isnull()` | |\n",
    "| `missing()` | |\n",
    "| `empty()` | |\n",
    "| `nan_check()` | |\n",
    "\n",
    "| **PhÆ°Æ¡ng thá»©c `fillna()` Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÃ m gÃ¬?** | |\n",
    "|---|---|\n",
    "| Loáº¡i bá» dá»¯ liá»‡u thiáº¿u | |\n",
    "| Thay tháº¿ dá»¯ liá»‡u thiáº¿u | |\n",
    "| PhÃ¡t hiá»‡n dá»¯ liá»‡u thiáº¿u | |\n",
    "| Äáº¿m dá»¯ liá»‡u thiáº¿u | |\n",
    "\n",
    "| **MinMaxScaler Ä‘Æ°a dá»¯ liá»‡u vá» khoáº£ng giÃ¡ trá»‹ nÃ o?** | |\n",
    "|---|---|\n",
    "| [-1, 1] | |\n",
    "| [0, 1] | |\n",
    "| [0, 100] | |\n",
    "| [-100, 100] | |\n",
    "\n",
    "| **PhÆ°Æ¡ng thá»©c nÃ o dÃ¹ng Ä‘á»ƒ loáº¡i bá» hÃ ng trÃ¹ng láº·p?** | |\n",
    "|---|---|\n",
    "| `remove_duplicates()` | |\n",
    "| `drop_duplicates()` | |\n",
    "| `delete_duplicates()` | |\n",
    "| `unique()` | |\n",
    "\n",
    "| **Trong pandas, Ä‘á»ƒ chuyá»ƒn chuá»—i vá» chá»¯ thÆ°á»ng ta sá»­ dá»¥ng?** | |\n",
    "|---|---|\n",
    "| `.str.lowercase()` | |\n",
    "| `.str.lower()` | |\n",
    "| `.str.downcase()` | |\n",
    "| `.str.small()` | |\n",
    "\n",
    "| **Label Encoding phÃ¹ há»£p nháº¥t vá»›i loáº¡i dá»¯ liá»‡u nÃ o?** | |\n",
    "|---|---|\n",
    "| Dá»¯ liá»‡u sá»‘ liÃªn tá»¥c | |\n",
    "| Dá»¯ liá»‡u nominal | |\n",
    "| Dá»¯ liá»‡u ordinal | |\n",
    "| Dá»¯ liá»‡u thá»i gian | |\n",
    "\n",
    "| **StandardScaler chuáº©n hÃ³a dá»¯ liá»‡u cÃ³ Mean vÃ  Standard Deviation lÃ  bao nhiÃªu?** | |\n",
    "|---|---|\n",
    "| Mean=1, Std=0 | |\n",
    "| Mean=0, Std=1 | |\n",
    "| Mean=0.5, Std=0.5 | |\n",
    "| Mean=100, Std=10 | |\n",
    "\n",
    "| **Khi nÃ o nÃªn sá»­ dá»¥ng RobustScaler thay vÃ¬ MinMaxScaler?** | |\n",
    "|---|---|\n",
    "| Khi dá»¯ liá»‡u cÃ³ nhiá»u outliers | |\n",
    "| Khi dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a | |\n",
    "| Khi dá»¯ liá»‡u lÃ  categorical | |\n",
    "| Khi dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c nhá» | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee804b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ‹ï¸ **BÃ€I Táº¬P THá»°C HÃ€NH**\n",
    "\n",
    "> **ğŸ“ LÆ¯U Ã:** BÃ i giáº£ng nÃ y cÃ³ **2 hÃ¬nh thá»©c thá»±c hÃ nh:**\n",
    "> 1. **ğŸ¯ Quiz tráº¯c nghiá»‡m trá»±c tuyáº¿n** (30 cÃ¢u há»i) - Tá»± Ä‘á»™ng cháº¥m Ä‘iá»ƒm\n",
    "> 2. **ğŸ’» BÃ i táº­p code tá»± do** (9 bÃ i táº­p) - Thá»±c hÃ nh sÃ¢u hÆ¡n\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“± Pháº§n A: QUIZ TRáº®C NGHIá»†M (30 cÃ¢u)**\n",
    "\n",
    "> **ğŸ® LÃ m quiz online táº¡i:**  \n",
    "> **[Quiz Lecture 5 - Data Cleaning & Preprocessing](../../quiz/Lec05_quiz/index.html)**\n",
    "\n",
    "**Cáº¥u trÃºc quiz:**\n",
    "- âœ… 30 cÃ¢u há»i tráº¯c nghiá»‡m\n",
    "- âœ… Tá»± Ä‘á»™ng cháº¥m Ä‘iá»ƒm\n",
    "- âœ… CÃ³ gá»£i Ã½ cho tá»«ng cÃ¢u\n",
    "- âœ… CÃ³ thá»ƒ xem Ä‘Ã¡p Ã¡n ngay\n",
    "\n",
    "**Ná»™i dung quiz bao gá»“m:**\n",
    "1. **Missing Data** (6 cÃ¢u): Detection, Drop, Fill, ML Imputation\n",
    "2. **Duplicate Data** (3 cÃ¢u): Detection, Removal, Subset handling\n",
    "3. **Data Normalization** (6 cÃ¢u): MinMax, Standard, Robust Scaler\n",
    "4. **String Processing** (6 cÃ¢u): Basic methods, Regex, Cleaning\n",
    "5. **Categorical Encoding** (6 cÃ¢u): Label, One-Hot, Ordinal\n",
    "6. **Advanced** (3 cÃ¢u): Pipeline, Feature Engineering, Best Practices\n",
    "\n",
    "**ğŸ’¡ Khuyáº¿n nghá»‹:** LÃ m quiz TRÆ¯á»šC KHI lÃ m bÃ i táº­p code Ä‘á»ƒ kiá»ƒm tra hiá»ƒu biáº¿t cÆ¡ báº£n!\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ’» Pháº§n B: BÃ€I Táº¬P CODE Tá»° DO (9 bÃ i)**\n",
    "\n",
    "### **NhÃ³m 1: BÃ i táº­p cÆ¡ báº£n (â­) - TÆ°Æ¡ng á»©ng Quiz cÃ¢u 1-10**\n",
    "\n",
    "### **BÃ i 1.1: Xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u cÆ¡ báº£n**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 1, 2, 3, 4\n",
    "\n",
    "**Äá» bÃ i:** PhÃ¢n tÃ­ch dá»¯ liá»‡u kháº£o sÃ¡t khÃ¡ch hÃ ng cÃ³ nhiá»u giÃ¡ trá»‹ thiáº¿u\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u kháº£o sÃ¡t khÃ¡ch hÃ ng (cÃ³ missing values)\n",
    "data = {\n",
    "    'Customer_ID': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'Age': [25, None, 30, 28, None, 35, 32, 29],\n",
    "    'Income': [50000000, 60000000, None, 70000000, 55000000, None, 80000000, 65000000],\n",
    "    'Education': ['Bachelor', 'Master', 'Bachelor', None, 'PhD', 'Master', None, 'Bachelor'],\n",
    "    'Satisfaction': [4, 5, None, 3, 4, 5, 4, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. Kiá»ƒm tra sá»‘ lÆ°á»£ng missing values trong má»—i cá»™t\n",
    "2. TÃ­nh tá»· lá»‡ pháº§n trÄƒm missing values\n",
    "3. Táº¡o 3 phiÃªn báº£n xá»­ lÃ½:\n",
    "   - Version 1: Loáº¡i bá» táº¥t cáº£ dÃ²ng cÃ³ missing values\n",
    "   - Version 2: Äiá»n missing values báº±ng giÃ¡ trá»‹ trung bÃ¬nh/median\n",
    "   - Version 3: Äiá»n missing values báº±ng forward fill\n",
    "4. So sÃ¡nh sá»‘ dÃ²ng cá»§a 3 phiÃªn báº£n\n",
    "\n",
    "**Gá»£i Ã½:** `.isnull().sum()`, `.dropna()`, `.fillna()`, `.ffill()`\n",
    "\n",
    "---\n",
    "\n",
    "### **BÃ i 1.2: PhÃ¡t hiá»‡n vÃ  xá»­ lÃ½ dá»¯ liá»‡u trÃ¹ng láº·p**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 5, 6, 7\n",
    "\n",
    "**Äá» bÃ i:** LÃ m sáº¡ch database khÃ¡ch hÃ ng cÃ³ nhiá»u báº£n ghi trÃ¹ng láº·p\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u khÃ¡ch hÃ ng cÃ³ duplicates\n",
    "data = {\n",
    "    'Customer_ID': [1, 2, 3, 1, 4, 2, 5, 3, 6],\n",
    "    'Name': ['An', 'BÃ¬nh', 'Chi', 'An', 'DÅ©ng', 'BÃ¬nh', 'Eva', 'Chi', 'Giang'],\n",
    "    'Email': ['an@email.com', 'binh@email.com', 'chi@email.com', \n",
    "              'an@email.com', 'dung@email.com', 'binh@email.com', \n",
    "              'eva@email.com', 'chi@email.com', 'giang@email.com'],\n",
    "    'Phone': ['0123456789', '0987654321', '0111222333', \n",
    "              '0123456789', '0444555666', '0987654321', \n",
    "              '0777888999', '0111222333', '0555666777']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. PhÃ¡t hiá»‡n cÃ¡c dÃ²ng trÃ¹ng láº·p hoÃ n toÃ n\n",
    "2. PhÃ¡t hiá»‡n cÃ¡c dÃ²ng trÃ¹ng láº·p theo Email\n",
    "3. PhÃ¡t hiá»‡n cÃ¡c dÃ²ng trÃ¹ng láº·p theo Phone\n",
    "4. Loáº¡i bá» duplicates vÃ  giá»¯ láº¡i báº£n ghi Ä‘áº§u tiÃªn\n",
    "5. Táº¡o bÃ¡o cÃ¡o sá»‘ lÆ°á»£ng duplicates Ä‘Ã£ loáº¡i bá»\n",
    "\n",
    "**Gá»£i Ã½:** `.duplicated()`, `.drop_duplicates()`, `subset` parameter\n",
    "\n",
    "---\n",
    "\n",
    "### **NhÃ³m 2: BÃ i táº­p trung bÃ¬nh (â­â­) - TÆ°Æ¡ng á»©ng Quiz cÃ¢u 11-20**\n",
    "\n",
    "### **BÃ i 2.1: Chuáº©n hÃ³a dá»¯ liá»‡u tÃ i chÃ­nh**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 11, 12, 13, 14\n",
    "\n",
    "**Äá» bÃ i:** Chuáº©n hÃ³a dá»¯ liá»‡u tÃ i chÃ­nh cá»§a cÃ¡c cÃ´ng ty Ä‘á»ƒ so sÃ¡nh\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u tÃ i chÃ­nh cÃ¡c cÃ´ng ty (Ä‘Æ¡n vá»‹: triá»‡u VND)\n",
    "data = {\n",
    "    'Company': ['VinGroup', 'Viettel', 'FPT', 'Masan', 'VNM'],\n",
    "    'Revenue': [500000, 200000, 50000, 30000, 80000],\n",
    "    'Profit': [50000, 30000, 8000, 2000, 10000],\n",
    "    'Assets': [2000000, 800000, 200000, 100000, 300000],\n",
    "    'Employees': [50000, 20000, 10000, 5000, 15000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. Ãp dá»¥ng MinMaxScaler cho táº¥t cáº£ cá»™t sá»‘\n",
    "2. Ãp dá»¥ng StandardScaler cho táº¥t cáº£ cá»™t sá»‘\n",
    "3. Ãp dá»¥ng RobustScaler cho táº¥t cáº£ cá»™t sá»‘\n",
    "4. So sÃ¡nh káº¿t quáº£ cá»§a 3 phÆ°Æ¡ng phÃ¡p\n",
    "5. Táº¡o biá»ƒu Ä‘á»“ so sÃ¡nh (boxplot) trÆ°á»›c vÃ  sau chuáº©n hÃ³a\n",
    "\n",
    "**Gá»£i Ã½:** `MinMaxScaler()`, `StandardScaler()`, `RobustScaler()`, `.fit_transform()`\n",
    "\n",
    "---\n",
    "\n",
    "### **BÃ i 2.2: Xá»­ lÃ½ chuá»—i kÃ½ tá»± trong dá»¯ liá»‡u khÃ¡ch hÃ ng**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 15, 16, 17, 18\n",
    "\n",
    "**Äá» bÃ i:** LÃ m sáº¡ch dá»¯ liá»‡u khÃ¡ch hÃ ng cÃ³ nhiá»u lá»—i Ä‘á»‹nh dáº¡ng\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u khÃ¡ch hÃ ng cáº§n lÃ m sáº¡ch\n",
    "data = {\n",
    "    'Name': ['  NGUYá»„N VÄ‚N A  ', 'tráº§n thá»‹ b', 'LÃŠ VÄ‚N C', '  Pháº¡m Thá»‹ D  '],\n",
    "    'Email': ['A@GMAIL.COM', 'b@yahoo.com', 'C@HOTMAIL.COM', 'd@gmail.com'],\n",
    "    'Phone': ['0123-456-789', '0987654321', '+84-987-654-321', '0911-222-333'],\n",
    "    'Address': ['HÃ  Ná»™i', 'TP.HCM', 'ÄÃ  Náºµng', 'Cáº§n ThÆ¡']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. Chuáº©n hÃ³a tÃªn: loáº¡i bá» khoáº£ng tráº¯ng thá»«a, viáº¿t hoa chá»¯ cÃ¡i Ä‘áº§u\n",
    "2. Chuáº©n hÃ³a email: chuyá»ƒn vá» chá»¯ thÆ°á»ng\n",
    "3. Chuáº©n hÃ³a sá»‘ Ä‘iá»‡n thoáº¡i: loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, chá»‰ giá»¯ sá»‘\n",
    "4. TrÃ­ch xuáº¥t domain tá»« email\n",
    "5. Táº¡o cá»™t \"Region\" dá»±a trÃªn Ä‘á»‹a chá»‰\n",
    "\n",
    "**Gá»£i Ã½:** `.str.strip()`, `.str.title()`, `.str.lower()`, `.str.replace()`, `.str.extract()`\n",
    "\n",
    "---\n",
    "\n",
    "### **BÃ i 2.3: MÃ£ hÃ³a dá»¯ liá»‡u phÃ¢n loáº¡i**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 19, 20\n",
    "\n",
    "**Äá» bÃ i:** Chuáº©n bá»‹ dá»¯ liá»‡u sáº£n pháº©m cho machine learning\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u sáº£n pháº©m\n",
    "data = {\n",
    "    'Product': ['iPhone 14', 'Samsung Galaxy', 'iPhone 13', 'Xiaomi Redmi', 'Oppo Reno'],\n",
    "    'Brand': ['Apple', 'Samsung', 'Apple', 'Xiaomi', 'Oppo'],\n",
    "    'Category': ['Smartphone', 'Smartphone', 'Smartphone', 'Smartphone', 'Smartphone'],\n",
    "    'Price': [25000000, 20000000, 20000000, 8000000, 12000000],\n",
    "    'Rating': ['Excellent', 'Good', 'Good', 'Average', 'Good']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. Label Encoding cho cá»™t 'Brand'\n",
    "2. One-Hot Encoding cho cá»™t 'Rating'\n",
    "3. Chuáº©n hÃ³a cá»™t 'Price' vá»›i StandardScaler\n",
    "4. Táº¡o DataFrame cuá»‘i cÃ¹ng sáºµn sÃ ng cho ML\n",
    "5. So sÃ¡nh kÃ­ch thÆ°á»›c DataFrame trÆ°á»›c vÃ  sau encoding\n",
    "\n",
    "**Gá»£i Ã½:** `LabelEncoder()`, `pd.get_dummies()`, `StandardScaler()`\n",
    "\n",
    "---\n",
    "\n",
    "### **NhÃ³m 3: BÃ i táº­p nÃ¢ng cao (â­â­â­) - TÆ°Æ¡ng á»©ng Quiz cÃ¢u 21-30**\n",
    "\n",
    "### **BÃ i 3.1: Pipeline xá»­ lÃ½ dá»¯ liá»‡u hoÃ n chá»‰nh**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 21, 22, 23\n",
    "\n",
    "**Äá» bÃ i:** XÃ¢y dá»±ng pipeline xá»­ lÃ½ dá»¯ liá»‡u kháº£o sÃ¡t thá»‹ trÆ°á»ng\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u kháº£o sÃ¡t thá»‹ trÆ°á»ng (cÃ³ nhiá»u váº¥n Ä‘á»)\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Name': ['An', 'BÃ¬nh', 'Chi', 'DÅ©ng', 'Eva', 'An', 'BÃ¬nh', 'Giang', 'HÃ¹ng', 'Lan'],\n",
    "    'Age': [25, None, 30, 28, None, 25, 35, 32, 29, 27],\n",
    "    'Income': [50000000, 60000000, None, 70000000, 55000000, 50000000, 80000000, 65000000, 45000000, 75000000],\n",
    "    'City': ['HÃ  Ná»™i', 'TP.HCM', 'HÃ  Ná»™i', 'ÄÃ  Náºµng', 'TP.HCM', 'HÃ  Ná»™i', 'TP.HCM', 'HÃ  Ná»™i', 'Cáº§n ThÆ¡', 'Háº£i PhÃ²ng'],\n",
    "    'Satisfaction': ['Ráº¥t hÃ i lÃ²ng', 'HÃ i lÃ²ng', 'BÃ¬nh thÆ°á»ng', 'HÃ i lÃ²ng', 'Ráº¥t hÃ i lÃ²ng', 'HÃ i lÃ²ng', 'BÃ¬nh thÆ°á»ng', 'HÃ i lÃ²ng', 'KhÃ´ng hÃ i lÃ²ng', 'HÃ i lÃ²ng']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. **BÆ°á»›c 1:** PhÃ¢n tÃ­ch dá»¯ liá»‡u (info, describe, missing values)\n",
    "2. **BÆ°á»›c 2:** Xá»­ lÃ½ missing values (quyáº¿t Ä‘á»‹nh phÆ°Æ¡ng phÃ¡p phÃ¹ há»£p)\n",
    "3. **BÆ°á»›c 3:** Xá»­ lÃ½ duplicates (loáº¡i bá» theo ID)\n",
    "4. **BÆ°á»›c 4:** Chuáº©n hÃ³a dá»¯ liá»‡u sá»‘ (Income)\n",
    "5. **BÆ°á»›c 5:** Encoding dá»¯ liá»‡u phÃ¢n loáº¡i (City, Satisfaction)\n",
    "6. **BÆ°á»›c 6:** Táº¡o bÃ¡o cÃ¡o tá»•ng káº¿t\n",
    "7. **BÆ°á»›c 7:** LÆ°u káº¿t quáº£ ra file CSV\n",
    "\n",
    "**Gá»£i Ã½:** Pipeline approach, `.info()`, `.describe()`, `.isnull().sum()`\n",
    "\n",
    "---\n",
    "\n",
    "### **BÃ i 3.2: Feature Engineering nÃ¢ng cao**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 24, 25, 26\n",
    "\n",
    "**Äá» bÃ i:** Táº¡o features má»›i tá»« dá»¯ liá»‡u gá»‘c\n",
    "\n",
    "```python\n",
    "# Dá»¯ liá»‡u bÃ¡n hÃ ng\n",
    "data = {\n",
    "    'Date': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],\n",
    "    'Product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone'],\n",
    "    'Price': [15000000, 8000000, 5000000, 16000000, 8500000],\n",
    "    'Quantity': [2, 5, 3, 1, 4],\n",
    "    'Customer_Age': [25, 30, 35, 28, 32],\n",
    "    'Customer_City': ['HÃ  Ná»™i', 'TP.HCM', 'ÄÃ  Náºµng', 'HÃ  Ná»™i', 'TP.HCM']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**YÃªu cáº§u:**\n",
    "1. Táº¡o cá»™t 'Total_Revenue' = Price Ã— Quantity\n",
    "2. Táº¡o cá»™t 'Price_Category' (High/Medium/Low) dá»±a trÃªn Price\n",
    "3. Táº¡o cá»™t 'Age_Group' (Young/Adult/Senior) dá»±a trÃªn Customer_Age\n",
    "4. Táº¡o cá»™t 'Region' (North/South/Central) dá»±a trÃªn Customer_City\n",
    "5. Táº¡o cá»™t 'Day_of_Week' tá»« Date\n",
    "6. Táº¡o cá»™t 'Is_Weekend' (True/False)\n",
    "7. Chuáº©n hÃ³a táº¥t cáº£ cá»™t sá»‘\n",
    "8. One-Hot encoding cho táº¥t cáº£ cá»™t phÃ¢n loáº¡i\n",
    "\n",
    "**Gá»£i Ã½:** `pd.to_datetime()`, `.dt.day_name()`, `pd.cut()`, `.map()`\n",
    "\n",
    "---\n",
    "\n",
    "### **BÃ i 3.3: Mini Project - PhÃ¢n tÃ­ch dá»¯ liá»‡u kháº£o sÃ¡t khÃ¡ch hÃ ng**\n",
    "**LiÃªn quan Ä‘áº¿n:** Quiz cÃ¢u 27-30 (Best practices, Pipeline, Advanced techniques)\n",
    "\n",
    "**Äá» bÃ i:** XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n tÃ­ch vÃ  lÃ m sáº¡ch dá»¯ liá»‡u kháº£o sÃ¡t khÃ¡ch hÃ ng\n",
    "\n",
    "**YÃªu cáº§u chi tiáº¿t:**\n",
    "\n",
    "**BÆ°á»›c 1: Thu tháº­p vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u**\n",
    "- Táº¡o dataset kháº£o sÃ¡t khÃ¡ch hÃ ng (100+ records) vá»›i cÃ¡c váº¥n Ä‘á»:\n",
    "  - Missing values (5-15% má»—i cá»™t)\n",
    "  - Duplicates (10-20%)\n",
    "  - Inconsistent formatting (names, emails, phones)\n",
    "  - Outliers trong dá»¯ liá»‡u sá»‘\n",
    "  - Categorical data cáº§n encoding\n",
    "\n",
    "**BÆ°á»›c 2: XÃ¢y dá»±ng Data Cleaning Pipeline**\n",
    "- Táº¡o class `DataCleaner` vá»›i cÃ¡c methods:\n",
    "  - `detect_missing()`: PhÃ¡t hiá»‡n vÃ  bÃ¡o cÃ¡o missing values\n",
    "  - `handle_missing()`: Xá»­ lÃ½ missing values vá»›i nhiá»u phÆ°Æ¡ng phÃ¡p\n",
    "  - `detect_duplicates()`: PhÃ¡t hiá»‡n duplicates\n",
    "  - `handle_duplicates()`: Xá»­ lÃ½ duplicates\n",
    "  - `clean_strings()`: LÃ m sáº¡ch dá»¯ liá»‡u chuá»—i\n",
    "  - `normalize_data()`: Chuáº©n hÃ³a dá»¯ liá»‡u sá»‘\n",
    "  - `encode_categorical()`: MÃ£ hÃ³a dá»¯ liá»‡u phÃ¢n loáº¡i\n",
    "\n",
    "**BÆ°á»›c 3: Ãp dá»¥ng Pipeline**\n",
    "- Ãp dá»¥ng pipeline lÃªn dataset\n",
    "- Táº¡o bÃ¡o cÃ¡o chi tiáº¿t vá»:\n",
    "  - Sá»‘ lÆ°á»£ng records trÆ°á»›c/sau cleaning\n",
    "  - CÃ¡c thay Ä‘á»•i Ä‘Æ°á»£c thá»±c hiá»‡n\n",
    "  - Cháº¥t lÆ°á»£ng dá»¯ liá»‡u cuá»‘i cÃ¹ng\n",
    "\n",
    "**BÆ°á»›c 4: Validation vÃ  Testing**\n",
    "- Táº¡o unit tests cho cÃ¡c methods\n",
    "- Validate káº¿t quáº£ cuá»‘i cÃ¹ng\n",
    "- So sÃ¡nh performance trÆ°á»›c/sau cleaning\n",
    "\n",
    "**BÆ°á»›c 5: Visualization vÃ  Reporting**\n",
    "- Táº¡o visualizations:\n",
    "  - Missing values heatmap\n",
    "  - Before/after comparison charts\n",
    "  - Data quality metrics dashboard\n",
    "- Táº¡o bÃ¡o cÃ¡o tá»•ng káº¿t (PDF/HTML)\n",
    "\n",
    "**ÄÃ¡nh giÃ¡:**\n",
    "- Correctness: 40%\n",
    "- Code quality & documentation: 30%\n",
    "- Pipeline design: 20%\n",
    "- Visualization & reporting: 10%\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78d269",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ’¡ **TIPS & TRICKS CHO SINH VIÃŠN**\n",
    "\n",
    "## **ğŸ“– CÃ¡ch há»c hiá»‡u quáº£:**\n",
    "\n",
    "### **1. Há»c theo thá»© tá»± Ä‘á»™ khÃ³ tÄƒng dáº§n**\n",
    "```\n",
    "Missing Data â†’ Duplicates â†’ Normalization â†’ String Processing â†’ Categorical Encoding\n",
    "â­â­           â­           â­â­            â­â­â­              â­â­\n",
    "```\n",
    "\n",
    "### **2. Thá»±c hÃ nh thÆ°á»ng xuyÃªn**\n",
    "- âœ… Cháº¡y láº¡i tá»«ng vÃ­ dá»¥ trong bÃ i giáº£ng\n",
    "- âœ… Thay Ä‘á»•i tham sá»‘ Ä‘á»ƒ xem káº¿t quáº£ khÃ¡c nhau\n",
    "- âœ… Ãp dá»¥ng vÃ o dá»¯ liá»‡u thá»±c táº¿ (kháº£o sÃ¡t khÃ¡ch hÃ ng, dá»¯ liá»‡u tÃ i chÃ­nh, v.v.)\n",
    "\n",
    "### **3. Xá»­ lÃ½ lá»—i Ä‘Ãºng cÃ¡ch**\n",
    "```python\n",
    "# LuÃ´n kiá»ƒm tra dá»¯ liá»‡u trÆ°á»›c khi xá»­ lÃ½\n",
    "print(\"Missing values:\", df.isnull().sum())\n",
    "print(\"Data types:\", df.dtypes)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Xá»­ lÃ½ exception\n",
    "try:\n",
    "    df_clean = df.dropna()\n",
    "except Exception as e:\n",
    "    print(f\"Lá»—i: {e}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **âš ï¸ Nhá»¯ng sai láº§m thÆ°á»ng gáº·p:**\n",
    "\n",
    "### **Top 5 lá»—i phá»• biáº¿n:**\n",
    "\n",
    "**1. KhÃ´ng kiá»ƒm tra dá»¯ liá»‡u trÆ°á»›c khi xá»­ lÃ½**\n",
    "```python\n",
    "# âŒ SAI - Trá»±c tiáº¿p xá»­ lÃ½\n",
    "df['normalized'] = scaler.fit_transform(df[['price']])\n",
    "\n",
    "# âœ… ÄÃšNG - Kiá»ƒm tra trÆ°á»›c\n",
    "print(df.isnull().sum())\n",
    "df_clean = df.dropna()\n",
    "df['normalized'] = scaler.fit_transform(df_clean[['price']])\n",
    "```\n",
    "\n",
    "**2. QuÃªn lÆ°u láº¡i DataFrame gá»‘c**\n",
    "```python\n",
    "# âŒ SAI - Máº¥t dá»¯ liá»‡u gá»‘c\n",
    "df = df.dropna()  # KhÃ´ng thá»ƒ quay láº¡i\n",
    "\n",
    "# âœ… ÄÃšNG - Giá»¯ báº£n gá»‘c\n",
    "df_original = df.copy()\n",
    "df_clean = df.dropna()\n",
    "```\n",
    "\n",
    "**3. KhÃ´ng hiá»ƒu sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c scaler**\n",
    "```python\n",
    "# âŒ SAI - DÃ¹ng sai scaler\n",
    "# MinMaxScaler cho dá»¯ liá»‡u cÃ³ outliers\n",
    "\n",
    "# âœ… ÄÃšNG - Chá»n scaler phÃ¹ há»£p\n",
    "# MinMaxScaler: Dá»¯ liá»‡u khÃ´ng cÃ³ outliers\n",
    "# StandardScaler: Dá»¯ liá»‡u cÃ³ phÃ¢n phá»‘i chuáº©n\n",
    "# RobustScaler: Dá»¯ liá»‡u cÃ³ outliers\n",
    "```\n",
    "\n",
    "**4. Encoding khÃ´ng phÃ¹ há»£p vá»›i loáº¡i dá»¯ liá»‡u**\n",
    "```python\n",
    "# âŒ SAI - Label encoding cho nominal data\n",
    "df['city_encoded'] = LabelEncoder().fit_transform(df['city'])\n",
    "\n",
    "# âœ… ÄÃšNG - One-hot cho nominal, Label cho ordinal\n",
    "df_encoded = pd.get_dummies(df, columns=['city'])  # Nominal\n",
    "df['rating_encoded'] = LabelEncoder().fit_transform(df['rating'])  # Ordinal\n",
    "```\n",
    "\n",
    "**5. KhÃ´ng validate káº¿t quáº£ sau khi xá»­ lÃ½**\n",
    "```python\n",
    "# âŒ SAI - KhÃ´ng kiá»ƒm tra káº¿t quáº£\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# âœ… ÄÃšNG - Validate káº¿t quáº£\n",
    "df_clean = df.dropna()\n",
    "print(f\"TrÆ°á»›c: {df.shape[0]} dÃ²ng, Sau: {df_clean.shape[0]} dÃ²ng\")\n",
    "print(\"Missing values cÃ²n láº¡i:\", df_clean.isnull().sum().sum())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ”§ Best Practices:**\n",
    "\n",
    "### **1. Data Cleaning Pipeline**\n",
    "```python\n",
    "def clean_data(df):\n",
    "    \"\"\"Pipeline lÃ m sáº¡ch dá»¯ liá»‡u\"\"\"\n",
    "    # BÆ°á»›c 1: PhÃ¢n tÃ­ch\n",
    "    print(\"=== PHÃ‚N TÃCH Dá»® LIá»†U ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    \n",
    "    # BÆ°á»›c 2: Xá»­ lÃ½ missing values\n",
    "    print(\"\\n=== Xá»¬ LÃ MISSING VALUES ===\")\n",
    "    df_clean = df.dropna()  # hoáº·c fillna()\n",
    "    \n",
    "    # BÆ°á»›c 3: Xá»­ lÃ½ duplicates\n",
    "    print(\"\\n=== Xá»¬ LÃ DUPLICATES ===\")\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    \n",
    "    # BÆ°á»›c 4: Chuáº©n hÃ³a\n",
    "    print(\"\\n=== CHUáº¨N HÃ“A Dá»® LIá»†U ===\")\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    df_clean[numeric_cols] = scaler.fit_transform(df_clean[numeric_cols])\n",
    "    \n",
    "    return df_clean\n",
    "```\n",
    "\n",
    "### **2. Validation Functions**\n",
    "```python\n",
    "def validate_cleaning(df_original, df_cleaned):\n",
    "    \"\"\"Validate káº¿t quáº£ lÃ m sáº¡ch\"\"\"\n",
    "    print(\"=== VALIDATION REPORT ===\")\n",
    "    print(f\"Records: {df_original.shape[0]} â†’ {df_cleaned.shape[0]}\")\n",
    "    print(f\"Columns: {df_original.shape[1]} â†’ {df_cleaned.shape[1]}\")\n",
    "    print(f\"Missing values: {df_original.isnull().sum().sum()} â†’ {df_cleaned.isnull().sum().sum()}\")\n",
    "    print(f\"Duplicates: {df_original.duplicated().sum()} â†’ {df_cleaned.duplicated().sum()}\")\n",
    "```\n",
    "\n",
    "### **3. Visualization cho Data Quality**\n",
    "```python\n",
    "def plot_data_quality(df):\n",
    "    \"\"\"Váº½ biá»ƒu Ä‘á»“ cháº¥t lÆ°á»£ng dá»¯ liá»‡u\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    sns.heatmap(df.isnull(), ax=axes[0,0], cbar=True)\n",
    "    axes[0,0].set_title('Missing Values Heatmap')\n",
    "    \n",
    "    # Missing values bar chart\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_counts[missing_counts > 0].plot(kind='bar', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Missing Values Count')\n",
    "    \n",
    "    # Data types distribution\n",
    "    df.dtypes.value_counts().plot(kind='pie', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Data Types Distribution')\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    axes[1,1].pie([duplicate_count, len(df)-duplicate_count], \n",
    "                   labels=['Duplicates', 'Unique'], autopct='%1.1f%%')\n",
    "    axes[1,1].set_title('Duplicate Records')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸš€ Lá»™ trÃ¬nh há»c tiáº¿p:**\n",
    "\n",
    "### **BÆ°á»›c tiáº¿p theo:**\n",
    "1. **BÃ i 6: Data Visualization** - Trá»±c quan hÃ³a dá»¯ liá»‡u\n",
    "2. **BÃ i 7: Statistical Analysis** - PhÃ¢n tÃ­ch thá»‘ng kÃª\n",
    "3. **BÃ i 8: Machine Learning** - XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n\n",
    "4. **BÃ i 9: Model Evaluation** - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh\n",
    "\n",
    "### **TÃ i liá»‡u tham kháº£o:**\n",
    "- ğŸ“š Pandas Documentation: https://pandas.pydata.org/docs/\n",
    "- ğŸ“š Scikit-learn Preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- ğŸ“š Data Cleaning Best Practices: https://realpython.com/python-data-cleaning-numpy-pandas/\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Checklist trÆ°á»›c khi káº¿t thÃºc:**\n",
    "\n",
    "- [ ] ÄÃ£ cháº¡y thá»­ táº¥t cáº£ code cells\n",
    "- [ ] Hiá»ƒu rÃµ sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ missing values\n",
    "- [ ] Biáº¿t cÃ¡ch chá»n scaler phÃ¹ há»£p\n",
    "- [ ] Biáº¿t cÃ¡ch encoding dá»¯ liá»‡u phÃ¢n loáº¡i Ä‘Ãºng cÃ¡ch\n",
    "- [ ] ÄÃ£ thá»­ lÃ m Ã­t nháº¥t 2 bÃ i táº­p\n",
    "- [ ] ÄÃ£ lÆ°u notebook vÃ  káº¿t quáº£\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ“ **Káº¾T THÃšC BÃ€I GIáº¢NG**\n",
    "\n",
    "> **ChÃºc cÃ¡c báº¡n há»c tá»‘t vÃ  thÃ nh cÃ´ng trong viá»‡c lÃ m sáº¡ch dá»¯ liá»‡u!** ğŸš€\n",
    "> \n",
    "> **CÃ¢u há»i?** LiÃªn há»‡ giáº£ng viÃªn qua email hoáº·c trong giá» há»c.\n",
    "\n",
    "**BÃ i giáº£ng tiáº¿p theo:** Trá»±c quan hÃ³a dá»¯ liá»‡u (Data Visualization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26077b9f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr-datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
