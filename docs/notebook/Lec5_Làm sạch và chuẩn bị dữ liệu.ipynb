{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a35277-2812-41cc-a00e-c99ade49156f",
   "metadata": {},
   "source": [
    "# 📊 Làm sạch và chuẩn bị dữ liệu trong Khoa học Dữ liệu\n",
    "\n",
    "## 🎯 Mục tiêu học tập\n",
    "\n",
    "Sau khi hoàn thành bài học này, bạn sẽ có thể:\n",
    "\n",
    "✅ **Hiểu và xử lý dữ liệu thiếu** trong các bộ dữ liệu kinh tế  \n",
    "✅ **Phát hiện và loại bỏ dữ liệu trùng lặp** trong khảo sát khách hàng  \n",
    "✅ **Chuẩn hóa và biến đổi dữ liệu** để phù hợp với phân tích  \n",
    "✅ **Xử lý dữ liệu chuỗi ký tự** từ các nguồn khác nhau  \n",
    "✅ **Mã hóa dữ liệu phân loại** cho machine learning  \n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Lộ trình học tập\n",
    "\n",
    "1. **🔍 Xử lý dữ liệu thiếu** - Tại sao dữ liệu bị thiếu và cách xử lý\n",
    "2. **🔄 Xử lý dữ liệu trùng lặp** - Phát hiện và loại bỏ duplicates  \n",
    "3. **📐 Biến đổi và chuẩn hóa** - Đưa dữ liệu về cùng thang đo\n",
    "4. **📝 Xử lý chuỗi ký tự** - Làm sạch text data\n",
    "5. **🏷️ Xử lý dữ liệu phân loại** - Encoding cho ML algorithms\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Lưu ý quan trọng\n",
    "\n",
    "> **💡 Cho sinh viên Kinh tế:** Bài học này tập trung vào các kỹ thuật thực tế mà bạn sẽ sử dụng khi phân tích dữ liệu kinh tế, khảo sát khách hàng, và nghiên cứu thị trường.\n",
    "\n",
    "> **🔧 Tương thích:** Notebook này hoạt động tốt trên cả **Jupyter Notebook**, **JupyterLab**, và **Google Colab**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc92628e",
   "metadata": {},
   "source": [
    "## 🛠️ Thiết lập môi trường\n",
    "\n",
    "Trước khi bắt đầu, hãy đảm bảo bạn đã cài đặt các thư viện cần thiết:\n",
    "\n",
    "**📦 Cài đặt thư viện (chạy cell này nếu bạn đang sử dụng Google Colab):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6aa4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt thư viện cho Google Colab (bỏ qua nếu đã cài đặt)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, KNNImputer\n",
    "    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "    print(\"✅ Tất cả thư viện đã sẵn sàng!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Thiếu thư viện: {e}\")\n",
    "    print(\"🔧 Đang cài đặt...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # Cài đặt các thư viện cần thiết\n",
    "    packages = ['pandas', 'numpy', 'scikit-learn']\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "    \n",
    "    print(\"✅ Cài đặt hoàn tất! Vui lòng restart kernel và chạy lại cell này.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d87558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8867191",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79fbd8d0",
   "metadata": {},
   "source": [
    "# 🔍 Phần 1: Xử lý dữ liệu thiếu (Missing Data)\n",
    "\n",
    "## 📊 Tại sao dữ liệu thiếu quan trọng trong kinh tế?\n",
    "\n",
    "Trong thực tế kinh doanh và nghiên cứu kinh tế, **dữ liệu thiếu** là vấn đề rất phổ biến:\n",
    "\n",
    "### 🏢 Ví dụ thực tế từ doanh nghiệp:\n",
    "- **Khảo sát khách hàng**: Một số khách hàng không trả lời câu hỏi về thu nhập\n",
    "- **Báo cáo tài chính**: Một số công ty không công bố đầy đủ thông tin\n",
    "- **Dữ liệu thị trường**: Giá cổ phiếu có thể bị thiếu trong ngày nghỉ lễ\n",
    "- **Nghiên cứu kinh tế**: Một số hộ gia đình từ chối cung cấp thông tin chi tiêu\n",
    "\n",
    "### ⚠️ Tác động của dữ liệu thiếu:\n",
    "- **Giảm độ tin cậy** của phân tích\n",
    "- **Thiên lệch kết quả** nghiên cứu\n",
    "- **Khó khăn trong dự báo** kinh tế\n",
    "- **Ảnh hưởng đến quyết định** đầu tư"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb9881",
   "metadata": {},
   "source": [
    "### Hiểu về dữ liệu thiếu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d04b1",
   "metadata": {},
   "source": [
    "* Trong thực tế, khi thu thập và lưu trữ dữ liệu, không phải lúc nào mọi giá trị cũng được ghi nhận đầy đủ.\n",
    "* Một số ô có thể bị trống hoặc mang các ký hiệu đặc biệt như NA, NaN, NULL, hoặc chuỗi rỗng \"\". Đây chính là dữ liệu thiếu (missing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a667638",
   "metadata": {},
   "source": [
    "### 🔍 Các dạng thiếu dữ liệu trong kinh tế\n",
    "\n",
    "Trong nghiên cứu kinh tế, chúng ta phân loại dữ liệu thiếu thành 3 loại chính:\n",
    "\n",
    "#### 1️⃣ **MCAR (Missing Completely At Random)** - Thiếu hoàn toàn ngẫu nhiên\n",
    "- **Ví dụ**: Máy tính bị lỗi khi thu thập dữ liệu giá cổ phiếu\n",
    "- **Đặc điểm**: Không liên quan đến bất kỳ yếu tố nào\n",
    "- **Xử lý**: Có thể loại bỏ an toàn\n",
    "\n",
    "#### 2️⃣ **MAR (Missing At Random)** - Thiếu có điều kiện\n",
    "- **Ví dụ**: Người có thu nhập cao thường không trả lời câu hỏi về thu nhập\n",
    "- **Đặc điểm**: Phụ thuộc vào các biến khác có thể quan sát được\n",
    "- **Xử lý**: Cần phân tích cẩn thận\n",
    "\n",
    "#### 3️⃣ **MNAR (Missing Not At Random)** - Thiếu có hệ thống\n",
    "- **Ví dụ**: Công ty có lợi nhuận thấp thường không công bố báo cáo tài chính\n",
    "- **Đặc điểm**: Liên quan trực tiếp đến giá trị bị thiếu\n",
    "- **Xử lý**: Cần kỹ thuật phức tạp để xử lý\n",
    "\n",
    "### 📋 Biểu diễn dữ liệu thiếu trong Python:\n",
    "- `NaN` (*Not a Number*) - cho dữ liệu số\n",
    "- `None` - cho dữ liệu đối tượng  \n",
    "- `NaT` (*Not a Time*) - cho dữ liệu thời gian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26c07b",
   "metadata": {},
   "source": [
    "### 🎯 Nguyên nhân gây ra dữ liệu thiếu trong kinh tế\n",
    "\n",
    "#### 📊 **Lỗi thu thập dữ liệu**\n",
    "- **Ví dụ**: Hệ thống giao dịch chứng khoán bị sập trong giờ cao điểm\n",
    "- **Tác động**: Mất dữ liệu giá cổ phiếu quan trọng\n",
    "\n",
    "#### 👥 **Người dùng không cung cấp**\n",
    "- **Ví dụ**: Khách hàng bỏ qua câu hỏi về thu nhập trong khảo sát\n",
    "- **Tác động**: Thiếu thông tin để phân tích hành vi tiêu dùng\n",
    "\n",
    "#### 📈 **Dữ liệu không tồn tại**\n",
    "- **Ví dụ**: Công ty mới thành lập chưa có báo cáo tài chính năm trước\n",
    "- **Tác động**: Khó so sánh hiệu suất với các công ty khác\n",
    "\n",
    "#### 🔄 **Lỗi xử lý dữ liệu**\n",
    "- **Ví dụ**: Lỗi khi chuyển đổi định dạng từ Excel sang CSV\n",
    "- **Tác động**: Mất thông tin quan trọng trong quá trình chuyển đổi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d455ee",
   "metadata": {},
   "source": [
    "### ⚠️ Tác động của dữ liệu thiếu đến phân tích kinh tế\n",
    "\n",
    "#### 📉 **Giảm kích thước mẫu**\n",
    "- **Ví dụ**: Khảo sát 1000 khách hàng, nhưng chỉ có 800 người trả lời đầy đủ\n",
    "- **Tác động**: Giảm độ tin cậy của kết quả nghiên cứu\n",
    "\n",
    "#### 🎯 **Thiên lệch kết quả**\n",
    "- **Ví dụ**: Chỉ những người có thu nhập cao mới trả lời câu hỏi về thu nhập\n",
    "- **Tác động**: Kết quả phân tích không đại diện cho toàn bộ dân số\n",
    "\n",
    "#### 🤖 **Giảm hiệu quả phân tích**\n",
    "- **Ví dụ**: Thuật toán machine learning không thể xử lý dữ liệu thiếu\n",
    "- **Tác động**: Không thể dự báo xu hướng thị trường chính xác\n",
    "\n",
    "#### 💼 **Ảnh hưởng quyết định kinh doanh**\n",
    "- **Ví dụ**: Thiếu dữ liệu về đối thủ cạnh tranh\n",
    "- **Tác động**: Ra quyết định đầu tư không chính xác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e720916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Ví dụ thực tế: Dữ liệu nhân viên công ty có missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu về nhân viên công ty (tình huống thực tế)\n",
    "print(\"🏢 VÍ DỤ: Dữ liệu nhân viên công ty có missing values\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyễn Văn A', 'Trần Thị B', 'Lê Văn C', 'Phạm Thị D', 'Hoàng Văn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],  # Một số nhân viên không cung cấp tuổi\n",
    "    'Luong': [15000000, 18000000, None, 22000000, 16000000],  # Lương bị thiếu\n",
    "    'PhongBan': ['IT', 'Marketing', None, 'IT', 'Marketing'],  # Phòng ban không rõ\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]  # Kinh nghiệm chưa được cập nhật\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"📋 DataFrame nhân viên với dữ liệu thiếu:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(f\"\\n📊 Thông tin tổng quan:\")\n",
    "print(f\"   - Tổng số nhân viên: {len(df_nhanvien)}\")\n",
    "print(f\"   - Số cột: {len(df_nhanvien.columns)}\")\n",
    "print(f\"   - Kiểu dữ liệu:\")\n",
    "print(df_nhanvien.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c84ff4",
   "metadata": {},
   "source": [
    "### 🔍 Các phương thức phát hiện dữ liệu thiếu trong pandas\n",
    "\n",
    "Pandas cung cấp các phương thức chuyên dụng để **phát hiện và kiểm tra dữ liệu thiếu**:\n",
    "\n",
    "| Phương thức | Mô tả | Trả về | Ví dụ sử dụng |\n",
    "|-------------|-------|--------|---------------|\n",
    "| `isna()` / `isnull()` | Kiểm tra từng phần tử có thiếu không | Boolean DataFrame/Series | `df.isna()` |\n",
    "| `notna()` / `notnull()` | Kiểm tra từng phần tử có dữ liệu không | Boolean DataFrame/Series | `df.notna()` |\n",
    "| `isna().sum()` | Đếm số lượng dữ liệu thiếu theo cột | Series với số lượng | `df.isna().sum()` |\n",
    "| `isna().any()` | Kiểm tra có cột nào thiếu dữ liệu không | Boolean Series | `df.isna().any()` |\n",
    "\n",
    "**📊 Hãy xem cách sử dụng các phương thức này với dữ liệu nhân viên:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ba1fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 DEMO: Phát hiện dữ liệu thiếu trong DataFrame nhân viên\n",
    "print(\"🔍 DEMO: Các phương thức phát hiện dữ liệu thiếu\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sử dụng DataFrame từ cell trước\n",
    "print(\"📋 DataFrame gốc:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1️⃣ KIỂM TRA TỪNG PHẦN TỬ CÓ THIẾU KHÔNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Kiểm tra dữ liệu thiếu - trả về Boolean DataFrame\n",
    "print(\"🔍 df_nhanvien.isna() - Kiểm tra từng ô có thiếu không:\")\n",
    "print(df_nhanvien.isna())\n",
    "\n",
    "print(\"\\n🔍 df_nhanvien.notna() - Kiểm tra từng ô có dữ liệu không:\")\n",
    "print(df_nhanvien.notna())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2️⃣ ĐẾM SỐ LƯỢNG DỮ LIỆU THIẾU THEO CỘT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 2. Đếm số lượng dữ liệu thiếu theo từng cột\n",
    "print(\"📊 df_nhanvien.isna().sum() - Số lượng missing values theo cột:\")\n",
    "missing_count = df_nhanvien.isna().sum()\n",
    "print(missing_count)\n",
    "\n",
    "# Tính phần trăm missing\n",
    "print(\"\\n📈 Tỷ lệ missing values (%):\")\n",
    "missing_percent = (missing_count / len(df_nhanvien)) * 100\n",
    "print(missing_percent.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3️⃣ KIỂM TRA CỘT NÀO CÓ DỮ LIỆU THIẾU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 3. Kiểm tra cột nào có dữ liệu thiếu\n",
    "print(\"🔍 df_nhanvien.isna().any() - Cột nào có missing values:\")\n",
    "print(df_nhanvien.isna().any())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4️⃣ TỔNG SỐ DỮ LIỆU THIẾU\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 4. Tổng số dữ liệu thiếu trong toàn bộ DataFrame\n",
    "total_missing = df_nhanvien.isna().sum().sum()\n",
    "total_cells = df_nhanvien.shape[0] * df_nhanvien.shape[1]\n",
    "missing_percentage = (total_missing / total_cells) * 100\n",
    "\n",
    "print(f\"📊 Tổng số missing values: {total_missing}\")\n",
    "print(f\"📊 Tổng số ô dữ liệu: {total_cells}\")\n",
    "print(f\"📊 Tỷ lệ missing: {missing_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23b439",
   "metadata": {},
   "source": [
    "### 🛠️ Các phương pháp xử lý dữ liệu thiếu trong kinh tế\n",
    "\n",
    "**🎯 Có 3 cách chính để xử lý dữ liệu thiếu:**\n",
    "\n",
    "#### 1️⃣ **Loại bỏ** (*Deletion*) \n",
    "- **Khi nào dùng**: Dữ liệu thiếu < 5%, thiếu ngẫu nhiên\n",
    "- **Ví dụ**: Loại bỏ khách hàng không trả lời đầy đủ khảo sát\n",
    "- **Ưu điểm**: Đơn giản, không tạo bias\n",
    "- **Nhược điểm**: Giảm kích thước mẫu\n",
    "\n",
    "#### 2️⃣ **Thay thế** (*Imputation*)\n",
    "- **Khi nào dùng**: Dữ liệu thiếu 5-20%, có pattern\n",
    "- **Ví dụ**: Thay thế lương thiếu bằng lương trung bình của phòng ban\n",
    "- **Ưu điểm**: Giữ nguyên kích thước mẫu\n",
    "- **Nhược điểm**: Có thể tạo bias\n",
    "\n",
    "#### 3️⃣ **Dự đoán** (*Prediction*)\n",
    "- **Khi nào dùng**: Dữ liệu thiếu > 20%, có mối quan hệ phức tạp\n",
    "- **Ví dụ**: Dùng machine learning để dự đoán thu nhập dựa trên các yếu tố khác\n",
    "- **Ưu điểm**: Chính xác cao\n",
    "- **Nhược điểm**: Phức tạp, cần hiểu biết về ML\n",
    "\n",
    "**⚖️ Hướng dẫn lựa chọn phương pháp:**\n",
    "\n",
    "| Tỷ lệ thiếu | Loại dữ liệu | Phương pháp khuyến nghị |\n",
    "|-------------|--------------|------------------------|\n",
    "| < 5% | Bất kỳ | Loại bỏ |\n",
    "| 5-20% | Số | Mean/Median |\n",
    "| 5-20% | Phân loại | Mode |\n",
    "| > 20% | Có quan hệ | Machine Learning |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27c281",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8cddba",
   "metadata": {},
   "source": [
    "#### **Phương pháp 1: Loại bỏ dữ liệu thiếu (`dropna`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b627f4",
   "metadata": {},
   "source": [
    "Phương thức `dropna()` cho phép loại bỏ các hàng hoặc cột có dữ liệu thiếu:\n",
    "\n",
    "**📋 Các tham số quan trọng của `dropna()`:**\n",
    "\n",
    "| Tham số | Giá trị | Mô tả |\n",
    "|---------|---------|-------|\n",
    "| `axis` | 0 (default) / 1 | 0: loại bỏ hàng, 1: loại bỏ cột |\n",
    "| `how` | 'any' (default) / 'all' | 'any': có ít nhất 1 NaN, 'all': toàn bộ là NaN |\n",
    "| `subset` | list | Chỉ xét dữ liệu thiếu trong các cột được chỉ định |\n",
    "| `thresh` | int | Số lượng giá trị không null tối thiểu cần có |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu với dữ liệu thiếu\n",
    "data_missing = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Tuổi': [25, None, 30, 28, None],\n",
    "    'Lương': [15000000, 18000000, None, 22000000, 16000000],\n",
    "    'Phòng ban': ['IT', 'Marketing', None, 'IT', 'Marketing']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data_missing)\n",
    "print(\"DataFrame với dữ liệu thiếu:\")\n",
    "print(df_missing)\n",
    "\n",
    "# 1. Loại bỏ tất cả hàng có ít nhất 1 giá trị thiếu\n",
    "print(\"1. Loại bỏ hàng có dữ liệu thiếu (how='any'):\")\n",
    "df_drop_any = df_missing.dropna()\n",
    "print(df_drop_any)\n",
    "print(f\"Số hàng còn lại: {len(df_drop_any)}\")\n",
    "\n",
    "# 2. Loại bỏ hàng chỉ khi TẤT CẢ giá trị đều thiếu\n",
    "print(\"2. Loại bỏ hàng khi tất cả giá trị đều thiếu (how='all'):\")\n",
    "df_drop_all = df_missing.dropna(how='all')\n",
    "print(df_drop_all)\n",
    "print(f\"Số hàng còn lại: {len(df_drop_all)}\")\n",
    "\n",
    "# 3. Loại bỏ cột có dữ liệu thiếu\n",
    "print(\"3. Loại bỏ cột có dữ liệu thiếu (axis=1):\")\n",
    "df_drop_cols = df_missing.dropna(axis=1)\n",
    "print(df_drop_cols)\n",
    "print(f\"Số cột còn lại: {len(df_drop_cols.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee315f8",
   "metadata": {},
   "source": [
    "#### **Phương pháp 2: Thay thế dữ liệu thiếu (`fillna`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff3235",
   "metadata": {},
   "source": [
    "Phương thức `fillna()` cho phép **thay thế dữ liệu thiếu** bằng các giá trị cụ thể:\n",
    "\n",
    "**🔧 Các chiến lược thay thế phổ biến:**\n",
    "\n",
    "| Chiến lược | Ứng dụng | Ví dụ |\n",
    "|------------|----------|-------|\n",
    "| **Giá trị cố định** | Thay thế bằng một giá trị nhất định | `fillna(0)`, `fillna('Unknown')` |\n",
    "| **Giá trị trung bình** | Dữ liệu số, phân phối chuẩn | `fillna(df['col'].mean())` |\n",
    "| **Giá trị trung vị** | Dữ liệu số, có outliers | `fillna(df['col'].median())` |\n",
    "| **Giá trị phổ biến nhất** | Dữ liệu phân loại | `fillna(df['col'].mode()[0])` |\n",
    "| **Forward fill** | Dữ liệu chuỗi thời gian | `fillna(method='ffill')` |\n",
    "| **Backward fill** | Dữ liệu chuỗi thời gian | `fillna(method='bfill')` |\n",
    "\n",
    "**📊 Hãy xem các ví dụ cụ thể:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d63477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu với dữ liệu thiếu\n",
    "data_missing = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Tuổi': [25, None, 30, 28, None],\n",
    "    'Lương': [15000000, 18000000, None, 22000000, 16000000],\n",
    "    'Phòng ban': ['IT', 'Marketing', None, 'IT', 'Marketing']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data_missing)\n",
    "print(\"DataFrame với dữ liệu thiếu:\")\n",
    "print(df_missing)\n",
    "\n",
    "# 1. Thay thế bằng giá trị cố định\n",
    "print(\"\\n1. Thay thế bằng giá trị cố định:\")\n",
    "df_fill_fixed = df_missing.fillna({'Tuổi': 0, 'Lương': 0, 'Phòng ban': 'Chưa xác định'})\n",
    "print(df_fill_fixed)\n",
    "\n",
    "# 2. Thay thế bằng giá trị trung bình (cho dữ liệu số)\n",
    "print(\"\\n2. Thay thế bằng giá trị trung bình:\")\n",
    "df_fill_mean = df_missing.copy()\n",
    "df_fill_mean['Tuổi'] = df_fill_mean['Tuổi'].fillna(df_fill_mean['Tuổi'].mean())\n",
    "df_fill_mean['Lương'] = df_fill_mean['Lương'].fillna(df_fill_mean['Lương'].mean())\n",
    "print(df_fill_mean)\n",
    "print(f\"Tuổi trung bình: {df_missing['Tuổi'].mean():.1f}\")\n",
    "print(f\"Lương trung bình: {df_missing['Lương'].mean():,.0f}\")\n",
    "\n",
    "# 3. Thay thế bằng giá trị trung vị (bền vững với outliers)\n",
    "print(\"\\n3. Thay thế bằng giá trị trung vị:\")\n",
    "df_fill_median = df_missing.copy()\n",
    "df_fill_median['Tuổi'] = df_fill_median['Tuổi'].fillna(df_fill_median['Tuổi'].median())\n",
    "df_fill_median['Lương'] = df_fill_median['Lương'].fillna(df_fill_median['Lương'].median())\n",
    "print(df_fill_median)\n",
    "\n",
    "# 4. Thay thế bằng giá trị phổ biến nhất (mode) - cho dữ liệu phân loại\n",
    "print(\"\\n4. Thay thế bằng giá trị phổ biến nhất (mode):\")\n",
    "df_fill_mode = df_missing.copy()\n",
    "df_fill_mode['Phòng ban'] = df_fill_mode['Phòng ban'].fillna(df_fill_mode['Phòng ban'].mode()[0])\n",
    "print(df_fill_mode)\n",
    "print(f\"Phòng ban phổ biến nhất: {df_missing['Phòng ban'].mode()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff8a4a",
   "metadata": {},
   "source": [
    "#### Phương pháp 3: Sử dụng mô hình dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68faa286",
   "metadata": {},
   "source": [
    "Sử dụng các mô hình **dự đoán** để ước lượng giá trị thiếu.\n",
    "\n",
    "**🔧 Các chiến lược thay thế phổ biến:**\n",
    "\n",
    "| Chiến lược | Ứng dụng | Ví dụ |\n",
    "|------------|----------|-------|\n",
    "| **Hồi quy** | Dữ liệu số | Sử dụng hồi quy tuyến tính để dự đoán giá trị |\n",
    "| **Phân loại** | Dữ liệu phân loại | Sử dụng cây quyết định để phân loại giá trị |\n",
    "| **Phân tích thống kê** | Dữ liệu số | Sử dụng thống kê để dự đoán giá trị |\n",
    "\n",
    "**📊 Hãy xem các ví dụ cụ thể:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b53ebe",
   "metadata": {},
   "source": [
    "**🤖 Khi nào sử dụng Machine Learning cho Missing Values:**\n",
    "\n",
    "- **Dữ liệu có mối quan hệ phức tạp**: Các biến có correlation cao với nhau\n",
    "- **Dữ liệu missing không ngẫu nhiên**: Missing data có pattern đặc biệt\n",
    "- **Dữ liệu quan trọng**: Không muốn mất thông tin bằng cách loại bỏ\n",
    "- **Yêu cầu độ chính xác cao**: Muốn dự đoán chính xác nhất có thể\n",
    "\n",
    "**⚡ Các kỹ thuật Machine Learning phổ biến:**\n",
    "\n",
    "- **Regression**: Dự đoán giá trị số (Linear, Random Forest, XGBoost)\n",
    "- **Classification**: Dự đoán giá trị phân loại (Decision Tree, SVM)\n",
    "- **Clustering**: Nhóm các quan sát tương tự (K-Means, DBSCAN)\n",
    "- **Deep Learning**: Neural Networks cho dữ liệu phức tạp\n",
    "\n",
    "**🎯 Ưu điểm và nhược điểm:**\n",
    "\n",
    "✅ **Ưu điểm:**\n",
    "- Độ chính xác cao hơn mean/median/mode\n",
    "- Tận dụng được mối quan hệ giữa các biến\n",
    "- Linh hoạt với nhiều loại dữ liệu\n",
    "\n",
    "❌ **Nhược điểm:**\n",
    "- Phức tạp, cần hiểu biết về ML\n",
    "- Tốn thời gian training\n",
    "- Có thể overfitting nếu không cẩn thận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết cho machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo DataFrame mẫu với dữ liệu thiếu phức tạp hơn\n",
    "print(\"📊 Tạo dữ liệu mẫu cho các ví dụ Machine Learning:\")\n",
    "\n",
    "data_advanced = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva', 'Phong', 'Giang', 'Hoa'],\n",
    "    'Tuổi': [25, None, 30, 28, None, 35, None, 32],\n",
    "    'Lương': [15000000, 18000000, None, 22000000, 16000000, None, 25000000, None],\n",
    "    'Phòng ban': ['IT', 'Marketing', None, 'IT', 'Marketing', 'IT', 'HR', 'HR'],\n",
    "    'Kinh nghiệm': [2, 5, 7, 3, 1, 10, 8, 6]\n",
    "}\n",
    "\n",
    "df_advanced = pd.DataFrame(data_advanced)\n",
    "print(\"Dữ liệu gốc:\")\n",
    "print(df_advanced)\n",
    "print(f\"\\n📈 Tỷ lệ missing data:\")\n",
    "missing_percent = (df_advanced.isnull().sum() / len(df_advanced)) * 100\n",
    "print(missing_percent[missing_percent > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd93f66",
   "metadata": {},
   "source": [
    "#### **A. Random Forest Regression - Dự đoán giá trị số**\n",
    "\n",
    "**🌲 Random Forest là gì?**\n",
    "\n",
    "Random Forest là thuật toán **ensemble learning** kết hợp nhiều **Decision Trees**:\n",
    "\n",
    "- **Ensemble**: Kết hợp nhiều mô hình yếu thành một mô hình mạnh\n",
    "- **Bootstrap Aggregating**: Mỗi tree được train trên một subset ngẫu nhiên của dữ liệu\n",
    "- **Feature Randomness**: Mỗi split chỉ xét một subset ngẫu nhiên của features\n",
    "- **Voting**: Kết quả cuối cùng là trung bình của tất cả trees (regression) hoặc vote đa số (classification)\n",
    "\n",
    "**🎯 Ưu điểm của Random Forest:**\n",
    "- **Robust**: Ít bị overfitting nhờ averaging nhiều trees\n",
    "- **Handle Missing Values**: Có thể xử lý missing values trong quá trình training\n",
    "- **Feature Importance**: Cung cấp thông tin về tầm quan trọng của từng feature\n",
    "- **Non-linear**: Có thể học được các mối quan hệ phi tuyến phức tạp\n",
    "\n",
    "**⚙️ Các tham số quan trọng:**\n",
    "- `n_estimators`: Số lượng trees (default=100)\n",
    "- `max_depth`: Độ sâu tối đa của tree\n",
    "- `min_samples_split`: Số sample tối thiểu để split node\n",
    "- `random_state`: Seed cho reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf59cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 DEMO 1: Dự đoán Tuổi dựa trên Lương, Phòng ban và Kinh nghiệm\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Bước 1: Chuẩn bị dữ liệu\n",
    "df_predict_age = df_advanced.copy()\n",
    "\n",
    "# Encode categorical data (Phòng ban)\n",
    "le_dept = LabelEncoder()\n",
    "df_predict_age['Phòng ban_encoded'] = le_dept.fit_transform(df_predict_age['Phòng ban'].fillna('Unknown'))\n",
    "\n",
    "print(\"📋 Mapping Phòng ban:\")\n",
    "dept_mapping = dict(zip(le_dept.classes_, le_dept.transform(le_dept.classes_)))\n",
    "print(dept_mapping)\n",
    "\n",
    "# Bước 2: Tách dữ liệu train và missing\n",
    "train_data = df_predict_age[df_predict_age['Tuổi'].notna()]\n",
    "missing_data = df_predict_age[df_predict_age['Tuổi'].isna()]\n",
    "\n",
    "print(f\"\\n📊 Dữ liệu train: {len(train_data)} samples\")\n",
    "print(f\"📊 Dữ liệu cần dự đoán: {len(missing_data)} samples\")\n",
    "\n",
    "if len(train_data) > 0 and len(missing_data) > 0:\n",
    "    # Bước 3: Chuẩn bị features và target\n",
    "    features = ['Lương', 'Phòng ban_encoded', 'Kinh nghiệm']\n",
    "    X_train = train_data[features].fillna(0)  # Fillna tạm thời cho missing features\n",
    "    y_train = train_data['Tuổi']\n",
    "    \n",
    "    print(f\"\\n🔧 Features sử dụng: {features}\")\n",
    "    print(\"📈 Training data:\")\n",
    "    print(X_train)\n",
    "    print(f\"\\n🎯 Target (Tuổi):\")\n",
    "    print(y_train.values)\n",
    "    \n",
    "    # Bước 4: Training model\n",
    "    model_age = RandomForestRegressor(n_estimators=10, random_state=42, max_depth=3)\n",
    "    model_age.fit(X_train, y_train)\n",
    "    \n",
    "    # Bước 5: Dự đoán\n",
    "    X_missing = missing_data[features].fillna(0)\n",
    "    predicted_ages = model_age.predict(X_missing)\n",
    "    \n",
    "    print(f\"\\n🔮 Dự đoán cho {len(missing_data)} samples:\")\n",
    "    for i, (idx, row) in enumerate(missing_data.iterrows()):\n",
    "        print(f\"   {row['Tên']}: {predicted_ages[i]:.1f} tuổi\")\n",
    "    \n",
    "    # Bước 6: Cập nhật dữ liệu\n",
    "    df_predict_age.loc[df_predict_age['Tuổi'].isna(), 'Tuổi'] = predicted_ages\n",
    "    \n",
    "    print(f\"\\n✅ Kết quả cuối cùng:\")\n",
    "    print(df_predict_age[['Tên', 'Tuổi', 'Lương', 'Phòng ban', 'Kinh nghiệm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abcf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎯 DEMO 2: Dự đoán Lương dựa trên Tuổi, Phòng ban và Kinh nghiệm\") \n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sử dụng dữ liệu gốc (chưa có Tuổi được dự đoán)\n",
    "df_predict_salary = df_advanced.copy()\n",
    "df_predict_salary['Phòng ban_encoded'] = le_dept.fit_transform(df_predict_salary['Phòng ban'].fillna('Unknown'))\n",
    "\n",
    "# Tách dữ liệu train và missing cho Lương\n",
    "train_salary = df_predict_salary[df_predict_salary['Lương'].notna()]\n",
    "missing_salary = df_predict_salary[df_predict_salary['Lương'].isna()]\n",
    "\n",
    "print(f\"📊 Dữ liệu train: {len(train_salary)} samples\")\n",
    "print(f\"📊 Dữ liệu cần dự đoán: {len(missing_salary)} samples\")\n",
    "\n",
    "if len(train_salary) > 0 and len(missing_salary) > 0:\n",
    "    # Features cho dự đoán lương\n",
    "    salary_features = ['Tuổi', 'Phòng ban_encoded', 'Kinh nghiệm'] \n",
    "    X_train_salary = train_salary[salary_features].fillna(0)\n",
    "    y_train_salary = train_salary['Lương']\n",
    "    \n",
    "    print(f\"\\n🔧 Features sử dụng: {salary_features}\")\n",
    "    print(\"📈 Training data:\")\n",
    "    combined_train = pd.concat([X_train_salary, y_train_salary], axis=1)\n",
    "    print(combined_train)\n",
    "    \n",
    "    # Training model cho lương\n",
    "    model_salary = RandomForestRegressor(n_estimators=10, random_state=42, max_depth=3)\n",
    "    model_salary.fit(X_train_salary, y_train_salary)\n",
    "    \n",
    "    # Feature importance\n",
    "    importance = model_salary.feature_importances_\n",
    "    print(f\"\\n📊 Feature Importance:\")\n",
    "    for feature, imp in zip(salary_features, importance):\n",
    "        print(f\"   {feature}: {imp:.3f}\")\n",
    "    \n",
    "    # Dự đoán lương\n",
    "    X_missing_salary = missing_salary[salary_features].fillna(0)\n",
    "    predicted_salaries = model_salary.predict(X_missing_salary)\n",
    "    \n",
    "    print(f\"\\n🔮 Dự đoán lương:\")\n",
    "    for i, (idx, row) in enumerate(missing_salary.iterrows()):\n",
    "        print(f\"   {row['Tên']}: {predicted_salaries[i]:,.0f} VND\")\n",
    "    \n",
    "    # Cập nhật dữ liệu\n",
    "    df_predict_salary.loc[df_predict_salary['Lương'].isna(), 'Lương'] = predicted_salaries\n",
    "    \n",
    "    print(f\"\\n✅ Kết quả cuối cùng:\")\n",
    "    print(df_predict_salary[['Tên', 'Tuổi', 'Lương', 'Phòng ban', 'Kinh nghiệm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b745f",
   "metadata": {},
   "source": [
    "#### **B. KNN Imputation - K-Nearest Neighbors**\n",
    "\n",
    "**🔍 KNN Imputation là gì?**\n",
    "\n",
    "KNN Imputation sử dụng thuật toán **K-Nearest Neighbors** để điền missing values:\n",
    "\n",
    "1. **Tìm K neighbors gần nhất**: Dựa trên khoảng cách Euclidean trong không gian features\n",
    "2. **Tính giá trị trung bình**: Lấy trung bình của K neighbors (cho số) hoặc mode (cho categorical)\n",
    "3. **Điền vào missing values**: Thay thế missing value bằng giá trị được tính\n",
    "\n",
    "**📏 Công thức khoảng cách Euclidean:**\n",
    "\n",
    "$$d(x_i, x_j) = \\sqrt{\\sum_{k=1}^{n} (x_{ik} - x_{jk})^2}$$\n",
    "\n",
    "**🎯 Ưu điểm của KNN Imputation:**\n",
    "- **Preserve relationships**: Giữ nguyên mối quan hệ giữa các features\n",
    "- **Non-parametric**: Không giả định về phân phối dữ liệu\n",
    "- **Local patterns**: Tận dụng patterns cục bộ trong dữ liệu\n",
    "- **Multivariate**: Xem xét tất cả features cùng lúc\n",
    "\n",
    "**⚙️ Các tham số quan trọng:**\n",
    "- `n_neighbors`: Số lượng neighbors (default=5)\n",
    "- `weights`: 'uniform' hoặc 'distance' weighted\n",
    "- `metric`: Phương pháp tính distance ('nan_euclidean' cho missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0062f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 DEMO 3: KNN Imputation - Điền tất cả missing values cùng lúc\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Chuẩn bị dữ liệu cho KNN\n",
    "df_knn = df_advanced.copy()\n",
    "print(\"📊 Dữ liệu trước KNN Imputation:\")\n",
    "print(df_knn)\n",
    "\n",
    "# Encode categorical data\n",
    "df_knn['Phòng ban_encoded'] = le_dept.fit_transform(df_knn['Phòng ban'].fillna('Unknown'))\n",
    "\n",
    "# Chỉ lấy các cột số cho KNN Imputation\n",
    "numerical_cols = ['Tuổi', 'Lương', 'Kinh nghiệm', 'Phòng ban_encoded']\n",
    "df_numerical = df_knn[numerical_cols].copy()\n",
    "\n",
    "print(f\"\\n🔧 Các cột số được sử dụng: {numerical_cols}\")\n",
    "print(\"📈 Ma trận dữ liệu số (có missing values):\")\n",
    "print(df_numerical)\n",
    "\n",
    "# Hiển thị missing pattern\n",
    "print(f\"\\n📊 Missing Data Pattern:\")\n",
    "missing_pattern = df_numerical.isnull()\n",
    "print(missing_pattern)\n",
    "\n",
    "# Áp dụng KNN Imputation\n",
    "print(f\"\\n🤖 Áp dụng KNN Imputation với k=2 neighbors:\")\n",
    "knn_imputer = KNNImputer(n_neighbors=2, weights='uniform')\n",
    "df_knn_filled = knn_imputer.fit_transform(df_numerical)\n",
    "\n",
    "# Chuyển đổi lại thành DataFrame  \n",
    "df_knn_result = df_knn.copy()\n",
    "df_knn_result['Tuổi'] = df_knn_filled[:, 0]\n",
    "df_knn_result['Lương'] = df_knn_filled[:, 1] \n",
    "df_knn_result['Kinh nghiệm'] = df_knn_filled[:, 2]\n",
    "\n",
    "print(f\"\\n✅ Kết quả sau KNN Imputation:\")\n",
    "result_display = df_knn_result[['Tên', 'Tuổi', 'Lương', 'Phòng ban', 'Kinh nghiệm']].copy()\n",
    "result_display['Tuổi'] = result_display['Tuổi'].round(1)\n",
    "result_display['Lương'] = result_display['Lương'].round(0)\n",
    "print(result_display)\n",
    "\n",
    "# So sánh missing values trước và sau\n",
    "print(f\"\\n📊 So sánh Missing Values:\")\n",
    "print(f\"Trước: {df_knn[numerical_cols[:-1]].isnull().sum().sum()} missing values\")\n",
    "print(f\"Sau: {pd.DataFrame(df_knn_filled[:, :-1]).isnull().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd82704",
   "metadata": {},
   "source": [
    "#### **C. So sánh các phương pháp xử lý Missing Values**\n",
    "\n",
    "**📊 Bảng tổng hợp so sánh:**\n",
    "\n",
    "| Phương pháp | Độ phức tạp | Thời gian | Độ chính xác | Phù hợp với |\n",
    "|-------------|-------------|-----------|--------------|-------------|\n",
    "| **Mean/Median** | Thấp ⭐ | Nhanh ⚡⚡⚡ | Thấp 📊 | Dữ liệu đơn giản, missing ngẫu nhiên |\n",
    "| **Mode** | Thấp ⭐ | Nhanh ⚡⚡⚡ | Thấp 📊 | Categorical data với ít categories |\n",
    "| **Forward/Backward Fill** | Thấp ⭐ | Nhanh ⚡⚡⚡ | Trung bình 📊📊 | Time series data |\n",
    "| **Random Forest** | Cao ⭐⭐⭐ | Chậm ⚡ | Cao 📊📊📊 | Dữ liệu có quan hệ phức tạp |\n",
    "| **KNN Imputation** | Trung bình ⭐⭐ | Trung bình ⚡⚡ | Cao 📊📊📊 | Dữ liệu có local patterns |\n",
    "\n",
    "**🎯 Hướng dẫn lựa chọn phương pháp:**\n",
    "\n",
    "**📈 Dữ liệu số (Numerical):**\n",
    "- **< 5% missing**: Mean/Median\n",
    "- **5-20% missing + có correlation**: KNN hoặc Random Forest  \n",
    "- **> 20% missing**: Cân nhắc loại bỏ cột hoặc thu thập thêm dữ liệu\n",
    "\n",
    "**🏷️ Dữ liệu phân loại (Categorical):**\n",
    "- **< 10% missing**: Mode\n",
    "- **> 10% missing + có relationship**: Random Forest Classification\n",
    "- **High cardinality**: Tạo category \"Unknown\"\n",
    "\n",
    "**⏰ Dữ liệu thời gian (Time Series):**\n",
    "- **Forward fill**: Cho dữ liệu stable (giá cổ phiếu)\n",
    "- **Backward fill**: Cho dữ liệu có trend  \n",
    "- **Interpolation**: Cho dữ liệu smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372d7dc",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu trùng lặp (Duplicate Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77a20c",
   "metadata": {},
   "source": [
    "### Hiểu về dữ liệu trùng lặp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf5e95",
   "metadata": {},
   "source": [
    "**🔄 Dữ liệu trùng lặp là gì?**\n",
    "\n",
    "Dữ liệu trùng lặp (*duplicate data*) là những **hàng có giá trị giống hệt nhau** trên tất cả hoặc một số cột nhất định. Dữ liệu trùng lặp có thể xuất hiện do:\n",
    "\n",
    "- **Lỗi nhập liệu**: Người dùng vô tình nhập cùng một thông tin nhiều lần\n",
    "- **Lỗi hệ thống**: Hệ thống ghi nhận cùng một sự kiện nhiều lần  \n",
    "- **Gộp dữ liệu**: Khi kết hợp nhiều nguồn dữ liệu có thông tin chồng chéo\n",
    "- **Lỗi thu thập**: Cảm biến hoặc thiết bị ghi nhận dữ liệu bị lặp\n",
    "\n",
    "**⚠️ Tác động của dữ liệu trùng lặp**\n",
    "\n",
    "- **Thiên lệch phân tích**: Một quan sát được tính nhiều lần, làm méo mó kết quả\n",
    "- **Giảm hiệu quả tính toán**: Xử lý dữ liệu thừa làm chậm thuật toán\n",
    "- **Tăng kích thước dữ liệu**: Lãng phí bộ nhớ và không gian lưu trữ\n",
    "- **Ảnh hưởng mô hình**: Machine learning có thể học sai từ dữ liệu lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo dữ liệu mẫu\n",
    "duplicate_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "    'age': [25, 30, 35, 25],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "duplicate_data = pd.DataFrame(duplicate_data)\n",
    "\n",
    "# In dữ liệu mẫu\n",
    "print(duplicate_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed9e8f",
   "metadata": {},
   "source": [
    "### Các phương pháp phát hiện và xử lý dữ liệu trùng lặp trong pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9479d87",
   "metadata": {},
   "source": [
    "Pandas cung cấp các phương thức để phát hiện và xử lý dữ liệu trùng lặp:\n",
    "\n",
    "| Phương thức | Mô tả | Trả về |\n",
    "|-------------|-------|--------|\n",
    "| `duplicated()` | Kiểm tra từng hàng có bị trùng lặp không | Boolean Series |\n",
    "| `drop_duplicates()` | Loại bỏ các hàng trùng lặp | DataFrame không trùng lặp |\n",
    "\n",
    "**📊 Hãy xem cách sử dụng các phương thức này:**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bdb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo dữ liệu mẫu\n",
    "duplicate_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Alice'],\n",
    "    'age': [25, 30, 35, 25],\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "duplicate_data = pd.DataFrame(duplicate_data)\n",
    "\n",
    "# In dữ liệu mẫu\n",
    "print(duplicate_data)\n",
    "\n",
    "# Phát hiện duplicate rows\n",
    "print(\"Phát hiện duplicate rows:\")\n",
    "print(duplicate_data.duplicated())\n",
    "\n",
    "print(\"\\nCác hàng bị duplicate:\")\n",
    "print(duplicate_data[duplicate_data.duplicated()])\n",
    "\n",
    "print(\"\\nĐếm số lượng duplicate:\")\n",
    "print(f\"Tổng số duplicate: {duplicate_data.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n Xử lý duplicate bằng cách loại bỏ:\")\n",
    "print(duplicate_data.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e951b8d",
   "metadata": {},
   "source": [
    "## Biến đổi và chuẩn hóa dữ liệu (Data Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b07aa",
   "metadata": {},
   "source": [
    "### Tổng quan về biến đổi dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449fd38",
   "metadata": {},
   "source": [
    "**🔄 Biến đổi dữ liệu là gì?**\n",
    "\n",
    "Biến đổi dữ liệu (*data transformation*) là quá trình **chuyển đổi dữ liệu** từ định dạng này sang định dạng khác để:\n",
    "\n",
    "- **Cải thiện chất lượng dữ liệu**: Làm cho dữ liệu phù hợp hơn cho phân tích\n",
    "- **Chuẩn hóa thang đo**: Đưa các biến về cùng một thang đo\n",
    "- **Giảm nhiễu**: Loại bỏ các biến động không mong muốn\n",
    "- **Tạo biến mới**: Kết hợp hoặc biến đổi biến hiện có để tạo thông tin mới\n",
    "\n",
    "**🎯 Các mục tiêu chính:**\n",
    "\n",
    "1. **Normalization**: Đưa dữ liệu về khoảng [0,1]\n",
    "2. **Standardization**: Đưa dữ liệu về phân phối chuẩn (mean=0, std=1) \n",
    "3. **Scaling**: Điều chỉnh thang đo cho phù hợp\n",
    "4. **Encoding**: Chuyển đổi dữ liệu phân loại thành số\n",
    "\n",
    "**📋 Khi nào cần biến đổi dữ liệu:**\n",
    "\n",
    "- Các biến có **đơn vị đo khác nhau** (VND, USD, kg, cm)\n",
    "- Dữ liệu có **phạm vi giá trị chênh lệch lớn** (1-10 vs 1000-10000)\n",
    "- Sử dụng **thuật toán nhạy cảm với thang đo** (KNN, SVM, Neural Networks)\n",
    "- **Cải thiện hiệu suất** của mô hình machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529a255",
   "metadata": {},
   "source": [
    "### Min-Max Normalization (Chuẩn hóa Min-Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05eac5",
   "metadata": {},
   "source": [
    "**📐 Công thức Min-Max Normalization:**\n",
    "\n",
    "$$X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$$\n",
    "\n",
    "**🎯 Đặc điểm:**\n",
    "- Đưa dữ liệu về khoảng **[0, 1]**\n",
    "- **Bảo toàn phân phối** gốc của dữ liệu\n",
    "- **Nhạy cảm với outliers** (giá trị ngoại lai)\n",
    "- Phù hợp khi biết **giới hạn trên và dưới** của dữ liệu\n",
    "\n",
    "**🔧 Sử dụng `MinMaxScaler` từ scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện cần thiết cho chuẩn hóa\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo dữ liệu mẫu với các thang đo khác nhau\n",
    "data_transform = {\n",
    "    'Lương': [15000000, 25000000, 30000000, 18000000, 22000000],\n",
    "    'Tuổi': [25, 35, 40, 28, 32],\n",
    "    'Kinh nghiệm': [2, 8, 12, 3, 6]\n",
    "}\n",
    "\n",
    "df_transform = pd.DataFrame(data_transform)\n",
    "print(\"Dữ liệu gốc:\")\n",
    "print(df_transform)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "norm_data_scaled = df_transform.copy()\n",
    "norm_data_scaled[['Lương', 'Tuổi', 'Kinh nghiệm']] = scaler.fit_transform(df_transform[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "\n",
    "print(\"Min-Max Normalization (0-1):\")\n",
    "print(norm_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978ba47",
   "metadata": {},
   "source": [
    "### Standard Scaler (Z-score Standardization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce3d87",
   "metadata": {},
   "source": [
    "**📊 Công thức Z-score Standardization:**\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Trong đó:\n",
    "- $X$ = giá trị gốc\n",
    "- $\\mu$ = giá trị trung bình (mean)\n",
    "- $\\sigma$ = độ lệch chuẩn (standard deviation)\n",
    "\n",
    "**🎯 Đặc điểm:**\n",
    "- Đưa dữ liệu về **phân phối chuẩn** với mean=0, std=1\n",
    "- **Không bị ảnh hưởng** bởi outliers nhiều như Min-Max\n",
    "- **Bảo toàn thông tin** về phân phối gốc\n",
    "- Phù hợp với **các thuật toán giả định phân phối chuẩn** (Linear Regression, Logistic Regression)\n",
    "\n",
    "**🔧 Sử dụng `StandardScaler` từ scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tạo dữ liệu mẫu với các thang đo khác nhau\n",
    "data_transform = {\n",
    "    'Lương': [15000000, 25000000, 30000000, 18000000, 22000000],\n",
    "    'Tuổi': [25, 35, 40, 28, 32],\n",
    "    'Kinh nghiệm': [2, 8, 12, 3, 6]\n",
    "}\n",
    "\n",
    "# Áp dụng Standard Scaler\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "# Fit và transform dữ liệu\n",
    "df_standard = df_transform.copy()\n",
    "df_standard[['Lương', 'Tuổi', 'Kinh nghiệm']] = scaler_std.fit_transform(\n",
    "    df_transform[['Lương', 'Tuổi', 'Kinh nghiệm']]\n",
    ")\n",
    "\n",
    "print(\"Dữ liệu sau Standard Scaling:\")\n",
    "print(df_standard)\n",
    "print(f\"\\nMô tả thống kê sau standardization:\")\n",
    "print(df_standard.describe().round(4))\n",
    "\n",
    "# Kiểm tra mean ≈ 0 và std ≈ 1\n",
    "print(f\"\\nMean của các cột: {df_standard[['Lương', 'Tuổi', 'Kinh nghiệm']].mean().round(4).values}\")\n",
    "print(f\"Std của các cột: {df_standard[['Lương', 'Tuổi', 'Kinh nghiệm']].std().round(4).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d372e",
   "metadata": {},
   "source": [
    "### Robust Scaler (Sử dụng Median và IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d20b9",
   "metadata": {},
   "source": [
    "**📈 Công thức Robust Scaling:**\n",
    "\n",
    "$$X_{robust} = \\frac{X - X_{median}}{IQR}$$\n",
    "\n",
    "Trong đó:\n",
    "- $X_{median}$ = giá trị trung vị (median)\n",
    "- $IQR$ = Interquartile Range = Q3 - Q1\n",
    "\n",
    "**🛡️ Đặc điểm:**\n",
    "- **Rất bền vững** (*robust*) trước outliers\n",
    "- Sử dụng **median thay vì mean**, **IQR thay vì std**\n",
    "- **Không bị méo** bởi các giá trị ngoại lai\n",
    "- Phù hợp khi dữ liệu có **nhiều outliers**\n",
    "\n",
    "**🎯 Khi nào sử dụng Robust Scaler:**\n",
    "- **Dữ liệu có nhiều outliers** \n",
    "- **Không muốn loại bỏ outliers** nhưng vẫn cần chuẩn hóa\n",
    "- **Dữ liệu không tuân theo phân phối chuẩn**\n",
    "\n",
    "**🔧 Sử dụng `RobustScaler` từ scikit-learn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a796d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Tạo dữ liệu có outliers\n",
    "data_with_outliers = {\n",
    "    'Lương': [15000000, 25000000, 30000000, 18000000, 22000000, 200000000],  # outlier: 200M\n",
    "    'Tuổi': [25, 35, 40, 28, 32, 22],\n",
    "    'Kinh nghiệm': [2, 8, 12, 3, 6, 1]\n",
    "}\n",
    "\n",
    "df_outliers = pd.DataFrame(data_with_outliers)\n",
    "print(\"Dữ liệu có outliers:\")\n",
    "print(df_outliers)\n",
    "print(f\"\\nMô tả thống kê:\")\n",
    "print(df_outliers.describe())\n",
    "\n",
    "# So sánh 3 phương pháp scaling\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SO SÁNH CÁC PHƯƠNG PHÁP SCALING VỚI OUTLIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# MinMax Scaler (bị ảnh hưởng mạnh bởi outliers)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaled_minmax = scaler_minmax.fit_transform(df_outliers[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "print(\"\\n1. MinMax Scaler (bị ảnh hưởng bởi outliers):\")\n",
    "print(pd.DataFrame(scaled_minmax, columns=['Lương', 'Tuổi', 'Kinh nghiệm']))\n",
    "\n",
    "# Standard Scaler (bị ảnh hưởng một phần bởi outliers)\n",
    "scaler_std = StandardScaler()\n",
    "scaled_std = scaler_std.fit_transform(df_outliers[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "print(\"\\n2. Standard Scaler (bị ảnh hưởng một phần):\")\n",
    "print(pd.DataFrame(scaled_std, columns=['Lương', 'Tuổi', 'Kinh nghiệm']))\n",
    "\n",
    "# Robust Scaler (ít bị ảnh hưởng bởi outliers)\n",
    "scaler_robust = RobustScaler()\n",
    "scaled_robust = scaler_robust.fit_transform(df_outliers[['Lương', 'Tuổi', 'Kinh nghiệm']])\n",
    "print(\"\\n3. Robust Scaler (bền vững trước outliers):\")\n",
    "print(pd.DataFrame(scaled_robust, columns=['Lương', 'Tuổi', 'Kinh nghiệm']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe95fbe",
   "metadata": {},
   "source": [
    "## Xử lý chuỗi ký tự (String Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544b9d0",
   "metadata": {},
   "source": [
    "### Tầm quan trọng của việc xử lý chuỗi ký tự"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4834c8a",
   "metadata": {},
   "source": [
    "**📝 Dữ liệu chuỗi ký tự trong thực tế**\n",
    "\n",
    "Dữ liệu chuỗi ký tự (*string data*) chiếm một phần lớn trong các bộ dữ liệu thực tế:\n",
    "\n",
    "- **Tên người, địa chỉ**: Thông tin cá nhân\n",
    "- **Mô tả sản phẩm**: Trong thương mại điện tử\n",
    "- **Bình luận, đánh giá**: Trong phân tích sentiment\n",
    "- **Danh mục, nhãn**: Dữ liệu phân loại\n",
    "\n",
    "**🧹 Các vấn đề thường gặp với dữ liệu chuỗi:**\n",
    "\n",
    "1. **Không nhất quán về định dạng**: \"iPhone\", \"iphone\", \"IPHONE\"\n",
    "2. **Khoảng trắng thừa**: \"  Apple  \", \"Apple \"\n",
    "3. **Ký tự đặc biệt**: \"email@domain.com\", \"phone: +84-123-456-789\"\n",
    "4. **Viết tắt khác nhau**: \"Dr.\", \"Doctor\", \"BS\"\n",
    "5. **Lỗi chính tả**: \"Compnay\" thay vì \"Company\"\n",
    "\n",
    "**🔧 Pandas String Accessor (`.str`)**\n",
    "\n",
    "Pandas cung cấp **accessor `.str`** cho phép áp dụng các phương thức xử lý chuỗi lên toàn bộ Series:\n",
    "\n",
    "```python\n",
    "# Thay vì làm thủ công từng phần tử\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'column'] = df.loc[i, 'column'].upper()\n",
    "\n",
    "# Sử dụng .str accessor\n",
    "df['column'] = df['column'].str.upper()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bfbce",
   "metadata": {},
   "source": [
    "### Các phương thức cơ bản xử lý chuỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337bbe7",
   "metadata": {},
   "source": [
    "**📋 Bảng tổng hợp các phương thức quan trọng:**\n",
    "\n",
    "| Phương thức | Mô tả | Ví dụ |\n",
    "|-------------|-------|-------|\n",
    "| `.str.lower()` | Chuyển về chữ thường | `\"HELLO\"` → `\"hello\"` |\n",
    "| `.str.upper()` | Chuyển về chữ hoa | `\"hello\"` → `\"HELLO\"` |\n",
    "| `.str.title()` | Viết hoa chữ cái đầu | `\"hello world\"` → `\"Hello World\"` |\n",
    "| `.str.strip()` | Loại bỏ khoảng trắng đầu/cuối | `\"  hello  \"` → `\"hello\"` |\n",
    "| `.str.replace()` | Thay thế chuỗi con | `\"hello\"` → `\"hi\"` |\n",
    "| `.str.contains()` | Kiểm tra chứa chuỗi con | `\"hello world\"` contains `\"world\"` → `True` |\n",
    "| `.str.startswith()` | Kiểm tra bắt đầu bằng | `\"hello\"` startswith `\"he\"` → `True` |\n",
    "| `.str.endswith()` | Kiểm tra kết thúc bằng | `\"hello\"` endswith `\"lo\"` → `True` |\n",
    "| `.str.len()` | Độ dài chuỗi | `\"hello\"` → `5` |\n",
    "| `.str.split()` | Tách chuỗi | `\"a,b,c\"` → `[\"a\", \"b\", \"c\"]` |\n",
    "\n",
    "**🔥 Hãy xem các ví dụ thực tế:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c701e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': ['1', '2', '3', '4', '5'],\n",
    "    'score': ['85.5', '90.0', '78.5', '92.0', '88.5'],\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'category': ['A', 'B', 'A', 'C', 'B']\n",
    "})\n",
    "\n",
    "print(\"Dữ liệu gốc và kiểu dữ liệu:\")\n",
    "print(sample_data.dtypes)\n",
    "print()\n",
    "print(sample_data)\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu\n",
    "sample_data['id'] = sample_data['id'].astype('int64')\n",
    "sample_data['score'] = sample_data['score'].astype('float64')\n",
    "sample_data['date'] = pd.to_datetime(sample_data['date'])\n",
    "sample_data['category'] = sample_data['category'].astype('category')\n",
    "\n",
    "print(\"\\nSau khi chuyển đổi kiểu dữ liệu:\")\n",
    "print(sample_data.dtypes)\n",
    "print()\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c64432",
   "metadata": {},
   "source": [
    "### Normalization và Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d22fbc",
   "metadata": {},
   "source": [
    "Normalization và standardization là các kỹ thuật quan trọng để đưa dữ liệu về cùng một thang đo, đặc biệt hữu ích cho machine learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbffc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Tạo dữ liệu mẫu cho normalization\n",
    "norm_data = pd.DataFrame({\n",
    "    'height': [150, 160, 170, 180, 190],  # cm\n",
    "    'weight': [50, 60, 70, 80, 90],       # kg  \n",
    "    'income': [30000, 45000, 60000, 75000, 90000]  # VND/month\n",
    "})\n",
    "\n",
    "print(\"Dữ liệu gốc:\")\n",
    "print(norm_data)\n",
    "print(\"\\nMô tả thống kê:\")\n",
    "print(norm_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2fc07",
   "metadata": {},
   "source": [
    "### Regular Expressions (Regex) cho xử lý chuỗi nâng cao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5f680",
   "metadata": {},
   "source": [
    "**🔍 Regular Expressions là gì?**\n",
    "\n",
    "Regular Expressions (*regex*) là **ngôn ngữ pattern matching** mạnh mẽ để tìm kiếm và thao tác với chuỗi ký tự:\n",
    "\n",
    "**📋 Các ký tự đặc biệt thường dùng:**\n",
    "\n",
    "| Pattern | Mô tả | Ví dụ |\n",
    "|---------|-------|-------|\n",
    "| `\\d` | Số (0-9) | `\"abc123\"` → tìm thấy `\"123\"` |\n",
    "| `\\w` | Ký tự từ (a-z, A-Z, 0-9, _) | `\"hello_123\"` → tìm thấy tất cả |\n",
    "| `\\s` | Khoảng trắng | `\"a b c\"` → tìm thấy 2 spaces |\n",
    "| `+` | 1 hoặc nhiều lần | `\\d+` → `\"123\"` (nhiều số liên tiếp) |\n",
    "| `*` | 0 hoặc nhiều lần | `\\d*` → có thể không có số |\n",
    "| `?` | 0 hoặc 1 lần | `\\d?` → tối đa 1 số |\n",
    "| `[]` | Nhóm ký tự | `[0-9]` tương đương `\\d` |\n",
    "| `^` | Bắt đầu chuỗi | `^Hello` → chuỗi bắt đầu bằng \"Hello\" |\n",
    "| `$` | Kết thúc chuỗi | `world$` → chuỗi kết thúc bằng \"world\" |\n",
    "\n",
    "**🔧 Sử dụng regex với pandas `.str` accessor:**\n",
    "\n",
    "- `.str.contains(pattern)` - kiểm tra chứa pattern\n",
    "- `.str.extract(pattern)` - trích xuất groups từ pattern  \n",
    "- `.str.replace(pattern, replacement, regex=True)` - thay thế với regex\n",
    "- `.str.findall(pattern)` - tìm tất cả matches\n",
    "\n",
    "**📱 Ví dụ thực tế: Xử lý số điện thoại, email, mã zip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce829d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tạo dữ liệu mẫu với các patterns phức tạp\n",
    "data_regex = {\n",
    "    'text': [\n",
    "        'Liên hệ: 0123-456-789 hoặc email: john@gmail.com',\n",
    "        'SDT: +84 98 765 4321, địa chỉ: 123 Lê Lợi, Q1, TP.HCM', \n",
    "        'Phone: (024) 3825-7863, email: info@company.vn',\n",
    "        'Mobile: 0987654321, website: https://example.com',\n",
    "        'Hotline: 1900-1234, fax: (028) 3829-5678'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_regex = pd.DataFrame(data_regex)\n",
    "print(\"Dữ liệu gốc:\")\n",
    "print(df_regex)\n",
    "\n",
    "# 1. Trích xuất số điện thoại\n",
    "print(\"\\n1. Trích xuất số điện thoại:\")\n",
    "phone_pattern = r'(\\+?\\d{1,3}[\\s\\-]?)?\\(?0?\\d{2,3}\\)?[\\s\\-]?\\d{3,4}[\\s\\-]?\\d{3,4}'\n",
    "df_regex['phone'] = df_regex['text'].str.extract(phone_pattern, expand=False)\n",
    "print(df_regex[['text', 'phone']])\n",
    "\n",
    "# 2. Trích xuất email\n",
    "print(\"\\n2. Trích xuất email:\")\n",
    "email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "df_regex['email'] = df_regex['text'].str.extract(email_pattern, expand=False)\n",
    "print(df_regex[['text', 'email']])\n",
    "\n",
    "# 3. Kiểm tra chứa website\n",
    "print(\"\\n3. Kiểm tra chứa website/URL:\")\n",
    "url_pattern = r'https?://[^\\s]+'\n",
    "df_regex['has_url'] = df_regex['text'].str.contains(url_pattern, regex=True)\n",
    "print(df_regex[['text', 'has_url']])\n",
    "\n",
    "# 4. Làm sạch và chuẩn hóa số điện thoại\n",
    "print(\"\\n4. Chuẩn hóa số điện thoại:\")\n",
    "def clean_phone(text):\n",
    "    # Tìm tất cả số điện thoại\n",
    "    phones = str(text).replace('nan', '')\n",
    "    # Chỉ giữ lại số\n",
    "    cleaned = ''.join(filter(str.isdigit, phones))\n",
    "    # Format lại nếu có đủ số\n",
    "    if len(cleaned) >= 10:\n",
    "        if cleaned.startswith('84'):\n",
    "            return f\"+84-{cleaned[2:5]}-{cleaned[5:8]}-{cleaned[8:]}\"\n",
    "        elif cleaned.startswith('0'):\n",
    "            return f\"{cleaned[:4]}-{cleaned[4:7]}-{cleaned[7:]}\"\n",
    "    return cleaned if cleaned else None\n",
    "\n",
    "df_regex['phone_clean'] = df_regex['phone'].apply(clean_phone)\n",
    "print(df_regex[['phone', 'phone_clean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b32509",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu phân loại (Categorical Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020f9e7",
   "metadata": {},
   "source": [
    "### Hiểu về dữ liệu phân loại"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a323b",
   "metadata": {},
   "source": [
    "**🏷️ Dữ liệu phân loại là gì?**\n",
    "\n",
    "Dữ liệu phân loại (*categorical data*) là loại dữ liệu có **số lượng giá trị hữu hạn** và thường được biểu diễn bằng **nhãn hoặc tên**:\n",
    "\n",
    "**📊 Các loại dữ liệu phân loại:**\n",
    "\n",
    "1. **Nominal** (Danh nghĩa): Không có thứ tự\n",
    "   - Giới tính: Nam, Nữ, Khác\n",
    "   - Màu sắc: Đỏ, Xanh, Vàng\n",
    "   - Quốc gia: Việt Nam, Mỹ, Nhật Bản\n",
    "\n",
    "2. **Ordinal** (Thứ tự): Có thứ tự ý nghĩa\n",
    "   - Học vị: Cử nhân < Thạc sĩ < Tiến sĩ\n",
    "   - Đánh giá: Kém < Trung bình < Tốt < Xuất sắc\n",
    "   - Kích cỡ: S < M < L < XL\n",
    "\n",
    "**🔧 Xử lý dữ liệu phân loại trong pandas:**\n",
    "\n",
    "- **Kiểu `category`**: Pandas có kiểu dữ liệu chuyên dụng cho categorical data\n",
    "- **Memory efficient**: Tiết kiệm bộ nhớ khi có nhiều giá trị lặp lại\n",
    "- **Performance**: Tăng tốc các phép toán groupby và merge\n",
    "- **Validation**: Kiểm soát các giá trị hợp lệ\n",
    "\n",
    "**⚙️ Khi nào sử dụng kiểu `category`:**\n",
    "\n",
    "- Cột có **ít giá trị duy nhất** so với tổng số hàng\n",
    "- **Nhiều giá trị lặp lại** (high cardinality)\n",
    "- Muốn **kiểm soát các giá trị** có thể xuất hiện\n",
    "- Cần **tối ưu hóa bộ nhớ** và hiệu suất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc6ba5",
   "metadata": {},
   "source": [
    "### Label Encoding - Mã hóa nhãn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd7819",
   "metadata": {},
   "source": [
    "**🔢 Label Encoding là gì?**\n",
    "\n",
    "Label Encoding là kỹ thuật chuyển đổi dữ liệu phân loại thành **số nguyên tuần tự**:\n",
    "\n",
    "- `\"Apple\"` → `0`\n",
    "- `\"Banana\"` → `1` \n",
    "- `\"Cherry\"` → `2`\n",
    "\n",
    "**✅ Ưu điểm:**\n",
    "- **Đơn giản**: Dễ hiểu và triển khai\n",
    "- **Tiết kiệm bộ nhớ**: Chỉ cần 1 cột\n",
    "- **Phù hợp với dữ liệu ordinal**: Bảo toàn thứ tự\n",
    "\n",
    "**❌ Nhược điểm:**\n",
    "- **Tạo thứ tự giả tạo**: Apple < Banana < Cherry (không đúng)\n",
    "- **Không phù hợp với nominal data**: Các thuật toán có thể hiểu sai quan hệ\n",
    "- **Bias trong mô hình**: Giá trị lớn hơn có thể được coi là \"quan trọng\" hơn\n",
    "\n",
    "**🎯 Khi nào sử dụng Label Encoding:**\n",
    "- **Dữ liệu ordinal** có thứ tự tự nhiên\n",
    "- **Tree-based algorithms** (Decision Tree, Random Forest) - ít bị ảnh hưởng bởi thứ tự\n",
    "- **Target variable** trong classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Tạo dữ liệu categorical để demo One-Hot Encoding\n",
    "data_categorical = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Phòng ban': ['IT', 'Marketing', 'IT', 'HR', 'Marketing'],\n",
    "    'Trình độ': ['Cử nhân', 'Thạc sĩ', 'Cử nhân', 'Tiến sĩ', 'Thạc sĩ'],\n",
    "    'Thành phố': ['Hà Nội', 'TP.HCM', 'Hà Nội', 'Đà Nẵng', 'TP.HCM']\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data_categorical)\n",
    "print(\"Dữ liệu categorical gốc:\")\n",
    "print(df_categorical)\n",
    "\n",
    "print(\"Sử dụng Label Encoding đối với dữ liệu categorical:\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Khởi tạo LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Áp dụng Label Encoding cho từng cột categorical\n",
    "for col in ['Phòng ban', 'Trình độ', 'Thành phố']:\n",
    "    df_categorical[col] = label_encoder.fit_transform(df_categorical[col])\n",
    "    print(f\"Các categoricals đã được mã hóa đối với {col}: {label_encoder.classes_}\")\n",
    "\n",
    "print(\"Kết quả Label Encoding:\")\n",
    "print(df_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7abc1c",
   "metadata": {},
   "source": [
    "### **One-Hot Encoding - Mã hóa One-Hot**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47859e9",
   "metadata": {},
   "source": [
    "**🔥 One-Hot Encoding là gì?**\n",
    "\n",
    "One-Hot Encoding tạo ra **binary columns** cho mỗi category:\n",
    "\n",
    "**Ví dụ:** `[\"Apple\", \"Banana\", \"Cherry\"]` → \n",
    "\n",
    "| Apple | Banana | Cherry |\n",
    "|-------|--------|--------|\n",
    "| 1     | 0      | 0      |\n",
    "| 0     | 1      | 0      |\n",
    "| 0     | 0      | 1      |\n",
    "\n",
    "**✅ Ưu điểm:**\n",
    "- **Không tạo thứ tự giả tạo**: Tất cả categories đều bình đẳng\n",
    "- **Phù hợp với nominal data**: Apple ≠ Banana ≠ Cherry\n",
    "- **Hoạt động tốt** với hầu hết machine learning algorithms\n",
    "- **Tránh bias**: Không có category nào được coi là \"quan trọng\" hơn\n",
    "\n",
    "**❌ Nhược điểm:**\n",
    "- **Curse of dimensionality**: Tăng số lượng features đáng kể  \n",
    "- **Sparse matrix**: Nhiều giá trị 0, tốn bộ nhớ\n",
    "- **Multicollinearity**: Các cột có correlation với nhau\n",
    "\n",
    "**🎯 Khi nào sử dụng One-Hot Encoding:**\n",
    "- **Dữ liệu nominal** không có thứ tự tự nhiên\n",
    "- **Ít categories** (< 10-15 giá trị duy nhất)\n",
    "- **Linear algorithms** (Linear/Logistic Regression, SVM)\n",
    "- **Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Tạo dữ liệu categorical để demo One-Hot Encoding\n",
    "data_categorical = {\n",
    "    'Tên': ['An', 'Bình', 'Chi', 'Dũng', 'Eva'],\n",
    "    'Phòng ban': ['IT', 'Marketing', 'IT', 'HR', 'Marketing'],\n",
    "    'Trình độ': ['Cử nhân', 'Thạc sĩ', 'Cử nhân', 'Tiến sĩ', 'Thạc sĩ'],\n",
    "    'Thành phố': ['Hà Nội', 'TP.HCM', 'Hà Nội', 'Đà Nẵng', 'TP.HCM']\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data_categorical)\n",
    "print(\"Dữ liệu categorical gốc:\")\n",
    "print(df_categorical)\n",
    "\n",
    "print(\"PHƯƠNG PHÁP 1: SỬ DỤNG pandas.get_dummies()\")\n",
    "\n",
    "# Phương pháp 1: Sử dụng pandas.get_dummies()\n",
    "df_onehot_pandas = pd.get_dummies(df_categorical, \n",
    "                                  columns=['Phòng ban', 'Trình độ', 'Thành phố'],\n",
    "                                  prefix=['PB', 'TD', 'TP'])\n",
    "\n",
    "print(\"Kết quả One-Hot Encoding với pandas:\")\n",
    "print(df_onehot_pandas)\n",
    "\n",
    "print(f\"\\nSố cột trước: {len(df_categorical.columns)}\")\n",
    "print(f\"Số cột sau: {len(df_onehot_pandas.columns)}\")\n",
    "\n",
    "print(\"PHƯƠNG PHÁP 2: SỬ DỤNG sklearn.OneHotEncoder\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Phương pháp 2: Sử dụng sklearn OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' để tránh multicollinearity\n",
    "\n",
    "# Chỉ encode các cột categorical (bỏ qua cột 'Tên')\n",
    "categorical_cols = ['Phòng ban', 'Trình độ', 'Thành phố']\n",
    "encoded_data = encoder.fit_transform(df_categorical[categorical_cols])\n",
    "\n",
    "# Tạo tên cột cho kết quả\n",
    "feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Tạo DataFrame mới\n",
    "df_onehot_sklearn = pd.DataFrame(encoded_data, columns=feature_names)\n",
    "df_onehot_sklearn = pd.concat([df_categorical[['Tên']], df_onehot_sklearn], axis=1)\n",
    "\n",
    "print(\"Kết quả One-Hot Encoding với sklearn:\")\n",
    "print(df_onehot_sklearn)\n",
    "\n",
    "print(f\"\\nLưu ý: sklearn với drop='first' giảm số cột để tránh multicollinearity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011775ca",
   "metadata": {},
   "source": [
    "## Câu hỏi ôn tập"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750156b9",
   "metadata": {},
   "source": [
    "**📝 Hãy trả lời các câu hỏi sau để kiểm tra hiểu biết của bạn:**\n",
    "\n",
    "| **Phương thức nào dùng để phát hiện dữ liệu thiếu trong pandas?** | |\n",
    "|---|---|\n",
    "| `isna()` hoặc `isnull()` | |\n",
    "| `missing()` | |\n",
    "| `empty()` | |\n",
    "| `nan_check()` | |\n",
    "\n",
    "| **Phương thức `fillna()` được sử dụng để làm gì?** | |\n",
    "|---|---|\n",
    "| Loại bỏ dữ liệu thiếu | |\n",
    "| Thay thế dữ liệu thiếu | |\n",
    "| Phát hiện dữ liệu thiếu | |\n",
    "| Đếm dữ liệu thiếu | |\n",
    "\n",
    "| **MinMaxScaler đưa dữ liệu về khoảng giá trị nào?** | |\n",
    "|---|---|\n",
    "| [-1, 1] | |\n",
    "| [0, 1] | |\n",
    "| [0, 100] | |\n",
    "| [-100, 100] | |\n",
    "\n",
    "| **Phương thức nào dùng để loại bỏ hàng trùng lặp?** | |\n",
    "|---|---|\n",
    "| `remove_duplicates()` | |\n",
    "| `drop_duplicates()` | |\n",
    "| `delete_duplicates()` | |\n",
    "| `unique()` | |\n",
    "\n",
    "| **Trong pandas, để chuyển chuỗi về chữ thường ta sử dụng?** | |\n",
    "|---|---|\n",
    "| `.str.lowercase()` | |\n",
    "| `.str.lower()` | |\n",
    "| `.str.downcase()` | |\n",
    "| `.str.small()` | |\n",
    "\n",
    "| **Label Encoding phù hợp nhất với loại dữ liệu nào?** | |\n",
    "|---|---|\n",
    "| Dữ liệu số liên tục | |\n",
    "| Dữ liệu nominal | |\n",
    "| Dữ liệu ordinal | |\n",
    "| Dữ liệu thời gian | |\n",
    "\n",
    "| **StandardScaler chuẩn hóa dữ liệu có Mean và Standard Deviation là bao nhiêu?** | |\n",
    "|---|---|\n",
    "| Mean=1, Std=0 | |\n",
    "| Mean=0, Std=1 | |\n",
    "| Mean=0.5, Std=0.5 | |\n",
    "| Mean=100, Std=10 | |\n",
    "\n",
    "| **Khi nào nên sử dụng RobustScaler thay vì MinMaxScaler?** | |\n",
    "|---|---|\n",
    "| Khi dữ liệu có nhiều outliers | |\n",
    "| Khi dữ liệu đã chuẩn hóa | |\n",
    "| Khi dữ liệu là categorical | |\n",
    "| Khi dữ liệu có kích thước nhỏ | |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
